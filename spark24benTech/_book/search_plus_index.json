{"handy/shell/":{"url":"handy/shell/","title":"shell常用","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/shell/awk.html":{"url":"handy/shell/awk.html","title":"awk","keywords":"","body":"awk 常用命令 使用特殊的分隔符 # 使用正则表达式分割符号，连续多个 ][, 为分割符 awk -F '[],[]*' '{print $2, $12, $14, $16}' # ascii 码分割符 awk -F '\\3' '{if (match($NF,/[0-9]{4}-[0-9]{2}-[0-9]{2}/)) print $NF}' 将 shell 变量传给 awk # 方法一 variable=\"line one\\nline two\" awk 'BEGIN {print \"'\"$variable\"'\"}' # 方法二 awk -v var=\"$variable\" 'BEGIN {print var}' 在 awk 中调用 shell 命令 # 例一 awk '{system(\"wc \"$1)}' myfile # 例二 awk '{ cmd = \"your_command \" $1 while (cmd | getline line) { do_something_with(line) } close(cmd) }' file gsub 替换，gsub 返回替换次数，源字符串被替换 date +\"%F %T\" | awk '{gsub(/[-:]/, \" \", $0); tm=mktime($0); print tm}' 正则匹配 awk '{if(match($0,/http:\\/\\/.*\\/(.*)\\.rpm/,a)) print a[1]}' 酷壳上的例子: # 指定匹配条件 awk '$3==0 && $6==\"LISTEN\" || NR==1' netstat.txt # $6 匹配 FIN 或 TIME awk '$6 ~ /FIN|TIME/ || NR==1 {print NR,$4,$5,$6}' OFS=\"\\t\" netstat.txt # $6 不匹配 WAIT awk '$6 !~ /WAIT/ || NR==1 {print NR,$4,$5,$6}' OFS=\"\\t\" netstat.txt # 不匹配 WAIT awk '!/WAIT/' netstat.txt # 从 file 文件中找出长度大于 80 的行 awk 'length>80' file # 按连接数查看客户端 IP netstat -ntu | awk '{print $5}' | cut -d: -f1 | sort | uniq -c | sort -nr # 打印 99 乘法表 seq 9 | sed 'H;g' | awk -v RS='' \\ '{for(i=1;i 内建变量 $0 当前记录（这个变量中存放着整个行的内容） $1~$n 当前记录的第n个字段，字段间由FS分隔 FS 输入字段分隔符 默认是空格或Tab NF 当前记录中的字段个数，就是有多少列 NR 已经读出的记录数，就是行号，从1开始，如果有多个文件话，这个值也是不断累加中。 FNR 当前记录数，与NR不同的是，这个值会是各个文件自己的行号 RS 输入的记录分隔符， 默认为换行符 OFS 输出字段分隔符， 默认也是空格 ORS 输出的记录分隔符，默认为换行符 FILENAME 当前输入文件的名字 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/shell/sed.html":{"url":"handy/shell/sed.html","title":"sed","keywords":"","body":"sed 常用命令 删除：d命令 sed '2,$d' example # 删除example文件的第二行到末尾所有行 sed '/test/d' example # 删除example文件所有包含test的行 替换：s命令 # 如果某一行开头的test被替换成mytest，打印 sed -n 's/^test/mytest/p' example # 所有以192.168.0.1开头的行变成192.168.0.1localhost sed 's/^192.168.0.1/&localhost/' example # love被标记为1，所有loveable会被替换成lovers sed -n 's/\\(love\\)able/\\1rs/p' example # 紧跟着s命令的都被认为是新的分隔符，“#”在这里是分隔符 sed 's#10#100#g' example 选定行的范围：逗号 # 所有在模板test和check所确定的范围内的行都被打印 sed -n '/test/,/check/p' example # 打印从第五行开始到第一个包含以test开始的行之间的所有行 sed -n '5,/^test/p' example # 对于模板test和check之间的行，每行的末尾用字符串sed test替换 sed '/test/,/check/s/$/sed test/' example 多点编辑：e命令 # 命令的执行顺序对结果有影响 sed -e '1,5d' -e 's/test/check/' example sed --expression='s/test/check/' --expression='/love/d' example 从文件读入：r命令 # file里的内容被读进来，显示在与test匹配的行后面 sed '/test/r file' example # insert file into example after line 2 sed '2r file' example 写入文件：w命令 # 在example中所有包含test的行都被写入file里 sed -n '/test/w file' example 追加命令：a命令 # 追加到以test开头的行后面，sed要求命令a后面有一个反斜杠 sed '/^test/a\\this is an appended line' example 插入：i命令 # 如果test被匹配，则把反斜杠后面的文本插入到匹配行的前面 sed '/test/i\\this is an inserted line' example 下一个：n命令 # 如果test被匹配，则移动到匹配行的下一行，替换这一行的aa，变为bb，并打印该行，然后继续 sed '/test/{n; s/aa/bb/;}' example 变形：y命令 # 把1--10行内所有abcde转变为大写，注意，正则表达式元字符不能使用这个命令 sed '1,10y/abcde/ABCDE/' example 退出：q命令 # 打印完第10行后，退出sed sed '10q' example 保持和获取：h命令和G命令。在sed处理文件的时候，每一行都被保存在一个叫模式空间的临时缓冲区中，除非行被删除或者输出被取消，否则所有被处理的行都将打印在屏幕上。接着模式空间被清空，并存入新的一行等待处理。在这个例子里，匹配test的行被找到后，将存入模式空间，h命令将其复制并存入一个称为保持缓存区的特殊缓冲区内。第二条语句的意思是，当到达最后一行后，G命令取出保持缓冲区的行，然后把它放回模式空间中，且追加到现在已经存在于模式空间中的行的末尾。在这个例子中就是追加到最后一行。 # 任何包含test的行都被复制并追加到该文件的末尾 sed -e '/test/H' -e '$G' example 保持和互换：h命令和x命令 # 互换模式空间和保持缓冲区的内容。也就是把包含test与check的行互换 sed -e '/test/h' -e '/check/x' example sed的选项： -e command, --expression=command 允许多台编辑 -n, --quiet, --silent 取消默认输出 sed定位的方法： x x为指定行号 x,y 指定从x到y的行号范围 /pattern/ 查询包含模式的行 /pattern/pattern/ 查询包含两个模式的行 /pattern/,x 从与pattern的匹配行到x号行之间的行 x,/pattern/ 从x号行到与pattern的匹配行之间的行 x,y! 查询不包含x和y行号的行 sed编辑命令表： p 打印匹配行 = 打印匹配行号 a\\ 在定位行之后追加文本信息 i\\ 在定位行之前插入文本信息 d 删除定位行 c\\ 用新文本替换定位行 s 使用替换模式替换相应的模式 r file 从另一个文件中读文本 w file 将文本写入到另一个文件中 y 变换字符 q 第一个模式匹配完成后退出 l 显示与八进制ASCII码等价的控制字符 {} 在定位行执行的命令组 n 读取下一个输入行，用下一个命令处理新的行 h 将模式缓存区的文本复制到保持缓存区 H 将模式缓存区的文本追加到保持缓存区 x 互换模式缓存区和保持缓存区的内容 g 将保持缓存区的内容复制到模式缓存区 G 将保持缓存区的内容追加到模式缓存区 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/shell/grep.html":{"url":"handy/shell/grep.html","title":"grep","keywords":"","body":"grep 常用命令 grep [option] 'pattern string' filename 高亮匹配结果，并过滤 .git .svn 等文件夹。 alias grep='grep --color=auto --exclude-dir={.bzr,CVS,.git,.hg,.svn}' 显示 /etc/inittab 中以 # 开头，且后面跟一个或者多个空白符，而后又跟了任意非空白符的行 grep '#[[:space:]]*[^[:space:]]' /etc/inittab egrep 命令等同于 grep -E ，利用此命令可以使用扩展的正则表达式对文本进行搜索，下面三条命令是等价的，列出当前目录（包括子目录）中查找所有包含 UA 或 DL 的文件 grep -r -l \"\\(UA\\)\\|\\(DL\\)\" ./ grep -r -l -E \"(UA)|(DL)\" ./ egrep -r -l \"(UA)|(DL)\" ./ 查找行首是 1 或 2，后面是 rc 中间接任意字符而后跟 /rc egrep '^(1|2).*(rc).*/\\1.*' /etc/inittab 查找含有非 ascii 字符的文件，并显示行 grep --color=auto -P -n \"[\\x80-\\xFF]\" file.txt 查找特殊字符 TAB，详细见这里 grep -P \"\\t\" foo.txt # 使用 perl 正则表达样 grep \"$(printf '\\t')\" foo.txt grep \"^V\" foo.txt grep $'\\t' foo.txt 查找含有 success 的行，并显示上下几行 grep -A \"success\" foo.txt # 显示前 4 行 grep -B \"success\" foo.txt # 显示后 4 行 grep -C \"success\" foo.txt # 显示前、后 4 行 grep 正则表达式 简介如下： ^ 锚定行首； $ 锚定行尾 .匹配一非换行符字符； * 匹配零个或多个先前字符 [] 匹配一个指定范围内的字符； [^] 匹配一个不在指定范围内的字符 /(../) 标记匹配字符 / 锚定单词开始； /> 锚定单词结束 x/{m/} 重复字符x，m次； x/{m,/} 重复字符x,至少m次； x/{m,n/} 重复字符x，至少m次，不多于n次 /w 匹配文字和数字字符，也就是 [A-Za-z0-9] ； /W 为 /w 的反置形式，匹配一个或多个非单词字符 /b 单词锁定符 扩展的正则表达式 基本正则表达式使用 ( ) { } . ? | 都需要转义，在扩展正则表达中不需要转义；另外扩展的正则表达式还加入了至少出现一次 + 、或者 | 。详细信息如下： 字符匹配的命令和用法与基本正则表达式的用法相同 字符锚定的用法和基本正则表达式的用法相同 次数匹配： * 匹配其前面字符的任意次 ? 匹配其前面字符的 0 或 1 次 + 匹配其前面字符至少 1 次 {m,n} 匹配其前面字符 m 到 n 次 特殊字符： | 代表或者 grep -E 'c|cat' file 表示在文件 file 内查找包含 c 或者 cat \\. \\表示转义字符，此表示符号 . POSIX字符类 POSIX增加了特殊的字符类，如 [:alnum:] 是 A-Za-z0-9 的另一个写法，要把它们放到[]号内才能成为正则表达式。在linux下的grep除fgrep外，都支持POSIX的字符类。 [:alnum:] 文字数字字符 [:alpha:] 文字字符 [:digit:] 数字字符 [:graph:] 非空字符（非空格、控制字符） [:lower:] 小写字符 [:cntrl:] 控制字符 [:print:] 非空字符（包括空格） [:punct:] 标点符号 [:space:] 所有空白字符（新行，空格，制表符） [:upper:] 大写字符 [:xdigit:] 六进制数字（0-9，a-f，A-F） var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/shell/find.html":{"url":"handy/shell/find.html","title":"find","keywords":"","body":"find 常用 find 命令的基本格式 find [path] [operation] find . -name *.py -maxdepth 1 查找一级目录下的所有 py 文件 find . -ctime -1 查找 24 小时之内创建的文件，atime 和 mtime 用法一致 find . -cmin -10 查找 10 分钟之内创建的文件，amin 和 mmin 用法一致 find . -anewer hello.py 查找在 hello.py 之后访问过的文件，cnewer 和 mnewer 用法一致 find . -user root 查找属于某一用户的文件 find . -type d -name *demo* 查找所有目录包含 demo 的目录 find . -type f -perm -o=x -exec rm {} \\; 查找所有可执行文件，并删除 find . -perm 600 查找权限为 600 的文件，如果权限前面加“-”号，表示满足一位匹配可， find . -perm -007 会匹配权限为 007、077、777 的文件 find . -empty -ls 显示所有的空白文件，并显示详细，加 ls 完全画蛇添足，只是为了说明这个参数 find . -size +10k -a -size -100k -o -name *demo* 查找大于 10k 且小于 100k 的文件或者名字含有 demo 的文件 find . -size +10k ! -name *demo* 查找大于 10k 并且名称不含有 demo 的文件 用正则表达式查找，匹配时会匹配整个路径，而不仅仅是文件名 使用 grep 正则表达式匹配以数字开头的文件 find . -regextype grep -regex \".*/[0-9][^/]*\" var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/shell/git.html":{"url":"handy/shell/git.html","title":"git","keywords":"","body":"git 使用小结 有用的命令 远端 git remote -v # 查看远端 git remote set-url origin http://sogou.git # 设置远程源 git push -u origin master # 推本地分支到远端 # 增加远端 git remote add liulin http://sogou.git # 设置远程源 git push liulin master 如果你还没有克隆现有仓库，并欲将你的仓库连接到某个远程服务器，你可以使用如下命令添加： git remote add origin git push origin master git 同步父流更新 git remote add upstream https://github.com/被fork的仓库.git git fetch upstream git merge upstream/master 强制推送本地库到服务器 git push origin HEAD --force 远端分支 git push origin : # 推送分支 git push origin --all # 推送所有分支 git push origin --delete # 删除远端分支 git checkout -b v0.0.1 remotes/origin/v0.0.1 # 拉取远程分支 git checkout -t origin/v0.0.1 # 拉取远程分支 远端tag git push origin --tags # 推送所有 tag git push origin v1.1.0 # 推送 tag 到远端 git push origin --delete tag # 删除远端tag 本地 git add files # 把当前文件放入暂存区 git reset -- files # 撤销最后一次 git add files git commit # 给暂存区域生成快照并提交 git checkout -- files # 把文件从暂存区域复制到工作目录，丢弃本地修改 分支 git checkout -b # 新建分支 git merge # 合并分支 git branch -d # 删除分支 标签 git tag # 查看标签 git tag -a v1.1.0 084ac46 # 增加标签 git show v1.1.0 # 查看标签 当执行完 cherry-pick 以后，将会生成一个新的提交；这个新的提交的哈希值和原来的不同，但标识名一样； git cherry-pick 38361a55 打包导出 git archive --format zip -o site-$(git log --pretty=format:\"%h\" -1).zip HEAD git archive v0.1 | gzip > site.tgz diff git diff 对比两个文件修改的记录 # 比较工作区和暂存区 git diff filename # 比较暂存区与最新本地版本库 git diff --cached filename # 比较工作区和最新版本 git diff HEAD filename # 比较工作区与指定的 commit-id 的差异 git diff commit-id filename # 比较暂存区与指定 commit-id 的差异 git diff --cached commit-id filename # 比较两个 commit-id 的差异 git diff commit-id commit-id 恢复修改 本地修改了许多文件，其中有些是新增的，因为开发需要这些都不要了，想要丢弃掉，可以使用如下命令： git checkout . # 本地所有修改的文件，没有的提交的，都返回到原来的状态 git checkout -- git stash # 把所有没有提交的修改暂存到stash里面。可用git stash pop恢复 git reset --hard HASH # 返回到某个节点，不保留修改 git reset --soft HASH # 返回到某个节点。保留修改 git clean -df # 返回到某个节点，-n 显示将要删除的文件和目录，-f 删除文件，-df 删除文件和目录 缓存修改 修改了一些东西，想切换到另一个分支： git stash # 保存工作 git stash list # 查看 git stash apply # 恢复stash ，默认stash@{0} git stash apply stash@{2} 假如你想要丢弃你所有的本地改动与提交，可以到服务器上获取最新的版本并将你本地主分支指向到它： git fetch origin git reset --hard origin/master 系统配置 彩色显示 git config --global color.status auto git config --global color.diff auto git config --global color.branch auto git config --global color.interactive auto 非交互式 git config --global pager.branch false # git diff using no pager git config --global --replace-all core.pager \"less -F -X\" 设置 git config --global user.name \"liulin209544\" git config --global user.email \"liulin209544@sogou-inc.com\" git config --local user.name \"liulin209544\" git config --local user.email \"liulin209544@sogou-inc.com\" 一般流程 假设需要开发某个功能，或者 fix 某个 bug，详细如下： 更新代码 在做所有开发工作之前，先把本地代码和 git repos 同步最新： git pull 修改代码 本地 coding, coding 过程中，可能会有多次本地 commit，比如说， coding balabalabala，然后： git add . git commit 再 coding，然后 git add . git commit 提交代码 假设 coding 完成，需要把本地代码推送到远端 git repos，在推送之前，一定做如下动作： git pull --rebase 在这一步，一定不要简单的执行 git pull，git pull 相当于两个动作，先 git featch, 然后 git merge；如果本地有冲突，这样会造成本地新创建一个分支出来。如果接着把这样没有意义的分支推送到远端 git repos，会导致整个 git tree 很难看。 在你 coding 期间，别人可能提交代码，提交的代码可能和你 coding 的内容冲突，如果有冲突，会给你提示，类似前面说得， >>>>>> branch 'master' of ...... 有冲突没关系，找到相应冲突的地方，按照提示修改就好了。改完以后做如下动作， git add . git commit 然后根据提示做 git rebase --continue 完成冲突解决以后就可以把本地 coding 内容 push 到远端 git repos 了 git push 资料 图解git var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/shell/svn.html":{"url":"handy/shell/svn.html","title":"svn","keywords":"","body":"svn 常用操作 只 checkout 部分目录 # 先checkout空目录 svn co --depth empty svnLocation localDir # 对需要的子目录递归checkout svn update --set-depth infinity localDir/data svn update --set-depth infinity localDir/block 一般开发流程 创建分支TRUNK='http://example.com/foo/trunk/bar' BRANCH='http://example.com/foo/branches/bar-1.0.2-1' svn copy $TRUNK $BRANCH -m \"something\" 做一些修改，并提交到分支上svn co $BRANCH $WORKDIR svn commit -m \"done\" 查询创建分支时的版本svn log --stop-on-copy $BRANCH | awk '/^r/ {print $1}' | tail -1 切换到主干svn switch $TRUNK $WORKDIR 合并分支，260为第3步输出的版本svn merge -r260:HEAD $BRANCH $WORKDIR 冲突解决svn st | grep ^C # 查找合并时的冲突文件，手工解决冲突 svn resolved filename # 告知 svn 冲突已解决 svn commit -m \"\" # 提交并后的版本 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/app/":{"url":"handy/app/","title":"常用组件","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/app/ceph.html":{"url":"handy/app/ceph.html","title":"ceph","keywords":"","body":"ceph 常用命令 pool 查看 pool ceph osd lspools # pool 列表 rados df # pool 状态 创建 pool # 创建一个test-pool，pg_num为128 ceph osd pool create test-pool 128 # 设置允许最大object数量为100 ceph osd pool set-quota test-pool max_objects 100 # 设置允许容量限制为10GB，取消配额限制只需要把对应值设为0即可 ceph osd pool set-quota test-pool max_bytes $((10 * 1024 * 1024 * 1024)) # 重命名 pool ceph osd pool rename test-pool test-pool-new # 删除 pool ceph osd pool delete test-pool test-pool --yes-i-really-really-mean-it 设置参数 # 设置pool的冗余副本数量为3 ceph osd pool set {pool_name} size 3 # 获取当前pg_num： ceph osd pool get {pool_name} pg_num # 获取当前副本数 ceph osd pool get {pool_name} size pg 查看 pg # 查看pg信息，包括状态，对应的osd ceph pg dump # pg映射OSD位置，【8,5】指osd.8和osd.5 2副本，osd.8为主副本 osdmap e99 pg 1.1ff (1.1ff) -> up [8,5] acting [8,5] ceph pg ls-by-primary # 查看某个osd上所有pg状态 ceph pg ls-by-osd 修复 incomplete pg ceph pg map 5.24 # 查看 pg 的 osd 分布 ceph-objectstore-tool --data-path /var/lib/ceph/osd/ceph-11/ \\ --pgid 5.24 --op mark-complete osd osd 替换 osd 机器上执行： systemctl stop ceph-osd\\*.service ceph-osd.target for ((i=1; i admin 机器上执行： chown -R ceph:ceph /data /data1 /data2 /data3 rm -rf /data/* /data1/* /data2/* /data3/* sudo ceph-deploy --overwrite-conf osd prepare \\ hostname:/data hostname:/data1 hostname:/data2 hostname:/data3 sudo ceph-deploy osd activate \\ hostname:/data hostname:/data1 hostname:/data2 hostname:/data3 重启 osd systemctl restart ceph-osd@1 创建用户与授权 set -euo pipefail if [ $# != 2 ]; then echo \"Usage: $0 user pool $#\" exit 1 fi user=${1} pool=${2} # 1. 创建用户与授权 radosgw-admin user create --uid=${user} --display-name=${user} radosgw-admin caps add --uid=${user} --caps=\"users=read,write\" radosgw-admin caps add --uid=${user} --caps=\"usage=read,write\" # 2. 设置 placement radosgw-admin metadata get user:${user} > ${user}.md.json sed -i \"s/\\\"default_placement\\\".*/\\\"default_placement\\\": \\\"${user}-placement\\\",/\" \\ ${user}.md.json radosgw-admin metadata put user:${user} pool_template.txt radosgw-admin zone get --rgw-zone=default > ${user}.zone.json sed -i '/placement_pools/r pool_template.txt' ${user}.zone.json radosgw-admin zone set --rgw-zone=default --infile ${user}.zone.json # 4. 更新 zone radosgw-admin zonegroup add --rgw-zonegroup=default --rgw-zone=default var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/app/kafka.html":{"url":"handy/app/kafka.html","title":"kafka","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/app/mysql.html":{"url":"handy/app/mysql.html","title":"mysql","keywords":"","body":"mysql 配置 本地能连接，远程不能连接 修改数据配置，注释掉 bind_address = 127.0.0.1 修改数据库，update user set host = '%' where user = 'root'; var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/app/kube.html":{"url":"handy/app/kube.html","title":"kube","keywords":"","body":"kubectl 常用命令 pod 操作 kubectl get pods -n test --sort-by=.status.startTime kubectl get pods -n test -o wide --selector=app=admin-label kubectl exec -n test pod-web2wfc9 -c con-web-init -it sh 扩容操作 kubectl scale sts mysql-local --replicas=2 查询特定event kubectl get event -n base -owide \\ --field-selector involvedObject.kind=AuthorizationAction 标签操作 kubectl label node 10.152.82.24 zoon=z3 kubectl label node 10.152.88.106 pool- 节点管理 标记节点unschedulable，并会驱逐节点上的pods kubectl drain $NODE 阻止在该节点上调度新pod，但不会影响改节点上正在运行的pods kubectl cordon $NODE 标记节点为schedulable状态 kubectl uncordon $NODE jsonpath https://kubernetes.io/docs/reference/kubectl/jsonpath/ 去除 finalizers kubectl patch authorizationactions -p '{\"metadata\":{\"finalizers\":[]}}' 或者 kubectl patch authorizationactions --type json \\ -p='[{\"op\":\"remove\",\"path\":\"/metadata/finalizers\"}]' 查询 ownerReferences kubectl get rs -o=jsonpath=\"{range .items[*]}{.metadata.namespace} \\ {.metadata.name} {.metadata.ownerReferences[0].name}{'\\n'}{end}\" var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/app/docker.html":{"url":"handy/app/docker.html","title":"docker","keywords":"","body":"docker 常用命令 docker rm containerid docker exec -it containerid bash docker run -p ip:hostPort:containerPort --env TERM='xterm' redis docker build --pull --tag ${TAG} ./ docker push ${TAG} 保存镜像容器 保存，加载镜像命令，通过image保存的镜像会保存操作历史，可以回滚到历史版本。 docker save imageID > filename docker load 保存，加载容器命令： docker export containID > filename docker import filename [newname] docker pool 扩容 enlarge-docker-pool.sh 清除废旧 image cleanup-unused-images.sh var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/misc/":{"url":"handy/misc/","title":"杂项","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/misc/rpm.html":{"url":"handy/misc/rpm.html","title":"rpm","keywords":"","body":"rpm rpm -ivh # 安装显示安装进度--install--verbose--hash rpm -Uvh # 升级软件包 --Update rpm -qpl # 列出RPM软件包内的文件信息[Query Package list] rpm -qpi # 列出RPM软件包的描述信息[Query Package install package(s)] rpm -qf # 查找指定文件属于哪个RPM软件包[Query File] rpm -Va # 校验所有的RPM软件包，查找丢失的文件[View Lost] rpm -e # 删除包 rpm2cpio kernel-debuginfo.rpm | cpio -div # 解压rpm包 # --force 强制操作 如强制安装删除等 # --requires 显示该包的依赖关系 # --nodeps 忽略依赖关系并继续操作 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/misc/tmux.html":{"url":"handy/misc/tmux.html","title":"tmux","keywords":"","body":"tmux 常用操作 tmux是一个优秀的终端复用软件，类似GNU Screen，但来自于OpenBSD，采用BSD授权。 tmux 开启tmux tmux ls 显示已有tmux列表 C-b s tmux attach-session -t 数字 选择tmux C-b c 创建一个新的窗口 C-b \" 水平分割出来一个窗口 C-b % 垂直分割出来一个窗口 C-b n 切换到下一个窗口 C-b p 切换到上一个窗口 C-b l 切换到最后一个窗口 c-b w 通过上下键选择当前窗口中打开的会话 C-b 数字 直接跳到你按的数字所在的窗口 C-b & 退出当前窗口 C-b d 临时断开会话 断开以后,还可以连上的哟:) C-b o 在小窗口中切换 C-b ! 关闭所有小窗口 C-b x 关闭当前光标处的小窗口 C-b t 钟表 C-b pageup/pagedown 滚屏 C-b (方向键) 切换窗口 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/misc/setup-ubuntu.html":{"url":"handy/misc/setup-ubuntu.html","title":"setup ubnutu","keywords":"","body":"ubnutu开发环境搭建 #!/bin/bash set -o errexit set -o nounset set -o pipefail # ==== add priv to vbox share ==== sudo usermod -a -G vboxsf $(whoami) # ==== install softwares ==== sudo apt-add-repository ppa:ubuntu-elisp/ppa # for emacs sudo apt-add-repository ppa:fcitx-team/nightly # for sogou-input sudo apt-get update sudo apt-get upgrade -y PKG_TO_INSTALL=(build-essential cgdb cmake curl emacs fcitx git golang-go \\ htop ipython kcachegrind kdiff3 subversion terminator tmux vim zsh) for pkg in ${PKG_TO_INSTALL[@]}; do echo sudo apt-get install -y $pkg done # ==== config git ==== git config --global color.status auto git config --global color.diff auto git config --global color.branch auto git config --global color.interactive auto git config --global user.email \"liulin59@gmail.com\" git config --global user.name \"9sheng\" # ==== config emacs ==== rm -rf ~/.emacs.d ~/.spacemacs.d git clone https://github.com/9sheng/spacemacs.git ~/.emacs.d git clone https://github.com/9sheng/spacemacs-private.git ~/.spacemacs.d (cd ~/.spacemacs.d && git checkout -b 9sheng remotes/origin/9sheng) # ==== config vim ==== cat ~/.vimrc set ts=4 set noexpandtab set sw=4 set nu set ic set nobackup EOF # ==== config zsh ==== git clone http://gitlab.biztech.sogou-inc.com/liulin209544/toolkit.git ~/toolkit sh -c \"$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" cat > ~/.zshrc export GOPATH=~/workspace/golang export PATH=$PATH:~/toolkit/bin:$GOPATH/bin EOF chsh -s $(which zsh) # ==== config svn ==== sed -i -e 's/# merge-tool-cmd =.*/merge-tool-cmd = svn-kdiff3-merge.sh/' \\ -e 's/# diff-cmd =.*/diff-cmd = svn-kdiff3.sh/' ~/.subversion/config # ==== install go tools ==== go install github.com/rogpeppe/godef # ==== end of file ==== # 安装中文支持 # 输入法后续调整搜狗输入法为默认 # 对某个工程设置 # git config --local user.email \"liulin209544@sogou-inc.com\" # git config --local user.name \"liulin\" network setting iwlwifi 驱动不支持802.11n 协议, 所以如果路由器要是使用这个协议的话无线上网就表现为已经连上了可没有速度。按照网上找到的方法，直接禁用掉802.11n协议，但是速度会被限制在54Mb/s echo \"options iwlwifi 11n_disable=1\" >> /etc/modprobe.d/iwlwifi.conf apt-get proxy use environment variables, do NOT work. export http_proxy=http://yourproxyaddress:proxyport export https_proxy=http://yourproxyaddress:proxyport modify file /etc/apt/apt.conf, add the following: Acquire::http::Proxy \"http://yourproxyaddress:proxyport\" squid代理服务器 安装完后需要设置localnet localhost相关配置 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/misc/shell-script.html":{"url":"handy/misc/shell-script.html","title":"脚本","keywords":"","body":"shell 脚本 常用判断比较 逻辑操作符： -a 逻辑与； -o 逻辑或； ! 逻辑否 字符串比较： = 相等； != 不等； -z 空串； -n 非空串 数值比较： -eq -ne -gt -lt -le -ge 文件状态： -d 目录； -f 正规文件； -L 符号链接； -r 可读； -w 可写； -x 可执行； -s 文件非空； -u 文件有suid位设置 脚本路径 echo \"scriptPath1: \" $(cd `dirname $0`; pwd -P) echo \"scriptPath2: \" $(dirname $(readlink -f $0)) 进程文件锁 有些脚本运行时，只允许一个实例，使用文件锁，代码如下，只需要在脚本开始处调用 lock_file lock_file() { THIS_NAME=`basename $0` #clear invalid symbolic link first. find /dev/shm -maxdepth 1 -type l -follow -exec unlink {} \\; #check whether another shell script is running. if [ -e /dev/shm/$THIS_NAME ]; then echo \"exit as previous task is still running: $THIS_NAME\" exit 0 fi ln -s /proc/$$ /dev/shm/$THIS_NAME trap \"exit_lock\" 0 1 2 3 15 22 24 } function exit_lock() { unlink /dev/shm/$THIS_NAME exit 0 } 后台job 在脚本中启动后台进程，并等待结果 for ((i = 0; i 数值计算 declare -i TOTAL=15; for ((id=1; id let does exactly what (( )) do. CPUs=$(grep -c processor /proc/cpuinfo) PIDs=$(ps aux | grep \"php-fpm[:] pool\" | awk '{print $2}') let i=0 for PID in $PIDs; do CPU=$(echo \"$i % $CPUs\" | bc) taskset -pc $CPU $PID let i++ #or, let i+=1 done 参数扩展 命令 说明 ${name:-default} 使用一个默认值（一般是空值）来代替那些空的或者没有赋值的变量name ${name:=default} 使用指定值来代替空的或者没有赋值的变量name ${name:?message} 如果变量为空或者未赋值，那么就会显示出错误信息并中止脚本的执行同时返回退出码1 ${#name} 给出name的长度 ${name%word} 从name的尾部开始删除与word匹配的最小部分，然后返回剩余部分 ${name%%word} 从name的尾部开始删除与word匹配的最长部分，然后返回剩余部分 ${name#word} 从name的头部开始删除与word匹配的最小部分，然后返回剩余部分 ${name##word} 从name的头部开始删除与word匹配的最长部分，然后返回剩余部分 检查变量是否存在 ${name:?error message} 如果脚本需要一个参数 input_file=${1:?usage: $0 input_file} 截断字符串 ${var%suffix} 和 ${var#prefix} var=foo.pdf; echo ${var%.pdf}.txt 输出：foo.txt dirname a=/home/aguo/insert.sql; echo ${a%/*} 输出：/home/aguo basename a=/home/aguo/insert.sql; echo ${a%%.*} 输出：/home/aguo/insert 只取 name a=/home/aguo/insert.test.sql; a=${a%%.*} && a=${a##*/} && echo $a 输出：insert subshell 临时地到另一个目录中： # do something in current dir (cd /some/other/dir; other-command) # continue in original dir 调试 使用 set -x 来 debug 输出 使用 set -e 来当有错误发生的时候 abort 执行 使用 set -o pipefail 来限制错误 使用 trap 来截获信号（如截获ctrl+c） 只调试部分脚本，在想要调试的脚本之前调用 set -x ，结束的时候调用 set +x 。如下所示： #!/bin/bash echo \"Hello $USER,\" set -x echo \"Today is $(date %Y-%m-%d)\" set +x var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"handy/misc/useful-snippets.html":{"url":"handy/misc/useful-snippets.html","title":"小知识点","keywords":"","body":" 随机端口范围：cat /proc/sys/net/ipv4/ip_local_port_range cpu 查看 物理cpu个数 grep \"physical id\" /proc/cpuinfo | sort -u | wc -l 核心数量 grep \"core id\" /proc/cpuinfo | sort -u | wc -l 逻辑cpu数量 grep \"processor\" /proc/cpuinfo | sort -u | wc -l var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"note/alg/":{"url":"note/alg/","title":"算法","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/alg/famous-balance-data-structure.html":{"url":"note/alg/famous-balance-data-structure.html","title":"常用平衡数据结构","keywords":"","body":"常用平衡数据结构 平衡二叉树 平衡二叉查找树，又称 AVL树。 它除了具备二叉查找树的基本特征之外，还具有一个非常重要的特点： 它的左子树和右子树都是平衡二叉树，且左子树和右子树的深度之差的绝对值（平衡因子）不超过1 也就是说AVL树每个节点的平衡因子只可能是-1、0和1（左子树高度减去右子树高度）。 B树 B树，又叫平衡多路查找树。每个节点都存储key和data，所有节点组成这棵树，并且叶子节点指针为null。一棵m阶的B树 (m叉树)的特性如下： 树中每个结点至多有m个孩子 除根结点和叶子结点外，其它每个结点至少有[m/2]个孩子 若根结点不是叶子结点，则至少有2个孩子 所有叶子结点都出现在同一层，叶子结点不包含任何关键字信息(可以看做是外部接点或查询失败的接点，实际上这些结点不存在，指向这些结点的指针都为null) 每个非终端结点中包含有n个关键字信息： (n，A0，K1，A1，K2，A2，......，Kn，An)。其中 Ki (i=1...n)为关键字，且关键字按顺序排序Ki Ai为指向子树根的接点，且指针A(i-1)指向子树种所有结点的关键字均小于Ki，但都大于K(i-1) 关键字的个数n必须满足： [m/2]-1 B+树 B+树，是应文件系统所需而产生的一种B树的变形树。只有叶子节点存储data，叶子节点包含了这棵树的所有键值，叶子节点不存储指针。一棵m阶的B+树和m阶的B-树的差异在于： 有n棵子树的结点中含有n个关键字（B树是n棵子树有n+1个关键字） 所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接。（B树的叶子节点并没有包括全部需要查找的信息） 所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。（B树的非终节点也包含需要查找的有效信息） B+树的优势所在： 由于B+树在内部节点上不包含数据信息，因此在内存页中能够存放更多的key。 数据存放的更加紧密，具有更好的空间局部性。因此访问叶子节点上关联的数据也具有更好的缓存命中率。 B+树的叶子结点都是相链的，因此对整棵树的便利只需要一次线性遍历叶子结点即可。而且由于数据顺序排列并且相连，所以便于区间查找和搜索。而B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。 为什么说B+树比B树更适合实际应用中操作系统的文件索引和数据库索引？ B+树的磁盘读写代价更低 B+树的查询效率更加稳定 实际上B+索引在数据库中有一个特点就是其高扇出性，因此在数据库中，B+树的高度一般不超过3层，也就是对于查找某一键值的行记录，最多只需要2到3次IO。现在一般的机械硬盘的IOPS在100～200之间，2～3次的IO意味着查询时间只需0.02～0.03秒，更有甚者，现在大多数企业都使用SSD固态硬盘，IOPS基本超过50000，查询效率进一步提升。 红黑树 R-B Tree，全称是Red-Black Tree，又称为“红黑树”，它一种特殊的二叉查找树。红黑树的每个节点上都有存储位表示节点的颜色，可以是红(Red)或黑(Black)。红黑树的特性: 每个节点或者是黑色，或者是红色 根节点是黑色 每个叶子节点（NIL）是黑色，为空(NIL或NULL)的叶子节点 如果一个节点是红色的，则它的子节点必须是黑色的 从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点 红黑树能够以O(log2(N))的时间复杂度进行搜索、插入、删除操作。此外，任何不平衡都会在3次旋转之内解决。这一点是AVL所不具备的。 红黑树相关定理 从根到叶子的最长的可能路径不多于最短的可能路径的两倍长 红黑树的树高(h)不大于两倍的红黑树的黑深度(bd) 一棵拥有n个内部结点(不包括叶子结点)的红黑树的树高h 实际应用中，很多语言都实现了红黑树的数据结构。比如 TreeMap, TreeSet(Java )、 STL(C++)等。 跳跃表（SkipList） 与SkipList对应的是红黑树，他们的功能一样，但在leveldb，hbase的hregion，以及redis的zset，在实现有序数据时，都采样了SkipList，主要的原因是考虑到并发性，红黑数在rebalance时需要lock，这个时间可能很长而且不确定(可能会影响到root node)，在并发环境下造成stop the world。而SkipList的并发性更好，因为在插入节点时，只影响与node相关的几个局部节点。插入、查找和删除操作都仅仅只需要O(log n)对数级别的时间复杂度。 跳表具有如下性质： 由很多层结构组成 每一层都是一个有序的链表 最底层(Level 1)的链表包含所有元素 如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素 跳表构造 给定一个有序的链表 选择连表中最大和最小的元素，然后从其他元素中按照一定算法（随机）随即选出一些元素，将这些元素组成有序链表。这个新的链表称为一层，原链表称为其下一层 为刚选出的每个元素添加一个指针域，这个指针指向下一层中值同自己相等的元素。Top指针指向该层首元素 重复2、3步，直到不再能选择出除最大最小元素以外的元素 跳表插入 使用随机算法，决策插入数据的“高度”，高度h的值由代码 h=1;while(rand()) h++;来决定（函数rand()，随机返回1或者0） 从高层至下插入，与普通链表的插入完全相同（先找到插入位置，然后插入） 伸展树 (splay tree) 伸展树（Splay Tree），也叫分裂树，是一种二叉排序树，它能在O(log n)内完成插入、查找和删除操作。它由Daniel Sleator和Robert Tarjan创造，后勃刚对其进行了改进。它的优势在于不需要记录用于平衡树的冗余信息。在伸展树上的一般操作都基于伸展操作。 伸展树的出发点是这样的：考虑到局部性原理（刚被访问的内容下次可能仍会被访问，查找次数多的内容可能下一次会被访问），为了使整个查找时间更小，被查频率高的那些节点应当经常处于靠近树根的位置。这样，很容易得想到以下这个方案：每次查找节点之后对树进行重构，把被查找的节点搬移到树根，这种自调整形式的二叉查找树就是伸展树。每次对伸展树进行操作后，它均会通过旋转的方法把被访问节点旋转到树根的位置。 Treap 同splay tree一样，treap也是一个平衡二叉树，不过Treap会记录一个额外的数据，即优先级。Treap在以关键码构成二叉搜索树的同时，还按优先级来满足堆的性质。因而，Treap=tree+heap。这里需要注意的是，Treap并不是二叉堆，二叉堆必须是完全二叉树，而Treap可以并不一定是。 为了使Treap 中的节点同时满足BST性质和最小堆性质，不可避免地要对其结构进行调整，调整方式被称为旋转。在维护Treap 的过程中，只有两种旋转，分别是左旋转(简称左旋)和右旋转(简称右旋)。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/arch/":{"url":"note/arch/","title":"架构","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/arch/note-on-ddia.html":{"url":"note/arch/note-on-ddia.html","title":"DDIA笔记","keywords":"","body":"可靠（reliable）、可扩展（saclable）、可维护（maintainable）系统背后的深刻思想 第一章 服务的两个指标 service level objectives (SLOs) service level agreements (SLAs) 可靠性 意味着系统在故障发生的时候仍能正常运行 可维护性 Operability: Making Life Easy for Operations Simplicity: Managing Complexity Evolvability: Making Change Easy 可扩展性 负载上升的时候，系统仍有办法保持较好的性能 好的抽象能降低系统的复杂性，使得系统更容易改造，以适用新的状况 第二章 schema-on-read： 数据结构是隐式的，只有数据在读取之后才能解释 schema-on-write：数据结构是显式的，如关系数据库 NoSQL 数据库有以下两种类型 文档形 Document databases，自包含的文档，文档之间很少有关系 图形 Graph databases：关系随意设置 第三章 log-structured 将数据库拆成变长的segment，通常有几M，并且顺序第写这些segment B-tree 将数据库拆成固定大小的blocks或pages，通常4KB，一次读写一个page，一个4层的4KB pages的 500 叉树，可以保持 256TB的数据 一般认为 LSM-trees 写快，B-trees 读快 Bloom filter 是一个基于内存的数据结构，用来近似一个集合里的内容，他能告诉你一个key在集合里是否不存在，用来节省比必要的磁盘IO 第四章 常用的文本格式：JSON XML CSV；二进制格式：Thrift, Protocol Buffers, and Avro web 服务有两种流行的方法： REST、SOAP。 REST emphasizes simple data formats, using URLs for identifying resources and using HTTP features for cache control, authentication, and content type negotiation SOAP is an XML-based protocol for making network API requests Finagle 和 Rest 使用 futures(promises) 来封装可能出错的异步调用。 异步的消息传输一般有两种：使用 messge brokers 或 actors。Actor 模型：每个 actor 实体（客户端）保存一些自己的状态，并且通过发送、接收异步消息和其他 actor 通讯 第五章 三种流行的复制模式 Single-leader replication：客户端将所有的写请求发送给leader，leader将数据变化事件流发送给follower。读请求可以在任意节点上执行，但从follower上可能会读到过期数据 semi-synchronous：半同步，至少有个一个follower 和 leader 的数据一致 Replication Lag 的问题：eventual consistency，最终一致性 脑裂 Multi-leader replication：客户端发送写请求到能接受写请求的某的一个leader，leader将数据变化事件流发送给follower 冲突解决 Leaderless replication：客户端将写请求发送给几个节点，从几个节点中同时读数据，并判断修正有过期数据的节点 quorum read/write sloppy quorum：读写仍有r/w个回复，但里面可能包括没有包含相应数据的节点 关于一致性 强一致性？？？ Read-after-write consistency：用户应该总能看到自己之前提交过的数据 Monotonic reads：用户看到某个时间点的数据后，他们不能读取到该时间点之前的数据 Consistent prefix reads：用户应该看到的数据应该符合因果关系，先看到问题后看到回答 复制的方法 statement-based replication：直接发SQL给从库 write-ahead log（WAL） shipping：被 PostgreSQL 和 Oracle 使用 Logical（row-based）log replication：Mysql binlog Trigger-based replication：Oracle GoldenGate 写冲突的解决 on write：写数据时候发现冲突，调用冲突解决方法，通常冲突不会告诉用户，后台默默解决 on read：检测到冲突后，所有的写冲突都被保存下来，当数据被读取时，应用通常告诉用户或自动地解决冲突，然后将结果写回数据库 常用冲突解决方法 每个 write 给一个唯一的ID（如时间戳，长随机数，UUID，kv 的hash值），选一个最大的ID写入，丢弃其他写。如果使用的是时间戳，即为last write wins (LWW)，该方法流行，但很危险 给每一个副本一个唯一的ID，有 higher- numbered 副本代替低lower- numbered副本，该方法也会丢数据 写入合并之后的数据，如按字母排序，并连接他们 用特殊的结构记录所有的冲突信息，后面再解决冲突 分布式系统的基本问题 节点宕机 不可靠的网络 副本间的权衡 一致性 持久性 可用性 延迟 第六章 partition 也叫 shard，目标是将数据和查询平均地分不到多台机器上，避免热点，主要有两种方法： key range partitioning：key是有序的，一个partition的key在一个区间范围内 hash partitioning：一个 partition有一个范围的hash key，数据无序，但数据更平均 一致性 hash，最初用来解决系统CDN缓存问题 如果一个 key 使用非常频繁，可以再key前或后加一个随机数 二级索引 secondary index通常不是唯一确定一条记录，还是用来查找包含某个值的所有记录，通常会通过异步的方式更新一个全局的二级索引 Document-partitioned indexes（local indexes）：二级索引存在partition本地，写快，读取时需要获取所有partition数据 Term-partitioned indexes（global indexes）：一个分区的索引可能需要访问其他分区的数据，写慢，读快（只需要从一个分区读） 第七章 ACID：Atomicity, Consistency, Isolation, Durablity BASE：Basically Available, Soft state, Eventual consistency Read Committed：最基本的隔离要求 ，无脏读写，只读到提交的数据，只覆盖写提交的数据。一般数据库采用行锁阻止脏写 Snapshot Isolation（也叫 Repeatable Read）：关键原则是读不能阻塞写，写不能阻塞读，一般使用multi-version concurrency control(MVCC)实现，更新操作被拆为delete 和create。oracle里的实现叫 serializable，pg和mysql里叫 repeatable read Serializable Isolation（可串行化隔离）一般被认为是最强的隔离级别，他保证并行执行的时候，意味着数据库保证事务运行的效果和串行运行的一样（一次一个，没有并行），通常有三个方法实现 字面上顺序执行事务：悲观至极锁，在一个CPU上，吞吐量小，VoltDB/H-Store、Redis、Datomic Two-phase Locking(2PL)：悲观锁，对锁进行分类，分出共享锁（读锁）和排它锁（写锁），标准方式，性能不好，Mysql(InnoDB)，SQL Server shared-mode exclusive-mode Seriazable Snapshot Isolation SSI，乐观锁，非常新的算法，允许事务无阻塞地执行，当想提交事务时，如果执行不是可串行化的则终止。和2PL相比，SSI的优点是一个事务不必因另一个事务阻塞；和并行处理相比，SSI不受限于一个CPUcore，FoundationDB通过检测多台机器上的冲突，从而获取了非常大的吞吐量 Read skew (nonrepeatable reads)：客户在不同的时间看到不同部分的数据。使用Snapshot Isolation能避免这个问题，通常使用MVCC实现 Write skew：事务读数据、处理、然后写回数据库，但在写库时，写入的数据不符合数据约束了，只有Serializable isolation能避免这个 Phantom reads：事务读取符合某些搜索条件的对象，另一个客户写入了影响搜索结果的数据。Snapshot isolation 避免了这个，但是对于write skew 下的phantoms需要特殊处理，如index-range locks. 第八章 网络拥塞、排队、延迟总会发生 使用公网上的NTP服务，最好的延迟时间精确度是10万之一秒 Java GC通常会停止整个线程 大多数拜占庭算法要求2/3的节点存活 通常UDP TCP的校验能检查出错误来，但有时也不行 第九章 evnentual consistency：意味着如果停止写数据库，一段时间之后，所有的读请求都返回同样的结果 分布式一致性主要是在有延迟、故障情况下协调多个副本的状态问题 This is the idea behind linearizability(also known as atomic consistency, strong consistency, immediate consistency, or external consistency). Serializability：可序列化，保证事务的执行像按某种顺序一个一个执行一样 Linearizability：是一个最近的关于读写一个寄存器的保证，他没有把一组操作当做事务处理，避免不了 write skew，本质上意味着只有一份数据，其上的所有的操作都是原子的 serial execution和2PL 都是 Linearizability，SSI 不是 Linearizability 的 CAP更好的理解，当网络故障发生的时候，只能选择 linearizability 或者 total availability；或者说，当发生Partitioned时候，只能选择 Consistent 或者Available 放弃 linearizability 的原因是 performanc，而不是fault tolerance a total order and a partial order： 在 Linearizability 系统中，是total order的，所有的操作都有序 Causality，是partial order的，某些操作是可以并行的 可以证明 linearizable compare-and-set register 和 total order broadcast 和 consensus 是等价的 补偿性事务 2PC：在一个分布式数据库中提供了 atomic commit；2PL 提供了 Serialization Isolation；2PC 有故障时只能等待协调者恢复 Termination is a liveness property, whereas the other three are safety properties The best-known fault-tolerant consensus algorithms are Viewstamped Replication (VSR) Paxos， Raft and Zab 第十章 shuffle 洗牌 sort-merge join 第十一章 如果发送者的发送速度大于消费者的消费速度，系统可以丢掉消息或者在队列里缓存消息或者使用backpressure（流量控制），Unix pipes and TCP use backpressure event sourcing 和 change data capture 最大的缺点是他们的消费者通常都是异步的 第十二章 在分布式事务协议的本质上，我认为log-based derived data 是最有前途的集成系统的方法 通常，建立一个完全有序的日志，需要所有的事件都经由一个leader来处理，如果吞吐量超过一台机器的处理量，需要使用多台机器分区处理 当数据跨过各种技术边界时，我认为基于 dempotent writes 的 asynchronous event log是一个更具鲁棒性和实用性的方法 系统从 request/ response 交互到 publish/subscribe dataflow 我们假设数据写入磁盘在fsync后不会丢失，内存中的数据不会损坏，CPU总会返回正确的执行结果 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/arch/ddia-1.html":{"url":"note/arch/ddia-1.html","title":"DDIA笔记1","keywords":"","body":" 第一章：可靠性，可扩展性，可维护性 可靠性 可扩展性 可维护性 第二章：数据模型与查询语言 第三章 存储与检索 两大类存储引擎 常用索引 第四章 编码与演化 编码数据的格式 服务中的数据流 第一章：可靠性，可扩展性，可维护性 可靠性 故障（fault）不同于失效（failure）。故障通常定义为系统的一部分状态偏离其标准，而失效则是系统作为一个整体停止向用户提供服务。故障的概率不可能降到零，因此最好设计容错机制以防因故障而导致失效。 硬盘的平均无故障时间（MTTF, mean time to failure）约为10到50年，从数学期望上讲，10000个磁盘平均每天会有1个磁盘出故障。 可扩展性 性能指标 对于批处理系统，通常关心的是吞吐量（throughput），即每秒可以处理的记录数量，或者在特定规模数据集上运行作业的总时间；对于在线系统，通常更重要的是服务的响应时间（response time），即客户端发送请求到接收响应之间的时间。 延迟（latency）和响应时间（response time）经常用作同义词，但实际上它们并不一样。响应时间是客户所看到的，除了实际处理请求的服务时间（service time）之外，还包括网络延迟和排队延迟；延迟是某个请求等待处理的持续时长，在此期间它处于休眠（latent）状态，并等待服务。 性能描述 通常使用百分位点（percentiles）比平均值更好，常用的有中位数（median）、95%、99%、99.9%（p50, p95, p99, p999）；百分位点通常用于服务级别目标（SLO, service level objectives）和服务级别协议（SLA, service level agreements），即定义服务预期性能和可用性的合同。 响应时间的高百分位点，尾部延迟（tail latencies）非常重要，因为他们直接影响用户的服务体验。例如亚马逊在描述内部服务的响应时间要求时以99.9百分位点为准，即使它只影响一千个请求中的一个。另一方面，优化第99.99百分位点（一万个请求中最慢的一个）被认为太昂贵。 排队延迟（queueing delay）通常占了高百分位点处响应时间的很大一部分。由于服务器只能并行处理少量的事务（如受其CPU核数的限制），所以只要有少量缓慢的请求就能阻碍后续请求的处理，这种效应有时被称为头部阻塞（head-of-line blocking）。 纵向扩展（scaling up）或垂直扩展（vertical scaling），转向更强大的机器；横向扩展（scaling out）或水平扩展（horizontal scaling），将负载分布到多台小机器上之间的对立。 一个良好适配应用的可扩展架构，是围绕着假设（assumption）建立的：哪些操作是常见的？哪些操作是罕见的？这就是所谓负载参数。如果假设最终是错误的，那么为扩展所做的工程投入就白费了，最糟糕的是适得其反。 可维护性 软件系统的三个设计原则 可操作性（Operability）便于运维团队保持系统平稳运行。如良好的监控，自动化运维支持，良好的文档，易于理解的操作模型，良好的默认行为，有条件的自我修复，行为可预测等。 简单性（Simplicity）从系统中消除尽可能多的复杂度（complexity），使新工程师也能轻松理解系统。复杂度（complexity）有各种可能的症状，如状态空间激增、模块间紧密耦合、纠结的依赖关系、不一致的命名和术语、解决性能问题的Hack、需要绕开的特例等用于消除额外复杂度的最好工具之一是抽象（abstraction）。一个好的抽象可以将大量实现细节隐藏在一个干净、简单易懂的外观下。 可演化性（evolability）使工程师在未来能轻松地对系统进行更改，当需求变化时为新应用场景做适配。也称为可扩展性（extensibility），可修改性（modifiability）或可塑性（plasticity）。 第二章：数据模型与查询语言 在历史上，数据最开始被表示为一棵大树（层次数据模型），但是这不利于表示多对多的关系，所以发明了关系模型来解决这个问题。新的非关系型“NoSQL”数据存储在两个主要方向上存在分歧： 文档数据库：数据通常是自我包含的，而且文档之间的关系非常稀少。 图形数据库：任意事物都可能与任何事物相关联。 文档数据库和图数据库有一个共同点：它们通常不会为存储的数据强制一个模式，这使应用程序更容易适应不断变化的需求。但是应用程序很可能仍会假定数据具有一定的结构；这只是模式是明确的（写入时强制）还是隐含的（读取时处理）的问题。 MySQL是一个值得注意的例外，它执行ALTER TABLE时会复制整个表（可以使用测试数据执行，查看 affected rows，淘宝、腾讯、fb都有辅助工具），这可能意味着在更改一个大型表时会花费几分钟甚至几个小时的停机时间。 第三章 存储与检索 两大类存储引擎 事务处理（OLTP）：通常面向用户，这意味着他们可能会看到大量的请求。为了处理负载，应用程序通常只触及每个查询中的少量记录。应用程序使用某种键来请求记录，存储引擎使用索引来查找所请求的键的数据。磁盘寻道时间往往是这里的瓶颈。 优化分析（OLAP）：主要由业务分析人员使用，而不是由最终用户使用。它们处理比OLTP系统少得多的查询量，但是每个查询通常要求很高，需要在短时间内扫描数百万条记录。磁盘带宽（不是查找时间）往往是瓶颈，列式存储是这种工作负载越来越流行的解决方案。 常用索引 哈希索引 键值存储与在大多数编程语言中可以找到的字典（dictionary）类型非常相似，通常字典都是用散列映射（hash map）或哈希表（hash table）实现的。 OLTP日志结构学派 只允许附加到文件和删除过时的文件，但不会更新已经写入的文件。 Bitcask，SSTables（Sorted Strings Table），LSM树（Log-structured merge-tree），LevelDB，Cassandra，HBase，Lucene等都属于这个组。日志结构的存储引擎是相对较新的发展。他们的主要想法是，系统地将随机访问写入顺序写入磁盘，由于硬盘驱动器和固态硬盘的性能特点，可以实现更高的写入吞吐量。 如何避免最终用完磁盘空间？一种好的解决方案是，将日志分为特定大小的段，当日志增长到特定尺寸时关闭当前段文件，并开始写入一个新的段文件。然后，我们就可以对这些段进行压缩（compaction，压缩意味着在日志中丢弃重复的键，只保留每个键的最近更新） SSTable提供一个可持久化[persistent]，有序的、不可变的从键到值的映射关系，其中键和值都是任意字节长度的字符串。SSTable提供了以下操作：按照某个键来查询关联值，可以指定键的范围，来遍历其中所有的键值对。每个SSTable内部由一系列块（block）组成（通常每块大小为64KB，是可配置的）。使用存储在SSTable结尾的块索引（block index）来定位块；当SSTable打开时，索引会被加载到内存里。一次磁盘寻道（disk seek）就可以完成查询（lookup）操作：首先通过二分查找在存储在内存的索引中找到对应的块，然后从磁盘上读取这块内容。SSTable也可以完整地映射到内存里，这样在执行查询和扫描（scan）的时候就不用操作磁盘了。 LSM树原理把一棵大树拆分成N棵小树，它首先写入内存中，随着小树越来越大，内存中的小树会flush到磁盘中，磁盘中的树定期可以做merge操作，合并成一棵大树，以优化读性能。 用SSTables制作LSM树 写入时，将其添加到内存中的平衡树数据结构（例如，红黑树（nginx的timer，epool内核实现，的linux进程调度Completely Fair Scheduler，stl的map）、跳表（leveldb、redis））。这个内存树有时被称为内存表（memtable） 当内存表大于某个阈值（通常为几兆字节）时，将其作为SSTable文件写入磁盘 为了提供读取请求，首先尝试在内存表中找到关键字，然后在最近的磁盘段中，然后在下一个较旧的段中找到该关键字 有时会在后台运行合并和压缩过程以组合段文件并丢弃覆盖或删除的值 如果数据库崩溃，则最近的写入（在内存表中，但尚未写入磁盘）将丢失。为了避免这个问题，可以在磁盘上保存一个单独的日志，每个写入都会立即被附加到磁盘上，每当内存表写出到SSTable时，相应的日志都可以被丢弃。 大量的细节使得存储引擎在实践中表现良好。但当查找数据库中不存在的键时，LSM树算法可能会很慢：您必须检查内存表，然后将这些段一直回到最老的（可能必须从磁盘读取每一个，然后才能确定键不存在）。为了优化这种访问，存储引擎通常使用额外的Bloom过滤器。 OLTP就地更新学派 将磁盘视为一组可以覆盖的固定大小的页面。 B树是这种哲学的最大的例子，被用在所有主要的关系数据库中，还有许多非关系数据库。 B树将数据库分解成固定大小的块或页面，传统上大小为4KB（有时会更大），并且一次只能读取或写入一个页面。这种设计更接近于底层硬件，因为磁盘也被安排在固定大小的块中。 大多数数据库可以放入一个三到四层的B树，所以你不需要遵追踪多页面引用来找到你正在查找的页面。（分支因子为 500 的 4KB 页面的四级树可以存储多达 256TB）。 为了使数据库对崩溃具有韧性，B树实现通常会带有一个额外的磁盘数据结构：预写式日志（WAL, write-ahead-log），也称为重做日志（redo log）。这是一个仅追加的文件，每个B树修改都可以应用到树本身的页面上。当数据库在崩溃后恢复时，这个日志被用来使B树恢复到一致的状态 反直觉的是，内存数据库的性能优势并不是因为它们不需要从磁盘读取的事实。即使是基于磁盘的存储引擎也可能永远不需要从磁盘读取，因为操作系统缓存最近在内存中使用了磁盘块。相反，它们更快的原因在于省去了将内存数据结构编码为磁盘数据结构的开销。 其他索引结构 索引中的关键字是查询搜索的内容，如果值是实际行（文档，顶点）在别处的引用，行被存储的地方被称为堆文件（heap file），并且存储的数据没有特定的顺序（它可以是仅附加的，或者可以跟踪被删除的行以便用新数据覆盖它们后来）。 在某些情况下，从索引到堆文件的额外跳跃对读取来说性能损失太大，因此可能希望将索引行直接存储在索引中。这被称为聚集索引。例如，在MySQL的InnoDB存储引擎中，表的主键总是一个聚簇索引，二级索引用主键（而不是堆文件中的位置）。 在聚集索引（clustered index）（在索引中存储所有行数据）和非聚集索引（nonclustered index）（仅在索引中存储对数据的引用）之间的折衷被称为包含列的索引（index with included columns）或覆盖索引（covering index），其存储表的一部分在索引内。这允许通过单独使用索引来回答一些查询（这种情况叫做索引覆盖了查询）。 列存储 列存储在关系数据模型中是最容易理解的，但它同样适用于非关系数据。例如，Parquet是一种列式存储格式，支持基于Google的Dremel 的文档数据模型。面向列的存储布局依赖于包含相同顺序行的每个列文件。 因此，如果您需要重新组装整行，您可以从每个单独的列文件中获取第23项，并将它们放在一起形成表的第23行。 列压缩：一列中不同值的数量与行数相比较小（例如，零售商可能有数十亿的销售交易，但只有100,000个不同的产品）。现在我们可以得到一个有 n 个不同值的列，并把它转换成 n 个独立的位图：每个不同值的一个位图，每行一位。如果该行具有该值，则该位为 1 ，否则为 0 。 比较B树和LSM树 存取速度 LSM树的写入速度更快，但读取通常比较慢，因为它们必须在压缩的不同阶段检查几个不同的数据结构和SSTables。 B树的读取速度更快，但写入慢，B树索引必须至少两次写入每一段数据：一次写入预先写入日志，一次写入树页面本身（也许再次分页），即使在该页面中只有几个字节发生了变化，也需要一次编写整个页面的开销。有些存储引擎甚至会覆盖同一个页面两次，以免在电源故障的情况下导致页面部分更新。 空间开销 LSM树可以被压缩得更好，因此经常比B树在磁盘上产生更小的文件。由于LSM树不是面向页面的，并且定期重写SSTables以去除碎片，所以它们具有较低的存储开销。 B树存储引擎会由于分割而留下一些未使用的磁盘空间：当页面被拆分或某行不能放入现有页面时，页面中的某些空间仍未被使用。 吞吐量 由于反复压缩和合并SSTables，日志结构索引也会重写数据。这种影响在数据库的生命周期中写入数据库导致对磁盘的多次写入被称为写放大（write amplification）LSM树通常能够比B树支持更高的写入吞吐量，部分原因是它们有时具有较低的写放大。 其他 B树的一个优点是每个键只存在于索引中的一个位置，而日志结构化的存储引擎可能在不同的段中有相同键的多个副本。这个方面使得B树在想要提供强大的事务语义的数据库中很有吸引力：在许多关系数据库中，事务隔离是通过在键范围上使用锁来实现的，在B树索引中，这些锁可以直接连接到树。 日志结构存储的缺点是压缩过程有时会干扰正在进行的读写操作。尽管存储引擎尝试逐步执行压缩而不影响并发访问，但是磁盘资源有限，所以很容易发生请求需要等待而磁盘完成昂贵的压缩操作。对吞吐量和平均响应时间的影响通常很小，但是在更高百分比的情况下，对日志结构化存储引擎的查询响应时间有时会相当长，而B树的行为则相对更具可预测性。 压缩的另一个问题出现在高写入吞吐量：磁盘的有限写入带宽需要在初始写入（记录和刷新内存表到磁盘）和在后台运行的压缩线程之间共享。写入空数据库时，可以使用全磁盘带宽进行初始写入，但数据库越大，压缩所需的磁盘带宽就越多。 第四章 编码与演化 编码数据的格式 向后兼容 （backward compatibility）：新代码可以读旧数据；向前兼容 （forward compatibility）：旧代码可以读新数据。 JSON，XML，Protocol Buffers，Thrift 和 Avro 编码（Encoding）、序列化（serialization）、编组（marshalling）；反过来称为解码（Decoding、解析（Parsing）、反序列化（deserialization）、反编组unmarshalling） REST （json）和 SOAP（xml） 服务中的数据流 在Web服务中，具象状态传输（REST）和远程过程调用（RPC），以及消息传递系统（如Actor和消息队列） RPC 模型试图向远程网络服务发出请求，看起来与在同一进程中调用编程语言中的函数或方法相同（这种抽象称为位置透明）。尽管RPC起初看起来很方便，但这种方法根本上是有缺陷的。网络请求与本地函数调用非常不同。 本地函数调用是可预测的，并且成功或失败，这仅取决于受您控制的参数。网络请求是不可预知的。 本地函数调用要么返回结果，要么抛出异常，或者永远不返回（因为进入无限循环或进程崩溃）。网络请求有另一个可能的结果：由于超时，它可能会返回没有结果。 如果您重试失败的网络请求，可能会发生请求实际上正在通过，只有响应丢失。在这种情况下，重试将导致该操作被执行多次，除非在协议中引入除重机制，本地函数调用没有这个问题。 每次调用本地功能时，通常需要大致相同的时间来执行。网络请求比函数调用要慢得多，而且其延迟也是非常可变的。 调用本地函数时，可以高效地将引用（指针）传递给本地内存中的对象。当你发出一个网络请求时，所有这些参数都需要被编码成可以通过网络发送的一系列字节。没关系，如果参数是像数字或字符串这样的基本类型，但是对于较大的对象很快就会变成问题。 使用消息队列，如RabbitMQ，ActiveMQ，HornetQ，NATS和Apache Kafka，与RPC相比，差异在于消息传递通信通常是单向的：发送者通常不期望收到其消息的回复。一个进程可能发送一个响应，但这通常是在一个单独的通道上完成的。这种通信模式是异步的：发送者不会等待消息被传递，而只是发送它，然后忘记它 Actor 模型是单个进程中并发的编程模型。逻辑被封装在角色中，而不是直接处理线程（以及竞争条件，锁定和死锁的相关问题）。每个角色通常代表一个客户或实体，它可能有一些本地状态（不与其他任何角色共享），它通过发送和接收异步消息与其他角色通信。消息传送不保证：在某些错误情况下，消息将丢失。由于每个角色一次只能处理一条消息，因此不需要担心线程，每个角色可以由框架独立调度。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/arch/ddia-2.html":{"url":"note/arch/ddia-2.html","title":"DDIA笔记2","keywords":"","body":" 第五章 复制 领导者与追随者 同步复制 vs 异步复制 复制日志 复制延迟（一致性读） 多主复制 无主复制 第六章 分区 根据键的范围分区 根据键的散列分区 分区再平衡 请求路由：服务发现 第七章 事务 隔离 第五章 复制 领导者与追随者 副本之一被指定为领导者（leader），也称为主库（master） ，首要（primary）。当客户端要向数据库写入时，它必须将请求发送给领导者，领导者会将新数据写入其本地存储。 其他副本被称为追随者（followers），亦称为只读副本（read replicas），从库（slaves），次要（ sencondaries），热备（hot-standby）。每当领导者将新数据写入本地存储时，它也会将数据变更发送给所有的追随者，称之为复制日志（replication log）记录或变更流（change stream）。 当客户想要从数据库中读取数据时，它可以向领导者或追随者查询。 但只有领导者才能接受写操作（从客户端的角度来看从库都是只读的）。 不同的人对热（hot），温（warn），冷（cold） 备份服务器有不同的定义。 例如在PostgreSQL中，热备（hot standby）指的是能接受客户端读请求的副本。而温备（warm standby）只是追随领导者，但不处理客户端的任何查询。 同步复制 vs 异步复制 将所有从库都设置为同步的是不切实际的：任何一个节点的中断都会导致整个系统停滞不前。 如果在数据库上启用同步复制，通常意味着其中一个跟随者是同步的，而其他的则是异步的。如果同步从库变得不可用或缓慢，则使一个异步从库同步。这保证至少在两个节点上拥有最新的数据副本：主库和同步从库。 这种配置有时也被称为半同步（semi-synchronous）。 对于异步复制系统而言，主库故障时有可能丢失数据。这可能是一个严重的问题，因此研究人员仍在研究不丢数据但仍能提供良好性能和可用性的复制方法。 例如，链式复制是同步复制的一种变体，已经在一些系统（如Microsoft Azure存储）中成功实现。 复制日志 基于语句（statement）的复制：主库记录下它执行的每个写入请求（语句（statement））并将该语句日志发送给其从库。 预写式日志（Write Ahead Log, WAL）： 对于日志结构存储引擎，日志是主要的存储位置。日志段在后台压缩，并进行垃圾回收。对于覆写单个磁盘块的B树，每次修改都会先写入预写式日志（WAL），以便崩溃后索引可以恢复到一个一致的状态。日志都是包含所有数据库写入的仅追加字节序列。可以使用完全相同的日志在另一个节点上构建副本：除了将日志写入磁盘之外，主库还可以通过网络将其发送给其从库。 逻辑日志复制（基于行）：复制和存储引擎使用不同的日志格式，这样可以使复制日志从存储引擎内部分离出来。这种复制日志被称为逻辑日志，以将其与存储引擎的（物理）数据表示区分开来。 基于触发器的复制：触发器允许您注册在数据库系统中发生数据更改（写入事务）时自动执行的自定义应用程序代码。触发器有机会将更改记录到一个单独的表中，使用外部程序读取这个表，再加上任何业务逻辑处理，会后将数据变更复制到另一个系统去。例如，Databus for Oracle和Bucardo for Postgres。 复制延迟（一致性读） 读己之写： 读写一致性（read-after-write consistency），也称为读己之写一致性（read-your-writes consistency），实现技术很多，如： 都从主库读 以跟踪上次更新的时间，在上次更新后的一分钟内，从主库读。还可以监控从库的复制延迟，防止任向任何滞后超过一分钟到底从库发出查询 客户端可以记住最近一次写入的时间戳，系统需要确保从库为该用户提供任何查询时，该时间戳前的变更都已经传播到了本从库中。如果当前从库不够新，则可以从另一个从库读，或者等待从库追赶上来，时间戳可以是逻辑时间戳（指示写入顺序的东西，例如日志序列号）或实际系统时钟（在这种情况下，时钟同步变得至关重要） 单调读（Monotonic reads） 比强一致性（strong consistency）更弱，但比最终一致性（eventually consistency）更强的保证，不会看到时间倒退 一种方式是确保每个用户总是从同一个副本进行读取 一致前缀读（consistent prefix reads）：如果一系列写入按某个顺序发生，那么任何人读取这些写入时，也会看见它们以同样的顺序出现 不一致前缀读，是分区（partitioned）（分片（sharded））数据库中的一个特殊问题。如果数据库总是以相同的顺序应用写入，则读取总是会看到一致的前缀，所以这种异常不会发生。但是在许多分布式数据库中，不同的分区独立运行，因此不存在全局写入顺序：当用户从数据库中读取数据时，可能会看到数据库的某些部分处于较旧的状态，而某些处于较新的状态。 多主复制 最大问题是可能发生写冲突 同步与异步冲突检测：可能会失去多主的优势 冲突避免：处理冲突的最简单的策略就是避免它们 收敛至一致的状态：单主数据库按顺序应用写操作：如果同一个字段有多个更新，则最后一个写操作将确定该字段的最终值 给每个写入一个唯一的ID（例如，一个时间戳，一个长的随机数，一个UUID或者一个键和值的哈希），挑选最高ID的写入作为胜利者 为每个副本分配一个唯一的ID，ID编号更高的写入具有更高的优先级 以某种方式将这些值合并在一起 在保留所有信息的显式数据结构中记录冲突，并编写解决冲突的应用程序代码（也许通过提示用户的方式） 无主复制 如果有n个副本，每个写入必须由w节点确认才能被认为是成功的，并且我们必须至少为每个读取查询 r 个节点，只要 $w + r > n$ 尽管法定人数似乎保证读取返回最新的写入值，但在实践中并不那么简单。 Dynamo风格的数据库通常针对可以忍受最终一致性的用例进行优化。允许通过参数w和r来调整读取陈旧值的概率，但把它们当成绝对的保证是不明智的 即使在 $w + r> n$ 的情况下，也可能存在返回陈旧值的边缘情况，取决于实现，包括： 使用松散的法定人数（sloppy quorum，写入指定n节点之外的节点） 和带提示的接力（hinted handoff） 如果两个写入同时发生，不清楚哪一个先发生。在这种情况下，唯一安全的解决方案是合并并发写入，数据丢失 读和写同时发生，不确认读的是新值还是旧值 没有写成 w 个副本，有的成功了，但没回滚 有时也会不幸地出现关于时序（timing）的边缘 第六章 分区 分区（partitions），也称为分片（sharding），分区主要是为了可扩展性。不同的分区可以放在不共享集群中的不同节点上。 根据键的范围分区 键是有序的，并且分区拥有从某个最小值到某个最大值的所有键。排序的优势在于可以进行有效的范围查询，但是如果应用程序经常访问相邻的主键，则存在热点的风险。这种方法中，当分区变得太大时，通常将分区分成两个子分区，动态地再平衡分区。 根据键的散列分区 散列函数应用于每个键，分区拥有一定范围的散列。这种方法破坏了键的排序，使得范围查询效率低下，但可以更均匀地分配负载。 散列函数不需要多么强壮的加密算法：例如，Cassandra和MongoDB使用MD5，Voldemort使用Fowler-Noll-Vo函数 一致性哈希由Karger等人定义。用于跨互联网级别的缓存系统，例如CDN中，是一种能均匀分配负载的方法。它使用随机选择的分区边界（partition boundaries）来避免中央控制或分布式一致性的需要，描述了重新平衡的特定方法 负载倾斜与消除热点，主键后加随机数，但读会更复杂 有两种用二级索引对数据库进行分区的方法：基于文档的分区（document-based）和基于关键词（term-based）的分区。 按文档的二级索引 每个分区是完全独立的：每个分区维护自己的二级索引，仅覆盖该分区中的文档。它不关心存储在其他分区的数据。文档分区索引也被称为本地索引（local index）。 如果要搜索，则需要将查询发送到所有分区，并合并所有返回的结果。这种查询分区数据库的方法有时被称为分散/聚集（scatter/gather），并且可能会使二级索引上的读取查询相当昂贵。 MonDBDB，Riak ，Cassandra ，Elasticsearch ，SolrCloud 和VoltDB 都使用文档分区二级索引 根据关键词（Term）的二级索引 一个覆盖所有分区数据的全局索引 关键词分区的全局索引优于文档分区索引的地方点是它可以使读取更有效率：不需要分散/收集所有分区，客户端只需要向包含关键词的分区发出请求。全局索引的缺点在于写入速度较慢且较为复杂，因为写入单个文档现在可能会影响索引的多个分区 分区再平衡 将负载从集群中的一个节点向另一个节点移动的过程称为再平衡（reblancing） 要求 再平衡之后，负载（数据存储，读取和写入请求）应该在集群中的节点之间公平地共享。 再平衡发生时，数据库应该继续接受读取和写入。 节点之间只移动必须的数据，以便快速再平衡，并减少网络和磁盘I/O负载。 常见策略 反面教材：hash mod N，如果节点数量N发生变化，大多数密钥将需要从一个节点移动到另一个节点 固定数量的分区：创建比节点更多的分区，并为每个节点分配多个分区。例如，运行在10个节点的集群上的数据库可能会从一开始就被拆分为1,000个分区，因此大约有100个分区被分配给每个节点。缺点：如果数据集的总大小难以预估（例如，如果它开始很小，但随着时间的推移可能会变得更大），选择正确的分区数是困难的。分区过多时，分区管理也会耗费过多的资源。 动态分区：当分区增长到超过配置的大小时（在HBase上，默认值是10GB），会被分成两个分区，每个分区约占一半的数据。与之相反，如果大量数据被删除并且分区缩小到某个阈值以下，则可以将其与相邻分区合并。动态分区的一个优点是分区数量适应总数据量。如果只有少量的数据，少量的分区就足够了，所以开销很小，如果有大量的数据，每个分区的大小被限制在一个可配置的最大值。动态分区和固定分区两种方法搭配使用也是可行的，例如使用复合主键：使用键的一部分来标识分区，而使用另一部分作为排序顺序。 按节点比例分区。通过动态分区，分区的数量与数据集的大小成正比，因为拆分和合并过程将每个分区的大小保持在固定的最小值和最大值之间。另一方面，对于固定数量的分区，每个分区的大小与数据集的大小成正比。在这两种情况下，分区的数量都与节点的数量无关。 Cassandra和Ketama使用的第三种方法是使分区数与节点数成正比——换句话说，每个节点具有固定数量的分区。当一个新节点加入集群时，它随机选择固定数量的现有分区进行拆分，然后占有这些拆分分区中每个分区的一半，同时将每个分区的另一半留在原地。 请求路由：服务发现 允许客户联系任何节点（例如，通过循环策略的负载均衡（Round-Robin Load Balancer））。如果该节点恰巧拥有请求的分区，则它可以直接处理该请求；否则，它将请求转发到适当的节点，接收回复并传递给客户端。 首先将所有来自客户端的请求发送到路由层，它决定了应该处理请求的节点，并相应地转发。此路由层本身不处理任何请求；它仅负责分区的负载均衡。 要求客户端知道分区和节点的分配。在这种情况下，客户端可以直接连接到适当的节点，而不需要任何中介。 第七章 事务 在数据系统的残酷现实中，很多事情都可能出错： 数据库软件、硬件可能在任意时刻发生故障（包括写操作进行到一半时）。 应用程序可能在任意时刻崩溃（包括一系列操作的中间）。 网络中断可能会意外切断数据库与应用的连接，或数据库之间的连接。 多个客户端可能会同时写入数据库，覆盖彼此的更改。 客户端可能读取到无意义的数据，因为数据只更新了一部分。 客户之间的竞争条件可能导致令人惊讶的错误。 事务是应用程序将多个读写操作组合成一个逻辑单元的一种方式。从概念上讲，事务中的所有读写操作被视作单个操作来执行：整个事务要么成功（提交（commit））要么失败（中止（abort），回滚（rollback））事务是一个抽象层，允许应用程序假装某些并发问题和某些类型的硬件和软件故障不存在。各式各样的错误被简化为一种简单情况：事务中止（transaction abort），而应用需要的仅仅是重试。 事务所提供的安全保证，通常由众所周知的首字母缩略词ACID来描述，ACID代表原子性（Atomicity），一致性（Consistency），隔离性（Isolation）和持久性（Durability）。高层次上的想法是合理的，但魔鬼隐藏在细节里。今天，当一个系统声称自己“符合ACID”时，实际上能期待的是什么保证并不清楚。 不符合ACID标准的系统有时被称为BASE，它代表基本可用性（Basically Available），软状态（Soft State）和最终一致性（Eventual consistency） 原子性的定义特征是：能够在错误时中止事务，丢弃该事务进行的所有写入变更的能力。 或许 可中止性（abortability） 是更好的术语 在ACID的上下文中，一致性是指数据库在应用程序的特定概念中处于“良好状态”，在CAP定理中，一致性一词用于表示可线性化；副本一致性，以及异步复制系统中的最终一致性问题；一致性哈希 ACID意义上的隔离性意味着，同时执行的事务是相互隔离的：它们不能相互冒犯。传统的数据库教科书将隔离性形式化为可序列化（Serializability），这意味着每个事务可以假装它是唯一在整个数据库上运行的事务。在Oracle中有一个名为“可序列化”的隔离级别，但实际上它实现了一种叫做快照隔离（snapshot isolation） 的功能，这是一种比可序列化更弱的保证 持久性 是一个承诺，即一旦事务成功完成，即使发生硬件故障或数据库崩溃，写入的任何数据也不会丢失。在历史上，持久性意味着写入归档磁带。后来它被理解为写入硬盘或SSD，最近它已经适应了“复制（replication）”的新内涵 如果你写入磁盘然后机器宕机，即使数据没有丢失，在修复机器或将磁盘转移到其他机器之前，也是无法访问的。这种情况下，复制系统可以保持可用性。 一个相关性故障（停电，或一个特定输入导致所有节点崩溃的Bug）可能会一次性摧毁所有副本，任何仅存储在内存中的数据都会丢失，故内存数据库仍然要和磁盘写入打交道。 在异步复制系统中，当主库不可用时，最近的写入操作可能会丢失。 当电源突然断电时，特别是固态硬盘，有证据显示有时会违反应有的保证：甚至fsync也不能保证正常工作。硬盘固件可能有错误，就像任何其他类型的软件一样。 存储引擎和文件系统之间的微妙交互可能会导致难以追踪的错误，并可能导致磁盘上的文件在崩溃后被损坏。 磁盘上的数据可能会在没有检测到的情况下逐渐损坏。如果数据已损坏一段时间，副本和最近的备份也可能损坏。这种情况下，需要尝试从历史备份中恢复数据。 一项关于固态硬盘的研究发现，在运行的前四年中，30％到80％的硬盘会产生至少一个坏块。相比固态硬盘，磁盘的坏道率较低，但完全失效的概率更高。 如果SSD断电，可能会在几周内开始丢失数据，具体取决于温度。 隔离 弱隔离级别（不可串行化（nonserializable））：数据库一直试图通过提供事务隔离（transaction isolation） 来隐藏应用程序开发者的并发问题。从理论上讲，隔离可以通过假装没有并发发生，让你的生活更加轻松：可序列化（serializable） 的隔离等级意味着数据库保证事务的效果与连续运行（即一次一个，没有任何并发）是一样的。 读已提交（Read Committed） 从数据库读时，只能看到已提交的数据（没有脏读（dirty reads）），写入数据库时，只会覆盖已经写入的数据（没有脏写（dirty writes））。某些数据库支持甚至更弱的隔离级别，称为读未提交（Read uncommitted）。它可以防止脏写，但不防止脏读。 读已提交是一个非常流行的隔离级别。这是Oracle 11g，PostgreSQL，SQL Server 2012，MemSQL和其他许多数据库的默认设置。 最常见的情况是，数据库通过使用行锁（row-level lock） 来防止脏写，但由于性能原因，大多数数据库对于写入的每个对象，数据库都会记住旧的已提交值，和由当前持有写入锁的事务设置的新值。 当事务正在进行时，任何其他读取对象的事务都会拿到旧值。 只有当新值提交后，事务才会切换到读取新值。 快照隔离和可重复读 快照隔离是一个有用的隔离级别，特别对于只读事务而言。但是，许多数据库实现了它，却用不同的名字来称呼。在Oracle中称为可序列化（Serializable）的，在PostgreSQL和MySQL中称为可重复读（repeatable read） 快照隔离的实现通常使用写锁来防止脏写，这意味着进行写入的事务会阻止另一个事务修改同一个对象。但是读取不需要任何锁定。从性能的角度来看，快照隔离的一个关键原则是：读不阻塞写，写不阻塞读。它并排维护着多个版本的对象，所以这种技术被称为多版本并发控制（MVCC, multi-version concurrentcy control）。如果一个数据库只需要提供读已提交的隔离级别，而不提供快照隔离，那么保留一个对象的两个版本就足够了：提交的版本和被覆盖但尚未提交的版本。支持快照隔离的存储引擎通常也使用MVCC来实现读已提交隔离级别。一种典型的方法是读已提交为每个查询使用单独的快照，而快照隔离对整个事务使用相同的快照。 不可重复读（nonrepeatable read）或读取偏差（read skew）： 在同一个事务中，客户端在不同的时间点会看见数据库的不同状态。快照隔离经常用于解决这个问题，它允许事务从一个特定时间点的一致性快照中读取数据。快照隔离通常使用多版本并发控制（MVCC） 来实现。 更新丢失（lost updates）：两个客户端同时执行读取-修改-写入序列。其中一个写操作，在没有合并另一个写入变更情况下，直接覆盖了另一个写操作的结果。所以导致数据丢失。快照隔离的一些实现可以自动防止这种异常，而另一些实现则需要手动锁定（SELECT FOR UPDATE）。数据库可以结合快照隔离高效地执行此检查。事实上，PostgreSQL的可重复读，Oracle的可串行化和SQL Server的快照隔离级别，都会自动检测到丢失更新，并中止惹麻烦的事务。但是，MySQL/InnoDB的可重复读并不会检测丢失更新。一些作者认为，数据库必须能防止丢失更新才称得上是提供了快照隔离，所以在这个定义下，MySQL下不提供快照隔离。 写偏差（write skew）：一个事务读取一些东西，根据它所看到的值作出决定，并将决定写入数据库。但是，写作的时候，决定的前提不再是真实的。只有可序列化的隔离才能防止这种异常。在PostgreSQL的可重复读，MySQL/InnoDB的可重复读，Oracle可序列化或SQL Server的快照隔离级别中，都不会自动检测写入偏差。自动防止写入偏差需要真正的可序列化隔离。（查询没有返回任何行，则SELECT FOR UPDATE锁不了任何东西。） 幻读（phantom reads）：事务读取符合某些搜索条件的对象。另一个客户端进行写入，影响搜索结果。快照隔离可以防止直接的幻像读取，但是写入歪斜环境中的幻影需要特殊处理，例如索引范围锁定。快照隔离避免了只读查询中幻读，但是在像我们讨论的例子那样的读写事务中，幻影会导致特别棘手的写偏差情况。 可序列化（serializability）隔离通常被认为是最强的隔离级别。它保证即使事务可以并行执行，最终的结果也是一样的，就好像它们没有任何并发性，连续挨个执行一样。因此数据库保证，如果事务在单独运行时正常运行，则它们在并发运行时继续保持正确 —— 换句话说，数据库可以防止所有可能的竞争条件。目前大多数提供可序列化的数据库都使用了三种技术之一： 字面意义上地串行顺序执行事务（真的串行执行） 数据库设计人员只是在2007年左右才决定， 因为RAM此时才足够便宜，数据库设计人员意识到OLTP事务通常很短，而且只进行少量的读写操作，串行执行事务的方法在VoltDB/H-Store，Redis和Datomic中实现。 每个事务都必须小而快，只要有一个缓慢的事务，就会拖慢所有事务处理。 仅限于活跃数据集可以放入内存的情况。很少访问的数据可能会被移动到磁盘，但如果需要在单线程执行的事务中访问，系统就会变得非常慢。 写入吞吐量必须低到能在单个CPU核上处理，如若不然，事务需要能划分至单个分区，且不需要跨分区协调。 跨分区事务是可能的，但是它们的使用程度有很大的限制。 两阶段锁（2PL, two-phase locking） 大约30年来唯一可行的选择 在2PL中，写入不仅会阻塞其他写入，也会阻塞读，反之亦然。快照隔离使得读不阻塞写，写也不阻塞读，这是2PL和快照隔离之间的关键区别。 2PL用于MySQL（InnoDB）和SQL Server中的可序列化隔离级别，以及DB2中的可重复读隔离级别。 读与写的阻塞是通过为数据库中每个对象添加锁来实现的。锁可以处于共享模式（shared mode）或独占模式（exclusive mode）。 两阶段锁定的巨大缺点，以及70年代以来没有被所有人使用的原因，是其性能问题。两阶段锁定下的事务吞吐量与查询响应时间要比弱隔离级别下要差得多。 断言锁（predicate lock）如果事务A想要读取匹配某些条件的对象，就像在这个 SELECT 查询中那样，它必须获取查询条件上的共享断言锁（shared-mode predicate lock）。如果另一个事务B持有任何满足这一查询条件对象的排它锁，那么A必须等到B释放它的锁之后才允许进行查询。 如果活跃事务持有很多锁，检查匹配的锁会非常耗时。因此，大多数使用2PL的数据库实际上实现了索引范围锁（也称为间隙锁（next-key locking）） 两阶段锁是一种所谓的悲观并发控制机制（pessimistic） ：它是基于这样的原则：如果有事情可能出错（如另一个事务所持有的锁所表示的），最好等到情况安全后再做任何事情。这就像互斥，用于保护多线程编程中的数据结构。 可序列化的快照隔离（serializable snapshot isolation, SSI），乐观并发控制技术 一方面，我们实现了性能不好（2PL）或者扩展性不好（串行执行）的可序列化隔离级别。另一方面，我们有性能良好的弱隔离级别，但容易出现各种竞争条件（丢失更新，写入偏差，幻读等）。它在2008年首次被描述，并且是Michael Cahill的博士论文的主题 序列化快照隔离是一种乐观（optimistic） 的并发控制技术。在这种情况下，乐观意味着，如果存在潜在的危险也不阻止事务，而是继续执行事务，希望一切都会好起来。当一个事务想要提交时，数据库检查是否有什么不好的事情发生（即隔离是否被违反）；如果是的话，事务将被中止，并且必须重试。只有可序列化的事务才被允许提交。 数据库需要跟踪一个事务由于MVCC可见性规则而忽略另一个事务的写入。当事务想要提交时，数据库检查是否有任何被忽略的写入现在已经被提交。如果是这样，事务必须中止。 与两阶段锁定相比，可序列化快照隔离的最大优点是一个事务不需要阻塞等待另一个事务所持有的锁。就像在快照隔离下一样，写不会阻塞读，反之亦然。这种设计原则使得查询延迟更可预测，变量更少。特别是，只读查询可以运行在一致的快照上，而不需要任何锁定，这对于读取繁重的工作负载非常有吸引力。 与串行执行相比，可序列化快照隔离并不局限于单个CPU核的吞吐量：FoundationDB将检测到的序列化冲突分布在多台机器上，允许扩展到很高的吞吐量。 中止率显着影响SSI的整体表现。例如，长时间读取和写入数据的事务很可能会发生冲突并中止，因此SSI要求同时读写的事务尽量短（只读长事务可能没问题）。对于慢事务，SSI可能比两阶段锁定或串行执行更不敏感。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/arch/ddia-3.html":{"url":"note/arch/ddia-3.html","title":"DDIA笔记3","keywords":"","body":" 第八章 分布式系统的麻烦 故障与部分失效 不可靠的网络 不可靠的时钟 知识、真相与谎言 系统模型与现实 第九章 一致性与共识 线性一致性（linearizability） 顺序保证（Ordering Guarantees） 全序广播 使用线性一致性存储实现全序广播 分布式事务与共识 实践中的分布式事务 共识的应用：成员与协调服务 与共识等价的问题 第八章 分布式系统的麻烦 故障与部分失效 使用分布式系统与在一台计算机上编写软件有着根本的区别，主要的区别在于，有许多新的和令人兴奋的方法可以使事情出错。 在分布式系统中，尽管系统的其他部分工作正常，但系统的某些部分可能会以某种不可预知的方式被破坏。这被称为部分失效（partial failure）。难点在于部分失效是不确定性的（nonderterministic）。 迟早会有一部分系统出现故障，软件必须以某种方式处理。故障处理必须是软件设计的一部分，并且作为软件的运维，您需要知道在发生故障的情况下，软件可能会表现出怎样的行为。 不可靠的网络 如果发送请求并没有得到响应，则无法区分（a）请求是否丢失，（b）远程节点是否关闭，或（c）响应是否丢失。处理这个问题的通常方法是超时（Timeout）：在一段时间之后放弃等待，并且认为响应不会到达。但是，当发生超时时，你仍然不知道远程节点是否收到了请求。 网络分区：网络的一部分由于网络故障而被切断时，有时称为网络分区（network partition）或网络断裂（netsplit）。 故障检测：长时间的超时意味着长时间等待，直到一个节点被宣告死亡（在这段时间内，用户可能不得不等待，或者看到错误信息）。短暂的超时可以更快地检测到故障，但是实际上它只是经历了暂时的减速（例如，由于节点或网络上的负载峰值）而导致错误地宣布节点失效的风险更高。 网络排队 如果多个不同的节点同时尝试将数据包发送到同一目的地，则网络交换机必须将它们排队并将它们逐个送入目标网络链路（如图8-2所示）。在繁忙的网络链路上，数据包可能需要等待一段时间才能获得一个插槽（这称为网络连接）。如果传入的数据太多，交换机队列填满，数据包将被丢弃，因此需要重新发送数据包 - 即使网络运行良好。 当数据包到达目标机器时，如果所有CPU内核当前都处于繁忙状态，则来自网络的传入请求将被操作系统排队，直到应用程序准备好处理它为止。根据机器上的负载，这可能需要一段任意的时间。 在虚拟化环境中，正在运行的操作系统经常暂停几十毫秒，而另一个虚拟机使用CPU内核。在这段时间内，虚拟机不能从网络中消耗任何数据，所以传入的数据被虚拟机监视器排队（缓冲），进一步增加了网络延迟的可变性。 TCP执行流量控制（flow control）（也称为拥塞避免（congestion avoidance）或背压（backpressure）），其中节点限制自己的发送速率以避免网络链路或接收节点过载。这意味着在数据甚至进入网络之前，在发送者处需要进行额外的排队。 系统不是使用配置的常量超时，而是连续测量响应时间及其变化（抖动），并根据观察到的响应时间分布自动调整超时。这可以通过Phi Accrual故障检测器来完成，该检测器例如在Akka和Cassandra 中使用。 同步网络 vs 异步网络：非常可靠的传统固定电话网络（非蜂窝，非VoIP），有限延迟（bounded delay）。 更一般地说，可以将延迟变化视为动态资源分区的结果。 不可靠的时钟 时钟是您直观地了解时钟的依据：它根据某个日历（也称为挂钟时间（wall-clock time））返回当前日期和时间。例如，Linux上的clock_gettime(CLOCK_REALTIME)和Java中的System.currentTimeMillis()返回自epoch（1970年1月1日 午夜 UTC，格林威治历）以来的秒数（或毫秒），根据公历日历，不包括闰秒。 单调钟适用于测量持续时间（时间间隔），例如超时或服务的响应时间：Linux上的clock_gettime(CLOCK_MONOTONIC)，和Java中的System.nanoTime()都是单调时钟。这个名字来源于他们保证总是前进的事实（而时钟可以及时跳回）。 在具有多个CPU插槽的服务器上，每个CPU可能有一个单独的计时器，但不一定与其他CPU同步。操作系统会补偿所有的差异，并尝试向应用线程表现出单调钟的样子，即使这些线程被调度到不同的CPU上。 时钟漂移取决于机器的温度。 Google假设其服务器时钟漂移为200 ppm（百万分之一），相当于每30秒与服务器重新同步一次的时钟漂移为6毫秒，或者每天重新同步的时钟漂移为17秒。 管通过保留最“最近”的值并放弃其他值来解决冲突是很诱惑人的，但是要注意，“最近”的定义取决于本地的时钟，这很可能是不正确的。 所谓的逻辑时钟是基于递增计数器而不是振荡石英晶体，对于排序事件来说是更安全的选择。逻辑时钟不测量一天中的时间或经过的秒数，而仅测量事件的相对顺序；相反的，用来测量实际经过时间的时钟和单调钟也被称为物理时钟。 时钟读数存在置信区间：一个系统可能以95％的置信度认为当前时间处于本分钟内的第10.3秒和10.5秒之间，它可能没法比这更精确了。一个有趣的例外是Spanner中的Google TrueTime API ，它明确地报告了本地时钟的置信区间。当你询问当前时间时，你会得到两个值：[最早，最晚]，这是最早可能的时间戳和最晚可能的时间戳。在不确定性估计的基础上，时钟知道当前的实际时间落在该区间内。间隔的宽度取决于自从本地石英钟最后与更精确的时钟源同步以来已经过了多长时间。 暂停进程：分布式系统中的节点，必须假定其执行可能在任意时刻暂停相当长的时间，即使是在一个函数的中间。在暂停期间，世界的其它部分在继续运转，甚至可能因为该节点没有响应，而宣告暂停节点的死亡。最终暂停的节点可能会继续运行，在再次检查自己的时钟之前，甚至可能不会意识到自己进入了睡眠。 知识、真相与谎言 真理由多数所定义：最常见的法定人数是超过一半的绝对多数（尽管其他类型的法定人数也是可能的） 即使一个节点认为它是“天选者（the choosen one）”（分区的负责人，锁的持有者，成功获取用户名的用户的请求处理程序），但这并不一定意味着有法定人数的节点同意。如果将ZooKeeper用作锁定服务，则可将事务标识zxid或节点版本cversion用作屏蔽令牌 如果存在节点可能“撒谎”（发送任意错误或损坏的响应）的风险，则分布式系统的问题变得更困难了——例如，如果节点可能声称其实际上没有收到特定的消息。这种行为被称为拜占庭故障（Byzantine fault），在不信任的环境中达成共识的问题被称为拜占庭将军问题。当一个系统在部分节点发生故障、不遵守协议、甚至恶意攻击、扰乱网络时仍然能继续正确工作，称之为拜占庭容错（Byzantine fault-tolerant）的。大多数拜占庭式容错算法要求超过三分之二的节点能够正常工作（即，如果有四个节点，最多只能有一个故障）。要使用这种方法对付bug，你必须有四个独立的相同软件的实现，并希望一个bug只出现在四个实现之一中。 弱谎言形式 由于硬件问题或操作系统，驱动程序，路由器等中的错误，网络数据包有时会受到损坏。通常，内建于TCP和UDP中的校验和会俘获损坏的数据包，但有时它们会逃避检测。 可公开访问的应用程序必须仔细清理来自用户的任何输入，例如检查值是否在合理的范围内，并限制字符串的大小以防止通过大内存分配拒绝服务。 NTP客户端可以配置多个服务器地址。同步时，客户端联系所有的服务器，估计它们的误差，并检查大多数服务器是否在对某个时间范围内达成一致。只要大多数的服务器没问题，一个配置错误的NTP服务器报告的时间会被当成特异值从同步中排除。 系统模型与现实 定时假设，三种常用的系统模型 同步模型（synchronous model） 假设网络延迟，进程暂停和和时钟误差都是有界限的。这并不意味着完全同步的时钟或零网络延迟；这只意味着你知道网络延迟，暂停和时钟漂移将永远不会超过某个固定的上限。同步模型并不是大多数实际系统的现实模型，因为（如本章所讨论的）无限延迟和暂停确实会发生。 部分同步（partial synchronous）意味着一个系统在大多数情况下像一个同步系统一样运行，但有时候会超出网络延迟，进程暂停和时钟漂移的界限。 异步模型 在这个模型中，一个算法不允许对时机做任何假设：事实上它甚至没有时钟（所以它不能使用超时）。一些算法被设计为可用于异步模型，但非常受限。 节点失效。三种最常见的节点系统模型 在崩溃停止（crash-stop）模型中，算法可能会假设一个节点只能以一种方式失效，即通过崩溃。这意味着节点可能在任意时刻突然停止响应，此后该节点永远消失——它永远不会回来。 假设节点可能会在任何时候崩溃，但也许会在未知的时间之后再次开始响应。在崩溃-恢复（crash-recovery）模型中，假设节点具有稳定的存储（即，非易失性磁盘存储）且会在崩溃中保留，而内存中的状态会丢失。 拜占庭（任意）故障：节点可以做（绝对意义上的）任何事情，包括试图戏弄和欺骗其他节点 对于真实系统的建模，具有崩溃-恢复故障（crash-recovery）的部分同步模型（partial synchronous）通常是最有用的模型。 安全性（safety）和活性（liveness）：安全性通常被非正式地定义为，没有坏事发生，而活性通常就类似：最终好事发生 如果安全属性被违反，我们可以指向一个特定的时间点（例如，如果违反了唯一性属性，我们可以确定重复的防护令牌返回的特定操作） 。违反安全属性后，违规行为不能撤销。 活性属性反过来：在某个时间点（例如，一个节点可能发送了一个请求，但还没有收到响应），它可能不成立，但总是希望在未来（即通过接受答复）。 可扩展性并不是使用分布式系统的唯一原因。容错和低延迟（通过将数据放置在距离用户较近的地方）是同等重要的目标，而这些不能用单个节点实现。 有可能给网络提供硬实时的响应保证和有限的延迟，但是这样做非常昂贵，且导致硬件资源的利用率降低。大多数非安全关键系统会选择便宜而不可靠，而不是昂贵和可靠。 第九章 一致性与共识 分布式系统最重要的抽象之一就是共识（consensus）：就是让所有的节点对某件事达成一致。 分布式一致性模型和我们之前讨论的事务隔离级别的层次结构有一些相似之处。尽管两者有一部分内容重叠，但它们大多是无关的问题：事务隔离主要是为了避免由于同时执行事务而导致的竞争状态，而分布式一致性主要关于，面对延迟和故障时，如何协调副本间的状态。 线性一致性（linearizability） 也称为原子一致性（atomic consistency），强一致性（strong consistency），立即一致性（immediate consistency）或外部一致性（external consistency ） 线性一致性本质上意味着表现得好像只有一个数据副本，而且所有的操作都是原子的 线性一致性与可序列化 可序列化（Serializability）是事务的隔离属性，每个事务可以读写多个对象（行，文档，记录）。它确保事务的行为，与它们按照某种顺序依次执行的结果相同 线性一致性（Linearizability）是读取和写入寄存器（单个对象）的新鲜度保证。它不会将操作组合为事务，因此它也不会阻止写偏差等问题 使用场景 锁定和领导选举：一个使用单主复制的系统，需要确保领导真的只有一个，而不是几个（脑裂） 唯一性约束：在数据库中很常见，这种情况实际上类似于一个锁 实现方式 单主复制（可能线性一致）：主库具有用于写入的数据的主副本，而追随者在其他节点上保留数据的备份副本。如果从主库或同步更新的从库读取数据，它们可能（protential）是线性一致性的 共识算法（线性一致）：与单领导者复制类似。然而，共识协议包含防止脑裂和陈旧副本的措施。由于这些细节，共识算法可以安全地实现线性一致性存储。例如，zookeeper 和etcd 多主复制（非线性一致）：具有多主程序复制的系统通常不是线性一致的，因为它们同时在多个节点上处理写入，并将其异步复制到其他节点。因此，它们可能会产生冲突的写入，需要解析。这种冲突是因为缺少单一数据副本人为产生的。 无主复制（也许不是线性一致的）：对于无领导者复制的系统（Dynamo风格），有时候人们会声称通过要求法定人数读写（ $w + r> n$ ）可以获得“强一致性”。这取决于法定人数的具体配置，以及强一致性如何定义（通常不完全正确）。 线性一致性和网络延迟 实际上，线性一致的系统惊人的少。例如，现代多核CPU上的内存甚至都不是线性一致的：如果一个CPU核上运行的线程写入某个内存地址，而另一个CPU核上运行的线程不久之后读取相同的地址，并没有保证一定能一定读到第一个线程写入的值（除非使用了内存屏障（memory barrier）或围栏（fence））。 牺牲线性一致性的原因是性能（performance），而不是容错。Attiya 和 Welch 证明，如果你想要线性一致性，读写请求的响应时间至少与网络延迟的不确定性成正比。 CAP定理没有帮助 网络正常工作的时候，系统可以提供一致性（线性一致性）和整体可用性。发生网络故障时，你必须在线性一致性和整体可用性之间做出选择。因此，一个更好的表达CAP的方法可以是一致的，或者在分区时可用。 CAP 只考虑了一个一致性模型（即线性一致性）和一种故障（网络分区，或活跃但彼此断开的节点），它没有讨论任何关于网络延迟，死亡节点或其他权衡的事。 因此，尽管CAP在历史上有一些影响力，但对于设计系统而言并没有实际价值 顺序保证（Ordering Guarantees） 顺序反复出现有几个原因，其中一个原因是，它有助于保持因果关系（causality）。 一个系统服从因果关系所规定的顺序，我们说它是因果一致（causally）的。例如，快照隔离提供了因果一致性：当你从数据库中读取到一些数据时，你一定还能够看到其因果前驱。 因果顺序不是全序的：全序（total order）允许任意两个元素进行比较，所以如果有两个元素，你总是可以说出哪个更大，哪个更小。 在线性一致的系统中，操作是全序的：如果系统表现的就好像只有一个数据副本，并且所有操作都是原子性的，这意味着对任何两个操作，我们总是能判定哪个操作先发生。 线性一致性强于因果一致性：线性一致性隐含着因果关系：任何线性一致的系统都能正确保持因果性。 实际上在所有的不会被网络延迟拖慢的一致性模型中，因果一致性是可行的最强的一致性模型。而且在网络故障时仍能保持可用。 我们可以使用序列号（sequence nunber）或时间戳（timestamp）来排序事件。 时间戳不一定来自时钟（或物理时钟，存在许多问题）。它可以来自一个逻辑时钟（logical clock），这是一个用来生成标识操作的数字序列的算法，典型实现是使用一个每次操作自增的计数器。 主库不存在时，如何产生序列号（可能因为使用了多主数据库或无主数据库，或者因为使用了分区的数据库，但以下实现有同一个问题：生成的序列号与因果不一致） 每个节点都可以生成自己独立的一组序列号。例如有两个节点，一个节点只能生成奇数，而另一个节点只能生成偶数。通常，可以在序列号的二进制表示中预留一些位，用于唯一的节点标识符 可以将时钟（物理时钟）时间戳附加到每个操作上。这种时间戳并不连续，但是如果它具有足够高的分辨率，那也许足以提供一个操作的全序关系。 可以预先分配序列号区块。例如，节点 A 可能要求从序列号1到1,000区块的所有权，而节点 B 可能要求序列号1,001到2,000区块的所有权。然后每个节点可以独立分配所属区块中的序列号，并在序列号告急时请求分配一个新的区块 兰伯特时间戳：因果关系一致的序列号，每个节点都有一个唯一标识符，和一个保存自己执行操作数量的计数器。 兰伯特时间戳就是两者的简单组合：计数器，节点ID。 两个节点有时可能具有相同的计数器值，但通过在时间戳中包含节点ID，每个时间戳都是唯一的。任意两个时间戳均可比较大小。 限制：只有在所有的操作都被收集之后，操作的全序才会出现。如果另一个节点已经产生了一些操作，但你还不知道那些操作是什么，那就无法构造所有操作最终的全序关系：来自另一个节点的未知操作可能需要被插入到全序中的不同位置。为了实诸如如用户名上的唯一约束这种东西，仅有操作的全序是不够的，你还需要知道这个全序何时会尘埃落定。 全序广播 如果你的程序只运行在单个CPU核上，操作全序可以简单地就是CPU执行这些操作的顺序。但是在分布式系统中，让所有节点对同一个全局操作顺序达成一致可能相当棘手。单主复制通过选择一个节点作为主库来确定操作的全序，并在主库的单个CPU核上对所有操作进行排序。如果吞吐量超出单个主库的处理能力，这种情况下如何扩展系统；以及如果主库失效（“处理节点宕机”），如何处理故障切换。在分布式系统文献中，这个问题被称为全序广播（total order broadcast）或原子广播（atomic broadcast）。 满足两个安全属性： 可靠交付（reliable delivery）：没有消息丢失：如果消息被传递到一个节点，它将被传递到所有节点。 全序交付（totally ordered delivery）：消息以相同的顺序传递给每个节点。 状态机复制（state machine replication）：如果每个消息都代表一次数据库的写入，且每个副本都按相同的顺序处理相同的写入，那么副本间将相互保持一致（除了临时的复制延迟） 全序广播对于实现提供防护令牌的锁服务也很有用。每个获取锁的请求都作为一条消息追加到日志末尾，并且所有的消息都按它们在日志中出现的顺序依次编号。序列号可以当成防护令牌用，因为它是单调递增的。在ZooKeeper中，这个序列号被称为zxid 使用全序广播实现线性一致的存储 从形式上讲，线性一致读写寄存器是一个更容易的问题。 全序广播等价于共识。而共识问题在异步的崩溃-停止模型中没有确定性的解决方案，而线性一致的读写寄存器可以在这种模型中实现。 然而，支持诸如比较并设置（CAS, compare-and-set），或自增并返回（increment-and-get）的原子操作使它等价于共识问题。 因此，共识问题与线性一致寄存器问题密切相关。 全序广播是异步的：消息被保证以固定的顺序可靠地传送，但是不能保证消息何时被送达（所以一个接收者可能落后于其他接收者）。相比之下，线性一致性是新鲜性的保证：读取一定能看见最新的写入值。 可以通过将全序广播当成仅追加日志的方式来实现这种线性一致的CAS操作，尽管这一过程保证写入是线性一致的，但它并不保证读取也是线性一致的，如果你从与日志异步更新的存储中读取数据，结果可能是陈旧的。 （精确地说，这里描述的过程提供了顺序一致性（sequential consistency），有时也称为时间线一致性（timeline consistency），比线性一致性稍微弱一些的保证）。 为了使读取也线性一致，有几个选项： 你可以通过追加一条消息，当消息回送时读取日志，执行实际的读取。消息在日志中的位置因此定义了读取发生的时间点。 （etcd的法定人数读取有些类似这种情况） 如果日志允许以线性一致的方式获取最新日志消息的位置，则可以查询该位置，等待直到该位置前的所有消息都传达到你，然后执行读取。（这是Zookeeper sync操作背后的思想） 你可以从同步更新的副本中进行读取，因此可以确保结果是最新的。 （这种技术用于链式复制；参阅“复制研究”。） 使用线性一致性存储实现全序广播 一般来说，如果你对线性一致性的序列号生成器进行深入过足够深入的思考，你不可避免地会得出一个共识算法 最简单的方法是假设你有一个线性一致的寄存器来存储一个整数，并且有一个原子自增并返回操作。或者原子CAS操作也可以完成这项工作。 与兰伯特时间戳不同，通过自增线性一致性寄存器获得的数字形式上是一个没有间隙的序列。因此，如果一个节点已经发送了消息 4 并且接收到序列号为 6 的传入消息，则它知道它在传递消息 6 之前必须等待消息 5 。兰伯特时间戳则与之不同 ，这是全序广播和时间戳排序间的关键区别。 分布式事务与共识 共识是分布式计算中最重要也是最基本的问题之一。从表面上看似乎很简单：非正式地讲，目标只是让几个节点达成一致（get serveral nodes to agree on something） 应用：如领导选举，原子提交 共识的不可能性：Fischer，Lynch和Paterson之后的FLP结果证明，如果存在节点可能崩溃的风险，则不存在总是能够达成共识的算法。但FLP结果在异步系统模型中得到了证明，这是一种限制性很强的模型，它假定确定性算法不能使用任何时钟或超时。如果允许算法使用超时或其他方法来识别可疑的崩溃节点（即使怀疑有时是错误的），则共识变为一个可解的问题。即使仅仅允许算法使用随机数，也足以绕过这个不可能的结果。 原子提交与二阶段提交（2PC） 两阶段提交（two-phase commit）是一种用于实现跨多个节点的原子事务提交的算法，即确保所有节点提交或所有节点中止。 它是分布式数据库中的经典算法。 2PC在某些数据库内部使用，也以XA事务的形式对应用可用（例如Java Transaction API支持）或以SOAP Web服务的WS-AtomicTransaction 形式提供给应用。 参与者收到准备请求时，需要确保在任意情况下都的确可以提交事务。这包括将所有事务数据写入磁盘（出现故障，电源故障，或硬盘空间不足都不能是稍后拒绝提交的理由）以及检查是否存在任何冲突或违反约束 当协调者收到所有准备请求的答复时，会就提交或中止事务作出明确的决定（只有在所有参与者投赞成票的情况下才会提交）。协调者必须把这个决定写到磁盘上的事务日志中，如果它随后就崩溃，恢复后也能知道自己所做的决定。这被称为提交点（commit point）。一旦协调者的决定落盘，提交或放弃请求会发送给所有参与者。如果这个请求失败或超时，协调者必须永远保持重试，直到成功为止。 两阶段提交被称为阻塞（blocking）原子提交协议，因为存在2PC可能卡住并等待协调者恢复的情况。理论上，可以使一个原子提交协议变为非阻塞（nonblocking）的，以便在节点失败时不会卡住。通常，非阻塞原子提交需要一个完美的故障检测器（perfect failure detector），即一个可靠的机制来判断一个节点是否已经崩溃。在具有无限延迟的网络中，超时并不是一种可靠的故障检测机制，因为即使没有节点崩溃，请求也可能由于网络问题而超时。出于这个原因，尽管大家都清楚可能存在协调者故障的问题，2PC仍然被使用。 实践中的分布式事务 数据库内部的分布式事务 异构分布式事务 恰好一次的消息处理 X/Open XA（扩展架构（eXtended Architecture）的缩写）是跨异构技术实现两阶段提交的标准。它于1991年推出并得到了广泛的实现：许多传统关系数据库（包括PostgreSQL，MySQL，DB2，SQL Server和Oracle）和消息代理（包括ActiveMQ，HornetQ，MSMQ和IBM MQ） 都支持XA。 共识算法要求 一致同意（Uniform agreement）：没有两个节点的决定不同。（安全性要求） 完整性（Integrity）:没有节点决定两次。（安全性要求） 有效性（Validity）:如果一个节点决定了值 v ，则 v 由某个节点所提议。（安全性要求） 终止（Termination） 由所有未崩溃的节点来最终决定值。（存活性要求）终止属性取决于一个假设，不超过一半的节点崩溃或不可达。然而即使多数节点出现故障或存在严重的网络问题，绝大多数共识的实现都能始终确保安全属性得到满足—— 一致同意，完整性和有效性 最著名的容错共识算法是视图戳复制（VSR, viewstamped replication），Paxos ，Raft 以及 Zab 。VSR，Raft和Zab直接实现了全序广播，因为这样做比重复一次一值的共识更高效。在Paxos的情况下，这种优化被称为Multi-Paxos。 主要过程 迄今为止所讨论的所有共识协议，在内部都以某种形式使用一个领导者，但它们并不能保证领导者是独一无二的。相反，它们可以做出更弱的保证：协议定义了一个时代编号（epoch number）（在Paxos中称为投票编号（ballot number），视图戳复制中的视图编号（view number），以及Raft中的任期号码（term number）），并确保在每个时代中，领导者都是唯一的。 两轮投票：第一次是为了选出一位领导者，第二次是对领导者的提议进行表决。关键的洞察在于，这两次投票的法定人群必须相互重叠（overlap）：如果一个提案的表决通过，则至少得有一个参与投票的节点也必须参加过最近的领导者选举。因此，如果在一个提案的表决过程中没有出现更高的时代编号。那么现任领导者就可以得出这样的结论：没有发生过更高时代的领导选举，因此可以确定自己仍然在领导，然后它就可以安全地对提议值做出决定。 共识的应用：成员与协调服务 线性一致性的原子操作：使用原子CAS操作可以实现锁，如果多个节点同时尝试执行相同的操作，只有一个节点会成功。共识协议保证了操作的原子性和线性一致性，即使节点发生故障或网络在任意时刻中断。分布式锁通常以租约（lease）的形式实现，租约有一个到期时间，以便在客户端失效的情况下最终能被释放 操作的全序排序：防护令牌是每次锁被获取时单调增加的数字。 ZooKeeper通过全局排序操作来提供这个功能，它为每个操作提供一个单调递增的事务ID（zxid）和版本号（cversion） 失效检测：客户端在ZooKeeper服务器上维护一个长期会话，客户端和服务器周期性地交换心跳包来检查节点是否还活着。即使连接暂时中断，或者ZooKeeper节点失效，会话仍保持在活跃状态。但如果心跳停止的持续时间超出会话超时，ZooKeeper会宣告该会话已死亡。当会话超时（ZooKeeper调用这些临时节点）时，会话持有的任何锁都可以配置为自动释放（ZooKeeper称之为临时节点（ephemeral nodes））。 变更通知：客户端不仅可以读取其他客户端创建的锁和值，还可以监听它们的变更。客户端可以知道另一个客户端何时加入集群（基于新客户端写入ZooKeeper的值），或发生故障（因其会话超时，而其临时节点消失）。通过订阅通知，客户端不用再通过频繁轮询的方式来找出变更。 将工作分配给节点：ZooKeeper/Chubby模型运行良好的一个例子是，如果你有几个进程实例或服务，需要选择其中一个实例作为主库或首选服务。如果领导者失败，其他节点之一应该接管。这对单主数据库当然非常实用，但对作业调度程序和类似的有状态系统也很好用。 服务发现：ZooKeeper，etcd和Consul也经常用于服务发现——也就是找出你需要连接到哪个IP地址才能到达特定的服务。但服务发现是否需要达成共识还不太清楚。 成员服务：ZooKeeper和它的小伙伴们可以看作是成员服务研究的悠久历史的一部分，这个历史可以追溯到20世纪80年代，并且对建立高度可靠的系统（例如空中交通管制）非常重要 与共识等价的问题 线性一致性的CAS寄存器：寄存器需要基于当前值是否等于操作给出的参数，原子地决定是否设置新值。 原子事务提交：数据库必须决定是否提交或中止分布式事务。 全序广播：消息系统必须决定传递消息的顺序。 锁和租约：当几个客户端争抢锁或租约时，由锁来决定哪个客户端成功获得锁。 成员/协调服务：给定某种故障检测器（例如超时），系统必须决定哪些节点活着，哪些节点因为会话超时需要被宣告死亡。 唯一性约束：当多个事务同时尝试使用相同的键创建冲突记录时，约束必须决定哪一个被允许，哪些因为违反约束而失败。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/arch/ddia-4.html":{"url":"note/arch/ddia-4.html","title":"DDIA笔记4","keywords":"","body":" 第十章 批处理 第十一章 流处理 记录系统（System of record），也被称为真相源（source of truth），持有数据的权威版本。当新的数据进入时（例如，用户输入）首先会记录在这里。每个事实正正好好表示一次（表示通常是标准化的（normalized）） 衍生数据系统（Derived data systems）：衍生系统中的数据，通常是另一个系统中的现有数据以某种方式进行转换或处理的结果。如果丢失衍生数据，可以从原始来源重新创建。典型的例子是缓存（cache） 第十章 批处理 三类系统：服务（在线系统）、批处理系统（离线系统）、流处理系统（准实时系统） Unix Shell GNU Coreutils（Linux）中的sort 程序通过溢出至磁盘的方式来自动应对大于内存的数据集，并能同时使用多个CPU核进行并行排序 换行，ASCII记录分隔符0x1E本来就是一个更好的选择，因为它是为了这个目的而设计的 MapReduce和分布式文件系统 Map-Reduce与1940年代和1950年代广泛用于商业数据处理的机电IBM卡片分类机器有着惊人的相似之处。正如我们所说，历史总是在不断重复自己。 最大的区别是，MPP（massively parallel processing ）数据库专注于在一组机器上并行执行分析SQL查询，而MapReduce和分布式文件系统的组合则更像是一个可以运行任意程序的通用操作系统。 与网络连接存储（NAS）和存储区域网络（SAN）架构的共享磁盘方法相比，HDFS基于无共享原则。共享磁盘存储由集中式存储设备实现，通常使用定制硬件和专用网络基础设施（如光纤通道）。而另一方面，无共享方法不需要特殊的硬件，只需要通过传统数据中心网络连接的计算机。 HDFS包含在每台机器上运行的守护进程，对外暴露网络服务，允许其他节点访问存储在该机器上的文件。NameNode的中央服务器会跟踪哪个文件块存储在哪台机器上。 只要当Mapper读取完输入文件，并写完排序后的输出文件，MapReduce调度器就会通知Reducer可以从该Mapper开始获取输出文件。Reducer连接到每个Mapper，并下载自己相应分区的有序键值对文件。按Reducer分区，排序，从Mapper向Reducer复制分区数据，这一整个过程被称为混洗（shuffle） 为了处理这些作业之间的依赖，有很多针对Hadoop的工作流调度器被开发出来，包括Oozie，Azkaban，Luigi，Airflow和Pinball。Hadoop的各种高级工具（如Pig，Hive，Cascading，Crunch 和FlumeJava）也能自动布线组装多个MapReduce阶段，生成合适的工作流。 MapReduce被设计为容忍频繁意外任务终止的原因：不是因为硬件很不可靠，而是因为任意终止进程的自由有利于提高计算集群中的资源利用率。 与Unix管道相比，MapReduce完全物化中间状态（简单来讲，将中间结果写入文件）的方法存在不足之处： MapReduce作业只有在前驱作业（生成其输入）中的所有任务都完成时才能启动，而由Unix管道连接的进程会同时启动，输出一旦生成就会被消费。不同机器上的数据倾斜或负载不均意味着一个作业往往会有一些掉队的任务，比其他任务要慢得多才能完成。必须等待至前驱作业的所有任务完成，拖慢了整个工作流程的执行。 Mapper通常是多余的：它们仅仅是读取刚刚由Reducer写入的同样文件，为下一个阶段的分区和排序做准备。在许多情况下，Mapper代码可能是前驱Reducer的一部分：如果Reducer和Mapper的输出有着相同的分区与排序方式，那么Reducer就可以直接串在一起，而不用与Mapper相互交织。 将中间状态存储在分布式文件系统中意味着这些文件被复制到多个节点，这些临时数据这么搞就比较过分了。 几种用于分布式批处理的新执行引擎被开发出来，其中最著名的是Spark ，Tez 和Flink 。它们的设计方式有很多区别，但有一个共同点：把整个工作流作为单个作业来处理，而不是把它分解为独立的子作业。 我们讨论了几种MapReduce的连接算法，其中大多数也在MPP数据库和数据流引擎内部使用。它们也很好地演示了分区算法是如何工作的： 排序合并连接：每个参与连接的输入都通过一个提取连接键的Mapper。通过分区，排序和合并，具有相同键的所有记录最终都会进入相同的Reducer调用。这个函数能输出连接好的记录。 广播散列连接：两个连接输入之一很小，所以它并没有分区，而且能被完全加载进一个哈希表中。因此，你可以为连接输入大端的每个分区启动一个Mapper，将输入小端的散列表加载到每个Mapper中，然后扫描大端，一次一条记录，并为每条记录查询散列表。 分区散列连接：如果两个连接输入以相同的方式分区（使用相同的键，相同的散列函数和相同数量的分区），则可以独立地对每个分区应用散列表方法。 第十一章 流处理 当我们想要进行低延迟的连续处理时，如果数据存储不是为这种用途专门设计的，那么轮询开销就会很大。轮询的越频繁，能返回新事件的请求比例就越低，而额外开销也就越高。相比之下，最好能在新事件出现时直接通知消费者。 向消费者通知新事件的常用方式是使用消息传递系统（messaging system）：生产者发送包含事件的消息，然后将消息推送给消费者。 消息系统 在这个发布/订阅模式中，不同的系统采取各种各样的方法，并没有针对所有目的的通用答案。为了区分这些系统，问一下这两个问题会特别有帮助： 如果生产者发送消息的速度比消费者能够处理的速度快会发生什么？一般来说，有三种选择：系统可以丢掉消息，将消息放入缓冲队列，或使用背压（backpressure）（也称为流量控制，即阻塞生产者，以免其发送更多的消息）。例如Unix管道和TCP使用背压：它们有一个固定大小的小缓冲区，如果填满，发送者会被阻塞，直到接收者从缓冲区中取出数据。 如果消息被缓存在队列中，那么理解队列增长会发生什么是很重要的。当队列装不进内存时系统会崩溃吗？还是将消息写入磁盘？如果是这样，磁盘访问又会如何影响消息传递系统的性能？ 如果节点崩溃或暂时脱机，会发生什么情况？ —— 是否会有消息丢失？与数据库一样，持久性可能需要写入磁盘和/或复制的某种组合，这是有代价的。如果你能接受有时消息会丢失，则可能在同一硬件上获得更高的吞吐量和更低的延迟。 直接从生产者传递给消费者 UDP组播广泛应用于金融行业 无代理的消息库，如ZeroMQ和nanomsg采取类似的方法，通过TCP或IP多播实现发布/订阅消息传递。 StatsD和Brubeck使用不可靠的UDP消息传递来收集网络中所有机器的指标并对其进行监控。 如果消费者在网络上公开了服务，生产者可以直接发送HTTP或RPC请求将消息推送给使用者。这就是webhooks背后的想法，一种服务的回调URL被注册到另一个服务中，并且每当事件发生时都会向该URL发出请求。 消息代理 一种广泛使用的替代方法是通过消息代理（message broker）（也称为消息队列（message queue））发送消息，消息代理实质上是一种针对处理消息流而优化的数据库。 排队的结果是，消费者通常是异步（asynchronous）的：当生产者发送消息时，通常只会等待代理确认消息已经被缓存，而不等待消息被消费者处理。 消息代理的传统观点被封装在诸如JMS 【14】和AMQP 【15】的标准中，并且被诸如RabbitMQ，ActiveMQ，HornetQ，Qpid，TIBCO企业消息服务，IBM MQ，Azure Service Bus和Google Cloud Pub/Sub实现 【16】。代理将单条消息分配给消费者，消费者在成功处理单条消息后确认消息。消息被确认后从代理中删除。这种方法适合作为一种异步形式的RPC（另请参阅“消息传递数据流”），例如在任务队列中，消息处理的确切顺序并不重要，而且消息在处理完之后，不需要回头重新读取旧消息。 - 多个消费者：当多个消费者从同一主题中读取消息时，有使用两种主要的消息传递模式，如图11-1所示： - 负载均衡（load balance）：每条消息都被传递给消费者之一，所以处理该主题下消息的工作能被多个消费者共享。代理可以为消费者任意分配消息。当处理消息的代价高昂，希望能并行处理消息时，此模式非常有用（在AMQP中，可以通过让多个客户端从同一个队列中消费来实现负载均衡，而在JMS中则称之为共享订阅（shared subscription））。 - 扇出（fan-out）：每条消息都被传递给所有消费者。扇出允许几个独立的消费者各自“收听”相同的消息广播，而不会相互影响 —— 这个流处理中的概念对应批处理中多个不同批处理作业读取同一份输入文件 （JMS中的主题订阅与AMQP中的交叉绑定提供了这一功能）。 确认与重新交付 为了确保消息不会丢失，消息代理使用确认（acknowledgments）：客户端必须显式告知代理消息处理完毕的时间，以便代理能将消息从队列中移除。 即使消息代理试图保留消息的顺序（如JMS和AMQP标准所要求的），负载均衡与重传的组合也不可避免地导致消息被重新排序。为避免此问题，你可以让每个消费者使用单独的队列（即不使用负载均衡功能）。 基于日志的消息代理（log-based message brokers） Apache Kafka，Amazon Kinesis Streams和Twitter的DistributedLog 都是基于日志的消息代理。 Google Cloud Pub/Sub在架构上类似，但对外暴露的是JMS风格的API，而不是日志抽象。尽管这些消息代理将所有消息写入磁盘，但通过跨多台机器分区，每秒能够实现数百万条消息的吞吐量，并通过复制消息来实现容错性。 典型的大型硬盘容量为6TB，顺序写入吞吐量为150MB/s。如果以最快的速度写消息，则需要大约11个小时才能填满磁盘。 保持系统同步 如果周期性的完整数据库转储过于缓慢，有时会使用的替代方法是双写（dual write），其中应用代码在数据变更时明确写入每个系统：例如，首先写入数据库，然后更新搜索索引，然后使缓存项失效（甚至同时执行这些写入）。 一个是竞争条件，如图11-4所示。在这个例子中，两个客户端同时想要更新一个项目X：客户端1想要将值设置为A，客户端2想要将其设置为B。两个客户端首先将新值写入数据库，然后将其写入到搜索索引。因为运气不好，这些请求的时序是交错的：数据库首先看到来自客户端1的写入将值设置为A，然后来自客户端2的写入将值设置为B，因此数据库中的最终值为B。搜索索引首先看到来自客户端2的写入，然后是客户端1的写入，所以搜索索引中的最终值是A。即使没发生错误，这两个系统现在也永久地不一致了。 双重写入的另一个问题是，其中一个写入可能会失败，而另一个成功。这是一个容错问题，而不是一个并发问题，但也会造成两个系统互相不一致的结果。确保它们要么都成功要么都失败，是原子提交问题的一个例子，解决这个问题的代价是昂贵的 变更数据捕获 变更数据捕获（change data capture, CDC）越来越感兴趣，这是一种观察写入数据库的所有数据变更，并将其提取并转换为可以复制到其他系统中的形式的过程 数据库触发器可用来实现变更数据捕获（参阅“基于触发器的复制”），通过注册观察所有变更的触发器，并将相应的变更项写入变更日志表中。但是它们往往是脆弱的，而且有显著的性能开销。解析复制日志可能是一种更稳健的方法，但它也很有挑战，例如应对模式变更。 LinkedIn的Databus，Facebook的Wormhole和Yahoo!的Sherpa 大规模地应用这个思路。 Bottled Water使用解码WAL的API实现了PostgreSQL的CDC，Maxwell和Debezium通过解析binlog对MySQL做了类似的事情，Mongoriver读取MongoDB oplog ，而GoldenGate为Oracle提供类似的功能。 像消息代理一样，变更数据捕获通常是异步的：记录数据库系统不会等待消费者应用变更再进行提交。这种设计具有的运维优势是，添加缓慢的消费者不会过度影响记录系统。 事件溯源 在变更数据捕获中，应用以可变方式（mutable way）使用数据库，任意更新和删除记录。变更日志是从数据库的底层提取的（例如，通过解析复制日志），从而确保从数据库中提取的写入顺序与实际写入的顺序相匹配，从而避免图11-4中的竞态条件。写入数据库的应用不需要知道CDC的存在。 在事件溯源中，应用逻辑显式构建在写入事件日志的不可变事件之上。在这种情况下，事件存储是仅追加写入的，更新与删除是不鼓励的或禁止的。事件被设计为旨在反映应用层面发生的事情，而不是底层的状态变更。 从事件日志中派生出当前状态 用于记录更新的CDC事件通常包含记录的完整新版本，因此主键的当前值完全由该主键的最近事件确定，而日志压缩可以丢弃相同主键的先前事件。 另一方面，事件溯源在更高层次进行建模：事件通常表示用户操作的意图，而不是因为操作而发生的状态更新机制。在这种情况下，后面的事件通常不会覆盖先前的事件，所以你需要完整的历史事件来重新构建最终状态。这里进行同样的日志压缩是不可能的。 事务日志记录了数据库的所有变更。高速追加下入是更改日志的唯一方法。从这个角度来看，数据库的内容其实是日志中记录最新值的缓存。日志才是真相，数据库是日志子集的缓存，这一缓存子集恰好来自日志中每条记录与索引值的最新值。 不可变事件的优点 如果发生错误，会计师不会删除或更改分类帐中的错误交易 —— 而是添加另一笔交易以补偿错误，例如退还一比不正确的费用。不正确的交易将永远保留在分类帐中，对于审计而言可能非常重要。如果从不正确的分类账衍生出的错误数字已经公布，那么下一个会计周期的数字就会包括一个更正。这个过程在会计事务中是很常见 尽管这种可审计性在金融系统中尤其重要，但对于不受这种严格监管的许多其他系统，也是很有帮助的。如“批处理输出的哲学”中所讨论的，如果你意外地部署了将错误数据写入数据库的错误代码，当代码会破坏性地覆写数据时，恢复要困难得多。使用不可变事件的仅追加日志，诊断问题与故障恢复就要容易的多。 流处理 与批量作业相比的一个关键区别是，流不会结束。这种差异会带来很多隐含的结果。 长期以来，流处理一直用于监控目的，如果某个事件发生，单位希望能得到警报 复合事件处理（complex, event processing, CEP）是20世纪90年代为分析事件流而开发出的一种方法，尤其适用于需要搜索某些事件模式的应用。在这些系统中，查询和数据之间的关系与普通数据库相比是颠倒的。通常情况下，数据库会持久存储数据，并将查询视为临时的：当查询进入时，数据库搜索与查询匹配的数据，然后在查询完成时丢掉查询。 CEP引擎反转了角色：查询是长期存储的，来自输入流的事件不断流过它们，搜索匹配事件模式的查询 流分析：使用流处理的另一个领域是对流进行分析。 CEP与流分析之间的边界是模糊的，但一般来说，分析往往对找出特定事件序列并不关心，而更关注大量事件上的聚合与统计指标 维护物化视图：事件溯源中，应用程序的状态是通过应用（apply）事件日志来维护的；这里的应用状态也是一种物化视图。与流分析场景不同的是，仅考虑某个时间窗口内的事件通常是不够的：构建物化视图可能需要任意时间段内的所有事件 在流上搜索：除了允许搜索由多个事件构成模式的CEP外，有时也存在基于复杂标准（例如全文搜索查询）来搜索单个事件的需求。 消息传递和RPC：消息传递系统可以作为RPC的替代方案，即作为一种服务间通信的机制，比如在Actor模型中所使用的那样。尽管这些系统也是基于消息和事件，但我们通常不会将其视作流处理组件：1）Actor框架主要是管理模块通信的并发和分布式执行的一种机制，而流处理主要是一种数据管理技术。2）Actor之间的交流往往是短暂的，一对一的；而事件日志则是持久的，多订阅者的。3）Actor可以以任意方式进行通信（允许包括循环的请求/响应），但流处理通常配置在无环流水线中，其中每个流都是一个特定作业的输出，由良好定义的输入流中派生而来。 Apache Storm有一个称为分布式RPC的功能，它允许将用户查询分散到一系列也处理事件流的节点上；然后这些查询与来自输入流的事件交织，而结果可以被汇总并发回给用户 时间推理 许多流处理框架使用处理机器上的本地系统时钟（处理时间（processing time））来确定窗口【79】。这种方法的优点是简单，事件创建与事件处理之间的延迟可以忽略不计。然而，如果存在任何显著的处理延迟 —— 即，事件处理显著地晚于事件实际发生的时间，处理就失效了。 用事件时间来定义窗口的一个棘手的问题是，你永远也无法确定是不是已经收到了特定窗口的所有事件，还是说还有一些事件正在来的路上。 要校正不正确的设备时钟，一种方法是记录三个时间戳【82】：事件发生的时间，取决于设备时钟；事件发送往服务器的时间，取决于设备时钟；事件被服务器接收的时间，取决于服务器时钟：通过从第三个时间戳中减去第二个时间戳，可以估算设备时钟和服务器时钟之间的偏移（假设网络延迟与所需的时间戳精度相比可忽略不计）。然后可以将该偏移应用于事件时间戳，从而估计事件实际发生的真实时间（假设设备时钟偏移在事件发生时与送往服务器之间没有变化） 窗口的类型 滚动窗口（Tumbling Window）：滚动窗口有着固定的长度，每个事件都仅能属于一个窗口。例如，假设你有一个1分钟的滚动窗口，则所有时间戳在10:03:00和10:03:59之间的事件会被分组到一个窗口中，10:04:00和10:04:59之间的事件被分组到下一个窗口，依此类推。通过将每个事件时间戳四舍五入至最近的分钟来确定它所属的窗口，可以实现1分钟的滚动窗口。 跳动窗口（Hopping Window）：跳动窗口也有着固定的长度，但允许窗口重叠以提供一些平滑。例如，一个带有1分钟跳跃步长的5分钟窗口将包含10:03:00至10:07:59之间的事件，而下一个窗口将覆盖10:04:00至10:08之间的事件： 59，等等。通过首先计算1分钟的滚动窗口，然后在几个相邻窗口上进行聚合，可以实现这种跳动窗口。 滑动窗口（Sliding Window）：滑动窗口包含了彼此间距在特定时长内的所有事件。例如，一个5分钟的滑动窗口应当覆盖10:03:39和10:08:12的事件，因为它们相距不超过5分钟（注意滚动窗口与步长5分钟的跳动窗口可能不会把这两个事件分组到同一个窗口中，因为它们使用固定的边界）。通过维护一个按时间排序的事件缓冲区，并不断从窗口中移除过期的旧事件，可以实现滑动窗口。 会话窗口（Session window）：与其他窗口类型不同，会话窗口没有固定的持续时间，而定义为：将同一用户出现时间相近的所有事件分组在一起，而当用户一段时间没有活动时（例如，如果30分钟内没有事件）窗口结束。会话切分是网站分析的常见需求（参阅“GROUP BY”）。 流式连接 流流连接（窗口连接）： 为了实现这种类型的连接，流处理器需要维护状态：例如，按会话ID索引最近一小时内发生的所有事件。无论何时发生搜索事件或点击事件，都会被添加到合适的索引中，而流处理器也会检查另一个索引是否有具有相同会话ID的事件到达。如果有匹配事件就会发出一个表示搜索结果被点击的事件；如果搜索事件直到过期都没看见有匹配的点击事件，就会发出一个表示搜索结果未被点击的事件。 流表连接（流扩展）：与批处理作业的区别在于，批处理作业使用数据库的时间点快照作为输入，而流处理器是长时间运行的，且数据库的内容可能随时间而改变，所以流处理器数据库的本地副本需要保持更新。这个问题可以通过变更数据捕获来解决：流处理器可以订阅用户档案数据库的更新日志，如同活跃事件流一样。当增添或修改档案时，流处理器会更新其本地副本。因此，我们有了两个流之间的连接：活动事件和档案更新。流表连接实际上非常类似于流流连接；最大的区别在于对于表的变更日志流，连接使用了一个可以回溯到“时间起点”的窗口（概念上是无限的窗口），新版本的记录会覆盖更早的版本。对于输入的流，连接可能压根儿就没有维护窗口。 表表连接（维护物化视图）：两个输入流都是数据库变更日志。在这种情况下，一侧的每一个变化都与另一侧的最新状态相连接。结果是两表连接所得物化视图的变更流。 观察这个流处理过程的另一种视角是：它维护了一个连接了两个表（推文与关注）的物化视图， 连接的时间依赖性：如果跨越流的事件顺序是未定的，则连接会变为不确定性的【87】，这意味着你在同样输入上重跑相同的作业未必会得到相同的结果：当你重跑任务时，输入流上的事件可能会以不同的方式交织。在数据仓库中，这个问题被称为缓慢变化的维度（slowly changing dimension, SCD），通常通过对特定版本的记录使用唯一的标识符来解决：例如，每当税率改变时都会获得一个新的标识符，而发票在销售时会带有税率的标识符【88,89】。这种变化使连接变为确定性的，但也会导致日志压缩无法进行：表中所有的记录版本都需要保留。 容错 微批量与存档点：一个解决方案是将流分解成小块，并像微型批处理一样处理每个块。这种方法被称为微批次（microbatching），它被用于Spark Streaming 【91】。批次的大小通常约为1秒，这是对性能妥协的结果：较小的批次会导致更大的调度与协调开销，而较大的批次意味着流处理器结果可见之前的延迟要更长。 Apache Flink则使用不同的方法，它会定期生成状态的滚动存档点并将其写入持久存储【92,93】。如果流算子崩溃，它可以从最近的存档点重启，并丢弃从最近检查点到崩溃之间的所有输出。存档点会由消息流中的壁障（barrier）触发，类似于微批次之间的边界，但不会强制一个特定的窗口大小。 在流处理框架的范围内，微批次与存档点方法提供了与批处理一样的恰好一次语义。但是，只要输出离开流处理器（例如，写入数据库，向外部消息代理发送消息，或发送电子邮件），框架就无法抛弃失败批次的输出了。在这种情况下，重启失败任务会导致外部副作用发生两次，只有微批次或存档点不足以阻止这一问题。 原子提交再现：为了在出现故障时表现出恰好处理一次的样子，我们需要确保事件处理的所有输出和副作用当且仅当处理成功时才会生效。这些影响包括发送给下游算子或外部消息传递系统（包括电子邮件或推送通知）的任何消息，任何数据库写入，对算子状态的任何变更，以及对输入消息的任何确认（包括在基于日志的消息代理中将消费者偏移量前移）我们讨论了分布式事务传统实现中的问题（如XA）。然而在限制更为严苛的环境中，也是有可能高效实现这种原子提交机制的。 Google Cloud Dataflow【81,92】和VoltDB 【94】中使用了这种方法，Apache Kafka有计划加入类似的功能【95,96】。与XA不同，这些实现不会尝试跨异构技术提供事务，而是通过在流处理框架中同时管理状态变更与消息传递来内化事务。事务协议的开销可以通过在单个事务中处理多个输入消息来分摊。 幂等性（idempotence）： 幂等操作是多次重复执行与单次执行效果相同的操作。例如，将键值存储中的某个键设置为某个特定值是幂等的（再次写入该值，只是用同样的值替代），而递增一个计数器不是幂等的（再次执行递增意味着该值递增两次）。即使一个操作不是天生幂等的，往往可以通过一些额外的元数据做成幂等的。 失败后重建状态：一种选择是将状态保存在远程数据存储中，并进行复制，然而正如在“流表连接”中所述，每个消息都要查询远程数据库可能会很慢。另一种方法是在流处理器本地保存状态，并定期复制。然后当流处理器从故障中恢复时，新任务可以读取状态副本，恢复处理而不丢失数据。Flink定期捕获算子状态的快照，并将它们写入HDFS等持久存储中【92,93】。 Samza和Kafka Streams通过将状态变更发送到具有日志压缩功能的专用Kafka主题来复制状态变更，这与变更数据捕获类似【84,100】。 VoltDB通过在多个节点上对每个输入消息进行冗余处理来复制状态。在某些情况下，甚至可能都不需要复制状态，因为它可以从输入流重建。然而，所有这些权衡取决于底层基础架构的性能特征：在某些系统中，网络延迟可能低于磁盘访问延迟，网络带宽可能与磁盘带宽相当。没有针对所有情况的普世理想权衡，随着存储和网络技术的发展，本地状态与远程状态的优点也可能会互换。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/arch/ddia-5.html":{"url":"note/arch/ddia-5.html","title":"DDIA笔记5","keywords":"","body":" 第十二章 数据系统的未来 组合使用衍生数据的工具 批处理与流处理 分拆数据库 信任但验证 做正确的事 第十二章 数据系统的未来 组合使用衍生数据的工具 理解数据流 在“使系统保持同步”中接触过集成数据系统的问题。随着数据不同表示形式的增加，集成问题变得越来越困难 如果您可以通过单个系统来提供所有用户输入，从而决定所有写入的排序，则通过按相同顺序处理写入，可以更容易地衍生出其他数据表示。 这是状态机复制方法的一个应用，我们在“全序广播”中看到。无论您使用变更数据捕获还是事件源日志，都不如仅对全局顺序达成共识更重要。 衍生数据与分布式事务 基于事件日志来更新衍生数据的系统，通常可以做到确定性与幂等性，使得从故障中恢复相当容易。与分布式事务相比，使用衍生数据系统的方法如何？ 在抽象层面，它们通过不同的方式达到类似的目标。分布式事务通过锁进行互斥来决定写入的顺序，而CDC和事件溯源使用日志进行排序。分布式事务使用原子提交来确保变更只生效一次，而基于日志的系统通常基于确定性重试和幂等性。 最大的不同之处在于事务系统通常提供线性一致性，这包含着有用的保证，例如读己之写。另一方面，衍生数据系统通常是异步更新的，因此它们默认不会提供相同的时序保证。 我相信为分布式事务设计一种更好的协议(类似XA)是可行的。但使这样一种协议被现有工具广泛接受是很有挑战的，且不是立竿见影的事。在没有广泛支持的良好分布式事务协议的情况下，我认为基于日志的衍生数据是集成不同数据系统的最有前途的方法。 全局有序的限制 在大多数情况下，构建完全有序的日志，需要所有事件汇集于决定顺序的单个领导节点。如果事件吞吐量大于单台计算机的处理能力，则需要将其分割到多台计算机上。然后两个不同分区中的事件顺序关系就不明确了。 如果服务器分布在多个地理位置分散的数据中心上，例如为了容忍整个数据中心掉线，您通常在每个数据中心都有单独的主库，因为网络延迟会导致同步的跨数据中心协调效率低下。这意味着源自两个不同数据中心的事件顺序未定义。 将应用程序部署为微服务时，常见的设计选择是将每个服务及其持久状态作为独立单元进行部署，服务之间不共享持久状态。当两个事件来自不同的服务时，这些事件间的顺序未定义。 某些应用程序在客户端保存状态，该状态在用户输入时立即更新（无需等待服务器确认），甚至可以继续脱机工作。有了这样的应用程序，客户端和服务器很可能以不同的顺序看到事件。 排序事件以捕捉因果关系 但是如果好友关系状态与消息存储在不同的地方，在这样一个系统中，可能会出现解除好友事件与发送消息事件之间的因果依赖丢失的情况。如果因果依赖关系没有被捕捉到，则发送有关新消息的通知的服务可能会在解除好友事件之前处理发送消息事件，从而错误地向前任发送通知。批处理与流处理 应用演化后重新处理数据：衍生视图允许渐进演化（gradual evolution）。如果你想重新构建数据集，不需要执行迁移，例如突然切换。取而代之的是，你可以将旧架构和新架构并排维护为相同基础数据上的两个独立衍生视图。然后可以开始将少量用户转移到新视图，以测试其性能并发现任何错误，而大多数用户仍然会被路由到旧视图。你可以逐渐地增加访问新视图的用户比例，最终可以删除旧视图 Lambda架构 Lambda架构的核心思想是通过将不可变事件附加到不断增长的数据集来记录传入数据，这类似于事件溯源。为了从这些事件中衍生出读取优化的视图， Lambda架构建议并行运行两个不同的系统：批处理系统（如Hadoop MapReduce）和独立的流处理系统（如Storm）。 在Lambda方法中，流处理器消耗事件并快速生成对视图的近似更新；批处理器稍后将使用同一组事件并生成衍生视图的更正版本。这个设计背后的原因是批处理更简单，因此不易出错，而流处理器被认为是不太可靠和难以容错的。而且，流处理可以使用快速近似算法，而批处理使用较慢的精确算法。 统一批处理和流处理分拆数据库 Unix和关系数据库以非常不同的哲学来处理信息管理问题。 Unix认为它的目的是为程序员提供一种相当低层次的硬件的逻辑抽象，而关系数据库则希望为应用程序员提供一种高层次的抽象，以隐藏磁盘上数据结构的复杂性，并发性，崩溃恢复以及等等。 Unix发展出的管道和文件只是字节序列，而数据库则发展出了SQL和事务。哪种方法更好？当然这取决于你想要的是什么。 Unix是“简单的”，因为它是硬件资源相当薄的包装；关系数据库是“更简单”的，因为一个简短的声明性查询可以利用很多强大的基础设施（查询优化，索引，连接方法，并发控制，复制等），而不需要查询的作者理解其实现细节。 联合数据库：统一读取可以为各种各样的底层存储引擎和处理方法提供一个统一的查询接口 —— 一种称为联合数据库（federated database）或多态存储（polystore）的方法。例如，PostgreSQL的外部数据包装器功能符合这种模式。需要专用数据模型或查询接口的应用程序仍然可以直接访问底层存储引擎，而想要组合来自不同位置的数据的用户可以通过联合接口轻松完成操作。联合查询接口遵循着单一集成系统与关系型模型的传统，带有高级查询语言和优雅的语义，但实现起来非常复杂。 分拆数据库：统一写入虽然联合能解决跨多个不同系统的只读查询问题，但它并没有很好的解决跨系统同步写入的问题。我们说过，在单个数据库中，创建一致的索引是一项内置功能。当我们构建多个存储系统时，我们同样需要确保所有数据变更都会在所有正确的位置结束，即使在出现故障时也是如此。将存储系统可靠地插接在一起（例如，通过变更数据捕获和事件日志）更容易，就像将数据库的索引维护功能以可以跨不同技术同步写入的方式分开。 传统的同步写入方法需要跨异构存储系统的分布式事务，我认为这是错误的解决方案。单个存储或流处理系统内的事务是可行的，但是当数据跨越不同技术之间的边界时，我认为具有幂等写入的异步事件日志是一种更加健壮和实用的方法。 基于日志的集成的一大优势是各个组件之间的松散耦合（loose coupling），这体现在两个方面： 在系统级别，异步事件流使整个系统对各个组件的中断或性能下降更加稳健。如果使用者运行缓慢或失败，那么事件日志可以缓冲消息，以便生产者和任何其他使用者可以继续不受影响地运行。有问题的消费者可以在固定时赶上，因此不会错过任何数据，并且包含故障。相比之下，分布式事务的同步交互往往会将本地故障升级为大规模故障。 在人力方面，分拆数据系统允许不同的团队独立开发，改进和维护不同的软件组件和服务。专业化使得每个团队都可以专注于做好一件事，并与其他团队的系统以明确的接口交互。事件日志提供了一个足够强大的接口，以捕获相当强的一致性属性（由于持久性和事件的顺序），但也足够普适于几乎任何类型的数据。 在维护衍生数据时，状态变更的顺序通常很重要（如果多个视图是从事件日志衍生的，则需要按照相同的顺序处理事件，以便它们之间保持一致）。如“确认与重传”中所述，许多消息代理在重传未确认消息时没有此属性，双写也被排除在外。 容错是衍生数据的关键：仅仅丢失单个消息就会导致衍生数据集永远与其数据源失去同步。消息传递和衍生状态更新都必须可靠。例如，许多Actor系统默认在内存中维护Actor的状态和消息，所以如果运行Actor的机器崩溃，状态和消息就会丢失。 在微服务方法中，处理购买的代码可能会查询汇率服务或数据库，以获取特定货币的当前汇率。 在数据流方法中，处理订单的代码会提前订阅汇率变更流，并在汇率发生变动时将当前汇率存储在本地数据库中。处理订单时只需查询本地数据库即可。 第二种方法能将对另一服务的同步网络请求替换为对本地数据库的查询（可能在同一台机器甚至同一个进程中）。数据流方法不仅更快，而且当其他服务失效时也更稳健。最快且最可靠的网络请求就是压根没有网络请求！我们现在不再使用RPC，而是在购买事件和汇率更新事件之间建立流联接。 在微服务方法中，你也可以通过在处理购买的服务中本地缓存汇率来避免同步网络请求。 但是为了保证缓存的新鲜度，你需要定期轮询汇率以获取其更新，或订阅变更流 —— 这恰好是数据流方法中发生的事情。 事务在某些领域被完全抛弃，并被提供更好性能与可扩展性的模型取代，但更复杂的语义。一致性（Consistency）经常被谈起，但其定义并不明确。有些人断言我们应当为了高可用而“拥抱弱一致性”，但却对这些概念实际上意味着什么缺乏清晰的认识。 如果你的应用可以容忍偶尔的崩溃，以及以不可预料的方式损坏或丢失数据，那生活就要简单得多，而你可能只要双手合十念阿弥陀佛，期望佛祖能保佑最好的结果。另一方面，如果你需要更强的正确性保证，那么可序列化与原子提交就是久经考验的方法，但它们是有代价的：它们通常只在单个数据中心中工作（排除地理散布式架构），并限制了系统能够实现的规模与容错特性。 操作标识符 要在通过几跳的网络通信上使操作具有幂等性，仅仅依赖数据库提供的事务机制是不够的 —— 你需要考虑端到端（end-to-end）的请求流。 例如，你可以为操作生成一个唯一的标识符（例如UUID），并将其作为隐藏表单字段包含在客户端应用中，或通过计算所有表单相关字段的散列来生成操作ID 。如果Web浏览器提交了两次POST请求，这两个请求将具有相同的操作ID。然后，你可以将该操作ID一路传递到数据库，并检查你是否曾经使用给定的ID执行过一个操作，如例12-2中所示。 达成这一共识的最常见方式是使单个节点作为领导，并使其负责所有决策。只要你不介意所有请求都挤过单个节点（即使客户端位于世界的另一端），只要该节点没有失效，系统就能正常工作。如果你需要容忍领导者失效，那么就又回到了共识问题（参阅“单领导者复制与共识”）。 更一般地来讲，我认为术语一致性（consistency）这个术语混淆了两个值得分别考虑的需求： 及时性（Timeliness）及时性意味着确保用户观察到系统的最新状态。我们之前看到，如果用户从陈旧的数据副本中读取数据，它们可能会观察到系统处于不一致的状态（参阅“复制延迟问题”）。但这种不一致是暂时的，而最终会通过等待与重试简单地得到解决。CAP定理（参阅“线性一致性的代价”）使用线性一致性（linearizability）意义上的一致性，这是实现及时性的强有力方法。像写后读这样及时性更弱的一致性也很有用（参阅“读己之写”）也很有用。 完整性（Integrity）完整性意味着没有损坏；即没有数据丢失，并且没有矛盾或错误的数据。尤其是如果某些衍生数据集是作为底层数据之上的视图而维护的（参阅“从事件日志导出当前状态”），这种衍生必须是正确的。例如，数据库索引必须正确地反映数据库的内容 —— 缺失某些记录的索引并不是很有用。 如果完整性被违背，这种不一致是永久的：在大多数情况下，等待与重试并不能修复数据库损坏。相反的是，需要显式地检查与修复。在ACID事务的上下文中（参阅“ACID的涵义”），一致性通常被理解为某种特定于应用的完整性概念。原子性和持久性是保持完整性的重要工具。 口号形式：违反及时性，“最终一致性”；违反完整性，“永无一致性”。 另一方面，对于在本章中讨论的基于事件的数据流系统而言，它们的一个有趣特性就是将及时性与完整性分开。在异步处理事件流时不能保证及时性，除非你显式构建一个在返回之前明确等待特定消息到达的消费者。但完整性实际上才是流处理系统的核心。 恰好一次或等效一次语义是一种保持完整性的机制。如果事件丢失或者生效两次，就有可能违背数据系统的完整性。因此在面对故障时，容错消息传递与重复抑制（例如，幂等操作）对于维护数据系统的完整性是很重要的。 正如我们在上一节看到的那样，可靠的流处理系统可以在无需分布式事务与原子提交协议的情况下保持完整性，这意味着它们能潜在地实现好得多的性能与运维稳健性，在达到类似正确性的前提下。为了达成这种正确性，我们组合使用了多种机制： 将写入操作的内容表示为单条消息，从而可以轻松地被原子写入 —— 与事件溯源搭配效果拔群 使用与存储过程类似的确定性衍生函数，从这一消息中衍生出所有其他的状态变更 将客户端生成的请求ID传递通过所有的处理层次，从而启用端到端除重，带来幂等性。 使消息不可变，并允许衍生数据能随时被重新处理，这使从错误中恢复更加容易 这种机制组合在我看来，是未来构建容错应用的一个非常有前景的方向。 然而另一个需要了解的事实是，许多真实世界的应用实际上可以摆脱这种形式，接受弱得多的唯一性： 如果两个人同时注册了相同的用户名或预订了相同的座位，你可以发送其中一个发消息道歉，并要求他们选择一个不同的用户名。这种纠正错误的变化被称为补偿性事务（compensating transaction）。 如果客户订购的物品多于仓库中的物品，你可以下单补仓，并为延误向客户道歉，向他们提供折扣。实际上，这么说吧，如果在叉车在仓库中轧过了你的货物，剩下的货物比你想象的要少，那么你也是得这么做。因此，既然道歉工作流无论如何已经成为你商业过程中的一部分了，那么对库存物品数目添加线性一致的约束可能就没必要了。 与之类似，许多航空公司都会超卖机票，打着一些旅客可能会错过航班的算盘；许多旅馆也会超卖客房，抱着部分客人可能会取消预订的期望。在这些情况下，出于商业原因而故意违反了“一人一座”的约束；当需求超过供给的情况出现时，就会进入补偿流程（退款、升级舱位/房型、提供隔壁酒店的免费的房间）。即使没有超卖，为了应对由恶劣天气或员工罢工导致的航班取消，你还是需要道歉与补偿流程 —— 从这些问题中恢复仅仅是商业活动的正常组成部分。 如果有人从账户超额取款，银行可以向他们收取透支费用，并要求他们偿还欠款。通过限制每天的提款总额，银行的风险是有限的。 我们现在做了两个有趣的观察： 数据流系统可以维持衍生数据的完整性保证，而无需原子提交，线性一致性，或者同步跨分区协调。 虽然严格的唯一性约束要求及时性和协调，但许多应用实际上可以接受宽松的约束：只要整个过程保持完整性，这些约束可能会被临时违反并在稍后被修复。 总之这些观察意味着，数据流系统可以为许多应用提供无需协调的数据管理服务，且仍能给出很强的完整性保证。这种无协调（coordination-avoiding）的数据系统有着很大的吸引力：比起需要执行同步协调的系统，它们能达到更好的性能与更强的容错能力。 我们讨论了如何确保所有这些处理在出现故障时保持正确。我们看到可扩展的强完整性保证可以通过异步事件处理来实现，通过使用端到端操作标识符使操作幂等，以及通过异步检查约束。客户端可以等到检查通过，或者不等待继续前进，但是可能会冒有违反约束需要道歉的风险。这种方法比使用分布式事务的传统方法更具可扩展性与可靠性，并且在实践中适用于很多业务流程。信任但验证 例如，我们应该假设进程可能会崩溃，机器可能突然断电，网络可能会任意延迟或丢弃消息。但是我们也可能假设写入磁盘的数据在执行fsync后不会丢失，内存中的数据没有损坏，而CPU的乘法指令总是能返回正确的结果。 因为大多数时候它们都是成立的，如果我们不得不经常担心计算机出错，那么基本上寸步难行。在传统上，系统模型采用二元方法处理故障：我们假设有些事情可能会发生，而其他事情永远不会发生。实际上，这更像是一个概率问题：有些事情更有可能，其他事情不太可能。问题在于违反我们假设的情况是否经常发生，以至于我们可能在实践中遇到它们。 检查数据系统的完整性，最好是以端到端的方式进行（参阅“数据库的端到端争论”）：我们能在完整性检查中涵盖的系统越多，某些处理阶中出现不被察觉损坏的几率就越小。 密码学审计与完整性检查通常依赖默克尔树（Merkle tree），这是一颗散列值的树，能够用于高效地证明一条记录出现在一个数据集中（以及其他一些特性）。除了炒作的沸沸扬扬的加密货币之外，证书透明性（certificate transparency）也是一种依赖Merkle树的安全技术，用来检查TLS/SSL证书的有效性。做正确的事 软件开发越来越多地涉及重要的道德抉择。有一些指导原则可以帮助软件工程师解决这些问题，例如ACM的软件工程道德规范与专业实践，但实践中很少会讨论这些，更不用说应用与强制执行了。因此，工程师和产品经理有时会对隐私与产品潜在的负面后果抱有非常傲慢的态度。 自动决策引发了关于责任与问责的问题。如果一个人犯了错误，他可以被追责，受决定影响的人可以申诉。算法也会犯错误，但是如果它们出错，谁来负责？ 即使是那些对人直接影响比较小的预测性应用，比如推荐系统，也有一些必须正视的难题。当服务变得善于预测用户想要看到什么内容时，它最终可能只会向人们展示他们已经同意的观点，将人们带入滋生刻板印象，误导信息，与极端思想的回音室。我们已经看到过社交媒体回音室对竞选的影响了。 除了预测性分析 —— 即使用数据来做出关于人的自动决策 —— 数据收集本身也存在道德问题。收集数据的组织，与被收集数据的人之间，到底属于什么关系？ var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/arch/about-consistency.html":{"url":"note/arch/about-consistency.html","title":"关于一致性","keywords":"","body":"关于一致性 一致性模型 『一致性』关注的是分布式系统中不同实体之间数据或者状态的一致程度；而从实际的角度来看，『一致性』其实反映了系统对 client 提供的服务所表现出的特征。 一般而言，分布式系统中的一致性按照从强到若可以分为四种： Linearizability (Strong consistency or Atomic consistency) 线性一致性又被称为强一致性或者原子一致性 Sequential consistency Causal consistency Eventual consistency var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/liyunhua/":{"url":"note/liyunhua/","title":"从0开始学架构","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/liyunhua/learn-arch-from-zero-1.html":{"url":"note/liyunhua/learn-arch-from-zero-1.html","title":"从0开始学架构1","keywords":"","body":"作者：李运华 01 架构是什么 作者的定义：软件架构指软件系统的顶层结构。 架构是顶层设计；框架是面向编程或配置的半成品；组件是从技术维度上的复用；模块是从业务维度上职责的划分；系统是相互协同可运行的实体。 02 架构设计的历史背景 第一次软件危机与结构化程序设计(20世纪60年代~20世纪70年代)：结构化程序设计的主要特点是抛弃 goto 语句，采取“自顶向下、逐步细化、模块化”的指导思想。 第二次软件危机与面向对象(20世纪80年代)：主要体现在软件的“扩展”变得非常复杂。 布鲁克斯发表《人月神话》三十年后，又写了《设计原本》。他认为一个成功的软件项目的最重要因素就是设计，架构师、设计师需要在业务需求和IT技术中寻找到一个平衡点。 软件设计过程中，模块、对象、组件本质上是对一定规模软件在不同粒度和层次上的“拆分”方法论，软件架构是一种对软件的“组织”方法论。 03 架构设计的目的 架构设计的主要目的是为了解决软件系统复杂度带来的问题。 架构抉择的主要因素：性能、可扩展性、高可用、安全性、成本（时间、人力）等方面的量化需求（要求）。 04 高性能 多核计算机架构：SMP(Symmetric Multi-Processor，对称多处理器结构)、NUMA(Non-Uniform Memory Access，非一致存储访问结构)、MPP(Massive Parallel Processing，海量并行处理结构)。其中SMP是我们最常见的，目前流行的多核处理器就是SMP方案。 任务分配器：常见的方法包括DNS轮询、智能DNS、CDN(Content Delivery Network，内容分发网络)、GSLB设备(Global Server Load Balance，全局负载均衡)等。 假设这些系统采用IP网络连接，理想情况下一次请求和响应在网络上耗费为1ms，业务处理本身耗时为50ms。 为什么要拆分为子系统 简单的系统更加容易做到高性能 可以针对单个任务进行扩展 05 高可用 系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。 从广州机房到北京机房，稳定情况下ping延时大约是50ms，不稳定情况下可能达到1s甚至更多。 06 可扩展性 正确预测变化、完美封装变化。 07 低成本、安全、规模 常见的 XSS 攻击、CSRF 攻击、SQL 注入、Windows 漏洞、密码破解。 传统企业主要通过防火墙实现不同区域的访问控制，功能强大、性能一般，但是成本更高。互联网企业更多地是依靠运营商或者云服务商强大的带宽和流量清洗的能力，较少自己来设计和实现。 目前的大数据理论基础是 Google 发表的三篇大数据相关论文，其中 Google File System 是大数据文件存储的技术理论，Google Bigtable 是列式数据存储的技术理论，Google MapReduce 是大数据运算的技术理论。 08 架构设计三原则 合适原则：合适优于业界领先 简单原则：简单优于复杂 结构复杂性：模块太多，模块关联太复杂 逻辑复杂性：模块少，单个模块的复杂性太高，带来问题 演化原则：演化优于一步到位 首先，设计出来的架构要满足当时的业务需要 其次，架构要不断地在实际应用过程中迭代，保留优秀的设计，修复有缺陷的设计，改正错误的设计，去掉无用的设计，使得架构逐渐完善 第三，当业务发生变化时，架构要扩展、重构，甚至重写；代码也许会重写，但有价值的经验、教训、逻辑、设计等(类似生物体内的基因)却可以在新架构中延续 09 架构设计原则案例 淘宝 和 QQ 的架构演进 10 架构设计流程：识别复杂度 正确的做法是将主要的复杂度问题列出来，然后根据业务、技术、团队等综合情况进行排序，优先解决当前面临的最主要的复杂度问题 对于架构师来说，常见系统的性能量级需要烂熟于心，例如，nginx负载均衡性能是3万左右， memcache的读取性能5万左右，kafka号称百万级，zookeeper写入读取2万以上，http请求访问大概在2万左右。 架构师推动是主要的，架构师需要五项全能：技术，沟通，推动，管理，撕逼 11 架构设计流程：设计备选方案 第一种常见的错误：设计最优秀的方案 第二种常见的错误：只做一个方案 备选方案的数量以 3~5 个为最佳。少于 3 个方案可能是因为思维狭隘，考虑不周全；多于 5 个则需要耗费大量的精力和时间，并且方案之间的差别可能不明显。 备选方案的差异要比较明显。例如，主备方案和集群方案差异就很明显，或者同样是主备方案，用 ZooKeeper 做主备决策和用 Keepalived 做主备决策的差异也很明显。 备选方案的技术不要只局限于已经熟悉的技术。设计架构时，架构师需要将视野放宽，考虑更多可能性。架构师对 MySQL 很熟悉，因此不管什么存储都基于 MySQL 去设计方案，系统性能不够了，首先考虑的就是 MySQL 分库分表，而事实上也许引入一个 Memcache 缓存就能够解决问题 第三种常见的错误：备选方案过于详细 架构师的技术储备越丰富、经验越多，备选方案也会更多，从而才能更好地设计备选方案。例如，开源方案选择可能就包括 Kafka、ActiveMQ、RabbitMQ;集群方案的存储既可以考虑用MySQL， 也可以考虑用HBase，还可以考虑用 Redis 与 MySQL 结合等；自研文件系统也可以有多个， 可以参考 Kafka，也可以参考 LevelDB，还可以参考 HBase 等 12 架构设计流程：评估和选择备选方案 列出我们需要关注的质量属性点，然后分别从这些质量属性的维度去评估每个方案，再综合挑选适合当时情况的最优方案 常见的方案质量属性点有:性能、可用性、硬件成本、项目投入、复杂度、安全性、可扩展性等。在评估这些质量属性时，需要遵循架构设计原则 1“合适原则”和原则 2“简单原则”，避免贪大求全，基本上某个质量属性能够满足一定时期内业务发展就可以了 引入开源方案工作量小，但是可运维性和可扩展性差；自研工作量大，但是可运维和可维护性好 RocketMQ 和 Kafka 有什么区别 Kafka适合日志处理；RocketMQ适合业务处理 Kafka单机写入TPS号称在百万条/秒；RocketMQ大约在10万条/秒。Kafka单机性能更高。 均支持pull长轮询，RocketMQ消息实时性更好 Kafka单机超过64个队列/分区，消息发送性能降低严重；RocketMQ单机支持最高5万个队列，性能稳定(这也是适合业务处理的原因之一) 数据可靠性：kafka使用异步刷盘方式，异步Replication；RocketMQ支持异步刷盘，同步刷盘，同步Replication，异步Replication 严格的消息顺序：Kafka支持消息顺序，但是一台Broker宕机后，就会产生消息乱序；RocketMQ支持严格的消息顺序，在顺序消息场景下，一台Broker宕机后，发送消息会失败，但是不会乱序 Kafka消费失败不支持重试，RocketMQ消费失败支持定时重试，每次重试间隔时间顺延 消费失败重试机制：定时消息：Kafka不支持定时消息，RocketMQ支持定时消息 Kafka不支持分布式事务消息，阿里云ONS支持分布式定时消息，未来开源版本的RocketMQ也有计划支持分布式事务消息 消息查询机制：Kafka不支持消息查询，RocketMQ支持根据Message Id查询消息，也支持根据消息内容查询消息(发送消息时指定一个Message Key，任意字符串，例如指定为订单Id) 消息回溯：Kafka理论上可以按照Offset来回溯消息；RocketMQ支持按照时间来回溯消息，精度毫秒，例如从一天之前的某时某分某秒开始重新消费消息 13 架构设计流程：详细方案设计 Nginx 的负载均衡策略，备选有轮询、权重分配、ip_hash、fair、url_hash 五个，具体选哪个呢？ 详细设计方案阶段可能遇到的一种极端情况就是在详细设计阶段发现备选方案不可行，一般情况下主要的原因是备选方案设计时遗漏了某个关键技术点或者关键的质量属性 架构师不但要进行备选方案设计和选型，还需要对备选方案的关键细节有较深入的理解，如es的索性设计就是关键设计点 就一些新的技术引入，架构师需要做哪些技术验证，或者研究到什么深度以后，才认为该技术适合呢?作者回复：基本原理，优点缺点，关键设计点，架构师至少要安装过，编写demo体验过，确定选型后，要进行性能和可用性测试例 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/liyunhua/learn-arch-from-zero-2.html":{"url":"note/liyunhua/learn-arch-from-zero-2.html","title":"从0开始学架构2","keywords":"","body":"14 高性能数据库集群：读写分离 mysql 是主从集群，不是主备集群 主从复制延迟的解决 写操作后的读指定发给数据库主服务器 二次读取：读丛机失败后再读一次主机 关键业务读写都指向主机，非关键业务采用读写分离 15 高性能数据库集群：分库分表 降低存储压力 业务分库：按照业务模块将数据分散到不同的数据库服务器 问题：join操作，事务，成本（一般来说单台数据库能支撑10万用户量量级的业务） 分表：有公司要求单表行数超过5000万必须分表 垂直分表、水平分表 问题：join 操作，count 操作，order by 操作 优化顺序 优化硬件，如 HDD 改为 SSD 数据库优化，如增加索引 引入缓存，如 redis 程序和数据库 scheme 优化，重构，减少不必要的查询 分库分表，要有预估 16 高性能 NoSQL 常见 NoSQL KV 存储，如 redis 文档数据库，如 MongoDB 列式数据库，如 HBase 行数据库压缩率一般在 3:1 和 5:1 之间，列数据库压缩率在 8:1 和 30:1 之间，行数据库读取时必须将所有的字段读出来，列数据库可读指定列，减少 IO 次数 全文检索引擎：如 Elasticsearch RDB 文章：当我们聊技术实力的时候，我们到底在聊什么 17 高性能缓存架构 缓存的内容是什么，触发缓存的方式和时机，缓存的层次和粒度，缓存的命名规范和失效规则、缓存监控指标和故障应对方案，缓存可视化（如key大小） 单台 Memcache 服务器的 kv 查询能达到5万 TPS 以上 缓存穿透：数据不存在，缓存数据生成耗费大量时间、资源 缓存雪崩：缓存失效（过期）引起系统性能急剧下降的情况 网友双 key 策略，一个 key 有过期，另一个 key1 无过期，读取 key 时候，如果 key 过期，返回 key1 的值，并触发事件同时更新 key 和 key1 缓存预热：系统上线后将数据直接加入到缓存系统 缓存热点：复制多份缓存副本，随机访问其中一个，不要设置统一的过期时间 18 单服务器高性能模式 PPC与TPC PPC：Process Per Connection 一个子进程服务一次请求，fork 代价太大 prefork，多个子进程 accept 同一个 socket，惊群现象，Linux2.6版本已经解决 适合数据库，中间件之类的，不会因为进程hang住而崩溃 TPC：Thread Per Connection prethread，Apache 服务器的MPM worker 本质上就是一种 prethread 方案，具体是先创建多个进程，每个进程创建多个线程 响应时间（RT），并发数（Concurrency），吞吐量（TPS），吞吐量=并发数/平均响应时间 三高系统，如秒杀、即时通讯不能使用 三低系统，如ToB，运营类、管理类系统一般可以使用 高吞吐量系统，如果以内存计算为主，一般可以使用，如果是网络IO为主，一般不使用 适用于吞吐量大，长连接且连接数不多的系统，不支持高并发 19 单服务器高性能模式 Reactor 与 Proactor 两种I/O多路复用模式：Reactor 和 Proactor，Reactor模式采用同步 IO，而Proactor采用异步 IO，异步情况下(Proactor)，当回调handler时，表示IO操作已经完成；同步情况下(Reactor)，回调handler时，表示IO设备可以进行某个操作(can read or can write)。 Reactor 模式也叫 Dispatcher 模式 事件来了我通知你，你来处理 单 Reactor 单线程/进程，如redis 单 Reactor 多线程/进程 多 Reactor 多线程/进程，如Nginx(进程）， Memcache和Netty（线程） Proactor：非阻塞同步网络模型 来了事件我（OS）来处理，处理完了我通知你（应用） 理论上 Proactor 比 Reactor 更高效一些，异步IO能重复利用DMA特性 目前 Windows 下通过IOCP真正实现了异步 IO，Linux 下的 AIO 不完善 20 高性能负载均衡：分类及架构 DNS 负载均衡 简单、成本低；就近访问，提升访问速度 更新不及时，DNS 缓存时间比较长；可扩展性差，控制器在域名商；分配策略比较简单 硬件负载均衡 F5 和 A10 能支持并发100万以上，稳定性好；但贵，扩展能力差 软件负载均衡 nginx：7层负载均衡 LVS：4层负载均衡 HAProxy：SLB 一般一个 linux 上装一个 nginx 大概5万/秒，LVS性能是10万级，据说可以达到80万，F5的性能是百万级，从200万到800万都有 21 高性能负载均衡：算法 轮询 加权轮询 负载最低优先（站在服务器角度分析） 最小连接数优先 CPU负载最低优先 性能最优类（站在客户端角度分析） 实现较复杂，需要根据场景决定具体策略 hash 类 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/liyunhua/learn-arch-from-zero-3.html":{"url":"note/liyunhua/learn-arch-from-zero-3.html","title":"从0开始学架构3","keywords":"","body":"22 必须知道的 CAP 理论 http://robertgreiner.com/2014/08/cap-theorem-revisited/ Consistency - A read is guaranteed to return the most recent write for a given client. 对于某个客户端来说，读操作保证能够返回最新的写操作结果 Availability - A non-failing node will return a reasonable response within a reasonable amount of time (no error or timeout). 一个没有故障的节点在一个合理的时间范围内会返回一个合理的结果（没有超时或错误） Partition Tolerance - The system will continue to function when network partitions occur. 系统在网络分区发生的时候会继续提供功能 zab 的读操作没有满足 CAP 的 C，TODO 23 必须知道的 CAP 细节 CAP：强一致，忽略了同步时间因素 ACID：原子性、一致性（数据不被破坏）、隔离性（并发地执行时）、持久性 隔离性：Read Committed、Snapshot Isolation（也叫 Repeatable Read）、Serializable Isolation（可串行化隔离） BASE：是 CAP 理论中 AP 方案的延伸 24 FMEA 方法，排除架构可用性隐患的利器 墨菲定律：可能出错的事情最终都会出错 FMEA：Failure mode and effects analysis，故障模式与影响分析 给出初始的架构设计图 假设架构中某个部件发生故障 分析此故障对系统功能造成的影响 根据分析结果，判断架构是否需要进行优化 功能点：以用户视角来看 故障模式：故障点与故障形式，只要现象即可 故障影响：对功能点的影响，如功能点偶尔不可用，完全不可用，部分用户功能点不可用，功能点响应缓慢，功能点出错 严重程度：一般分为“致命、高、中、低、无” 故障原因：不同故障原因发生的概率，检测手段，处理措施 故障概率：“高、中、低”，硬件、开源系统、自研系统 风险程度：= 严重程度*故障概率 已有措施：包括检测报警、容错、自恢复等 规避措施：可以是技术手段也可以是管理手段 解决措施：一般是技术手段 后续规划：改进的规划，包括技术手段和管理手段 25 高可用存储架构：双机部署 复杂性主要体现在数据延迟和中断导致数据不一致的问题 主备、主从、主主、集群、分区 主主一般适合于那些临时性、可丢失、可覆盖的数据场景，如登录产生的 session 数据，行为的日志数据，论坛的草稿数据（可丢失）等 26 高可用存储架构：集群和分区 数据集群 数据集中集群 主机如何将数据复制给备机 主机故障后如何确定新机 数据分散集群 均衡性 容错性 可伸缩性，加机器后，数据分区自动迁移到新服务器 数据分区 数据量 分区规则：洲分区、国家分区、城市分区 复制规则 集中式，单独设置一个数据中心用来备份 互备式 独立式：每个数据中心有自己独立的备份中心 27 如何设计计算高可用架构 对称集群：所有机器一样的角色 非对称集群：有 Master Slave 之分 ZooKeeper 机制 任务分配：Follower 收到请求后，会将写请求转发给 Leader，如果是读请求就自己处理 角色指定：当 Leader 故障后，暂停读写操作，直到重新选举出 Leader 后再对外提供服务 28 业务高可用保障：异地多活架构 支付宝等系统，对于余额一般不做跨城异地多活，只采用同城异区（和一个机房差不多），必要的时候可以采取事后补偿机制 跨国异地：如亚马逊中国，亚马逊美国 只读业务做多活 oceanbase 是怎么做的 29 异地多活设计4大技巧 保证核心业务的异地多活：不要把想所有的业务都异地多活 保证核心数据的一致性 不可能完全同步 尽量减少机房间的距离 尽量减少数据同步，只同步核心业务相关的数据 保证最终一致性，不保证实时一致性 采用多种手段同步数据：避免只使用存储系统，如mysql、redis 提供的同步手段 采用多种数据同步手段 消息队列方式： 二次读取方式：A中心数据还没同步到B中心，在B中心读不到，根据路由规则从A中心再读一次 回源读取方式：A中心的 session 数据，在B中心读不到，根据 sessionid 去A中心查 重新生成数据方式：异地session失败，从新登录 只保证绝大部分用户异地多活 30 异地多活设计4步走 业务分级 数据分类，常见的数据分析维度 数据量 唯一性 实时性 可丢失性 可恢复性 数据同步 异常处理：常见异常处理方案 多通道同步，多种方案并存，需要使用不同的网络 同步和访问结合：同步见上一章多种数据同步手段，访问可以优先访问本机房数据，不行再访问异地机房数据 日志记录 用户补偿 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/liyunhua/learn-arch-from-zero-4.html":{"url":"note/liyunhua/learn-arch-from-zero-4.html","title":"从0开始学架构4","keywords":"","body":"31 如何应对接口级故障 降级，应对系统自身的故障，停用部分非重要功能 系统后门降级，如通过访问系统降级 url 实现 独立降级系统 熔断，应对依赖的外部系统故障 需要集中统计接口的调用状况 限流，从用户访问压力方面考虑 基于请求的限流，限制请求量 基于资源的限流，如连接数、文件句柄、线程数、请求队列、CPU 占用率 排队，限流的变种 实现单独的排队模块，调度模块 32 可扩展架构的基本思想和模式 可扩展的基本思想：拆分；合理的拆分，即使程序员出错，会让出错的范围不会太广，影响不会太大 面向流程拆分：分层架构 面向服务拆分：SOA、微服务 面向功能拆分：微内核架构 33 传统的可扩展架构模式：分层架构和SOA 分层结构 C/S B/S MVC 架构、MVP 架构 分层之所以能支持系统扩展，本质在于隔离关注点（separation of concerns） 缺点，性能问题 SOA 解决传统 IT 行业系统重复建设和扩展效率低下的问题，SOA是为了将不同的系统整合起来 三个关键概念 服务 ESB（Enterprise Service Bus），SOA 用 ESB 来屏蔽异构系统对外提供各种不同接口方式 松耦合 缺点：协议转换工作量和复杂度都很大，性能问题 34 深入理解微服务架构：银弹 or 焦油坑？ Martin Fowler 提出？其推动微服务功不可没 微服务和 SOA 的关系 观点：微服务是 SOA 的实现方式，微服务是更细粒度的 SOA 观点：微服务是去掉 ESB 后的 SOA，去掉复杂的 ESB，使用轻量级的 HTTP 观点：微服务是一种和 SOA 相似但本质上不同的架构理念（作者支持这个观点） 对比维度 SOA 微服务 服务粒度 粗 细 服务通讯 重量级，ESB 轻量级，如HTTP RESTful 服务交付 慢 快 应用场景 企业级 互联网 微服务的陷阱 服务划分过细，服务间的关系复杂 服务数量太多，团队效率急剧下降 调用链太长，性能下降 调用链太长，问题定位困难 没有自动化支撑，无法快速交付 没有服务治理，微服务数据量多了后管理混乱 35 微服务架构最佳实践 - 方法篇 服务粒度 两个披萨理论，每个团队的认数不能多到两张披萨都不够吃的地步 三个火枪手：3个人负责一个微服务 拆分方法 基于业务逻辑拆分，需要根据团队人数决定 基于可扩展拆分，稳定的业务和易变化迭代的服务 基于可靠性拆分，按模块优先级排序，好处 避免非核心服务故障影响核心服务 核心服务高可用方案更加简单 降低高可用成本 基于性能拆分 基础设施，按以下优先级来搭建 服务发现、服务路由、服务容错 接口框架、API 网关 自动化测试、自动化部署、配置中心 服务监控、服务跟踪、服务安全 36 微服务架构最佳实践 - 基础设施篇 自动化测试 自动化部署 配置中心 版本管理、增删改查配置、节点管理、配置同步、配置推送等 接口框架 HTTP/REST 或 RPC API 网关 对外部系统的访问 服务发现 自理式：服务A自己访问 Service Registry 获取服务注册信息，然后直接访问服务B 代理式：微服务之间有一个 Load Balancer 系统，该系统可能是瓶颈 服务路由 发现服务后，需要挑出一个具体的节点发起请求 通常和服务发现放在一起 常见算法：随机路由、轮询路由、最小压力路由、最小连接数路由 服务容错 请求重试、流控、服务隔离 通常和服务发现、服务路由放在一起 服务监控 服务跟踪 实现基本基于 Goole 的论文 Dapper, a Large-Scale Distributed Systems Tracing Infrastructure 服务安全 接入安全 数据安全 传输安全 可集成到配置中心实现？ 37 微内核架构详解 微内核架构（Microkernel Architecture）也被称为插件化架构（Plug-in Architecture），包含两类组件：核心系统和插件模块 设计关键点 插件管理，如何加载插件，常用插件注册表（配置文件、代码、数据库都可以） 插件连接，插件如何连接到核心系统 如 OSGi、消息模式、依赖注入、分布式协议等 插件通信 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/liyunhua/learn-arch-from-zero-5.html":{"url":"note/liyunhua/learn-arch-from-zero-5.html","title":"从0开始学架构5","keywords":"","body":"38 架构师应该如何判断技术演进的方向？ 技术流派 潮流派：热衷新技术，紧跟技术潮流 采坑的小白鼠 新技术的学习成本 保守派：对新技术抱有很强的戒心 不能享受新技术的收益 跟风派：跟着竞争对手的步子走 技术演进的动力 产品类，技术创新推动业务发展 服务类，业务发展推动技术发展 技术演进的模式 功能复杂度、规模复杂度 不同阶段不一样 39 互联网技术演进的模式 业务发展：复杂性和用户规模 初创期 快实现 发展期 堆功能期 优化期 优化派：重构、分层、优化，小调整、快速 架构派：将大系统拆分为小系统，动作大，周期长 架构期：拆功能、拆数据库、拆服务器 竞争期 重复造轮子 系统交互一团麻 解决方案 平台化：数据化平台，存储平台，缓存平台 服务化：消息队列，服务框架 成熟期 性能 可用性 40 互联网架构模板：存储层技术 SQL：Mysql、PG、Oracle NoSQL：memchache、redis 小文件存储：淘宝的 TFS、京东的 JFS、Facebook 的 Haystack 大文件存储：Bigtable/Map-Reduce/GFS、HDFS、HBase、Storm、Hive 41 互联网架构模板：开发层和服务层技术 开发层 开发框架：SSH、SpringMVC、Ruby on Rails、ThinkPHP、Django web 服务器：Tomcat、JBoss、Resin、Nginx、Apache 容器技术：Docker 服务层 配置中心 服务中心 服务名字系统（Service Name System） 服务总线系统（Service Bus System） 消息队列 42 互联网架构模板：网络层技术 站在全公司的整体角度看系统 负载均衡 DNS HTTP-DNS 主要用在 app 提供的服务上 Nginx（5万）、LVS（数10万）、F5（200万~800万） CDN 多机房 多中心 43 互联网架构模板：用户层和业务层技术 用户层 用户管理 单点登录 SSO，使用 cookie、JSONP、token 等实现，最成熟的方案 CAS 授权登录：OAuth2 消息推送 短信、邮件、站内信、App推送 iOS：APNS，Android的五花八门 实现要点：设备管理（唯一标识、注册、注销），连接管理和消息管理 技术挑战：海量设备和用户管理，连接保活（应用互相拉起，手机厂商开白名单），消息管理 存储云、云图片 业务层 复杂度提升：拆 分久必合 原则：高内聚，低耦合 Facade 模式 44 互联网架构模板：平台技术 运维平台 功能：配置、部署、监控、应急 要素：标准化、平台化、自动化、可视化 测试平台 单元测试、集成测试、接口测试、性能测试 用例管理、资源管理、任务管理、数据管理 数据平台 数据管理：采集、存储、访问、安全 数据分析：数据挖掘、机器学习、深度学习 数据应用 管理平台 核心职责：权限管理 身份认证 权限控制 45 架构重构内功心法第一式：有的放矢 识别出需要用架构重构来解决的问题，不要想解决所有问题 架构重构 vs 系统优化：如果从0开始设计一个系统，和老架构是否相似？差异大，架构重构 46 架构重构内功心法第二式：合纵连横 合纵：用大家（业务人员，产品人员）能听懂的语言沟通，达成一致，少说技术术语 连横：站在对方（兄弟组）的角度，换位思考 47 架构重构内功心法第三式：运筹帷幄 分段实施，将要解决的问题根据优先级、重要性、实施难度划分为不同的阶段，每个阶段聚焦于一个整体的目标，集中精力和资源解决一类问题。 优先级排序 问题分类 先易后难（团队士气、相关人员评估、判断可能出错） 循序渐进（一个阶段不要超过3个月） 48 再谈开源项目：如何选择、使用以及二次开发 DRY：Donot repeat yourself. 灾难性的事故全是数据丢失 如何选择一个开源项目 聚焦是否满足业务：合适原则、演化原则 聚焦是否成熟：版本高，使用公司数量，社区活跃度 聚焦运维能力：日志是否齐全、维护工具、故障检测和恢复能力 如何使用开源项目 深入研究，仔细测试 小心应用，灰度发布 做好应急，以防万一 如何基于开源项目做二次开发 保持纯洁，加以包装：不要私下改代码 发明你的轮子 49 谈谈 App 架构的演进 Web App：快速开发、低成本 原生 App：用户体验 Hybrid App 组件化 & 容器化 跨平台 App 50 架构实战：架构设计文档模板 首先根据《备选方案模板》选择一个方案落地，《架构设计文档》用来详细描述细化方案的备选方案模板 需求介绍 背景、目标、范围 需求分析 全方位地描述相关信息 5W who：需求利益干系人，包括开发者、使用者、购买者、决策者 when：需求使用时间，包括季节、时间、里程碑等 what：需求的产出是什么，包括系统、数据、文件、开发库、平台等 where：需求的应用场景，包括国家、地点、环境等，例如只在测试环境部署 why：需求需要解决的问题，通常和需求背景相关 1H how：方案的关键流程 8C 性能 performance 成本 cost 时间 time 可靠性 reliability 安全性 security 合规性 compliance 技术性 technology 兼容性 compatibility 复杂度分析 高可用 高性能 可扩展 备选方案 至少三个备选方案 关键实现的描述，无需细节描述 架构模板 总体方案 架构图 模块、子系统、核心流程图 架构总览 架构图 架构的描述 核心流程 举例：消息发送，消息读取 详细设计 高可用设计：消息可靠性（发送、存储、读取） 高性能设计 可扩展设计：如不涉及写无 安全设计：身份识别、权限控制 其他设计：开发语言等待 部署方案：硬件要求、服务器部署方式、组网方式 架构演进规划 第一期 第二期 第三期 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/liyunhua/learn-arch-from-zero-6.html":{"url":"note/liyunhua/learn-arch-from-zero-6.html","title":"从0开始学架构6","keywords":"","body":"华仔，放学别走1 《UNIX 编程艺术》 《异类》 《羊皮卷》 《优秀到不能被忽视》 华仔，放学别走2 《技术的本质》 《系统之美》 学习 Elasticsearch 的过程 搭建一个单机伪集群，搭建完成后看看安装路径下的文件和目录，看看配置文件有哪些配置项，不同的配置项会有什么样的影响。 执行常用的操作，例如创建索引，插入、删除、查询文档，查看一下各种输出。 研究其基本原理，例如索引、分片、副本等，研究的时候要多思考，例如索引应该如何建，分片数量和副本数量对系统有什么影响等。 和其他类似系统对比，例如Solr、Sphinx，研究其优点、缺点、适用场景。 模拟一个案例看看怎么应用。例如，假设我用Elasticsearch来存储淘宝的商品信息，我应该如何设计索引和分片。 查看业界使用的案例，思考一下别人为何这么用；看看别人测试的结果，大概了解性能范围。 如果某部分特别有兴趣或者很关键，可能去看源码，例如Elasticsearch的选举算法。 如果确定要引入，会进行性能和可用性测试。 华仔，放学别走3 如何高效地学习开源项目 树立正确的观点，不管是什么身份都可以从开源项目中学到东西 不要只盯着数据结构和算法 采取自顶向下的方法学习，源码不是第一步，而是最后一步 自顶向下的学习步骤 安装 运行 原理研究 关键特性，怎么做到的 如 memcache 的高性能，基于 libevent 实现的，用了 slab allocator 机制，为了理解网络模型，需要掌握多路复用，linux epoll、Reactor 模型、多线程等 react为例， virtual DOM 的实现原理，virtual DOM 和 DOM 的关系 优缺点分析 只有掌握技术方案的优缺点后才算真正掌握了这门技术 如 Memcache 和 redis 的对比，集群方式的对比 redis 的 rdb 和 aof 的优缺点 研究原理的手段 通读项目的设计文档，白皮书 阅读网上已有的分析文档 demo 验证 测试（用的时再做） 测试一定要在原理研究之后再做 源码研究（有时间的时候做） 一般别通读源代码，带着明确的目的去研究代码 写 demo 看调用栈 华仔，放学别走4 内功 判断力 执行力 创新力 能力来源 积累经验 拓宽视野 深度思考 成长路线：工程师、高级工程师、技术专家、初级架构师、中级架构师、高级架构师 架构师是基于完善的架构设计方法论的指导来进行架构设计，而技术专家更多的是基于经验进行架构设计 你可以统计一下自己从头到尾认真读过的技术书籍数量、系统研究过的开源项目的数量，然后自我评估一下自己目前处于哪个层级，看看是否有什么发现？ 结束语 坚持梦想 坚持学习 坚持输出 小感触 知其然，知其所以然 自己停留在表面，只知道点，不能扩展成面，没有对比思考 坚持学习有热情 深度思考常总结 自顶向下学开源 快速通读技术书 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/haozi/":{"url":"note/haozi/","title":"左耳听风","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/haozi/0.html":{"url":"note/haozi/0.html","title":"成长","keywords":"","body":"程序员如何用技术变现（上） 保持技术和技能的领先，对技术本质和趋势的敏感度 注重输出，帮助更多的人，提高影响力 程序员如何用技术变现（下） 关注市场需求 不缺写代码的人，缺解决难题的人 了解技术趋势 学习技术时，两个问题：1） 这个技术解决什么问题？为什么别的同类技术做不到？2） 为什么是这样解决的？有没有更好的方式？ 动手能力要强 从源头获取信息，英文 朋友圈很重要 何为技术领导力 我们不难发现，在任何一个团队中，大多数人都是在提问题，而只有少数人在回答这些人的问题，或是在提供解决问题的思路和方案。 技术领导力特质： 能够发现问题。能够发现现有方案的问题。 能够提供解决问题的思路和方案，并能比较这些方案的优缺点。 能够做正确的技术决定。用什么样的技术、什么解决方案、怎样实现来完成一个项目。 能够用更优雅，更简单，更容易的方式来解决问题。 能够提高代码或软件的扩展性、重用性和可维护性。 能够用正确的方式管理团队。所谓正确的方式是，一方面是，让正确的人做正确的事，并发挥每个人的潜力；另一方面是，可以提高团队的生产力和人效，找到最有价值的需求，用最少的成本实现之。并且，可以不断地提高自身和团队的标准。 创新能力。能够使用新的方法新的方式解决问题，追逐新的工具和技术。 如何拥有技术领导力 扎实的基础技术：编程范式，（epoll里用了红黑树，数据库用了B+索引），《UNIX环境高级编程》《UNIX网络编程》《Windows核心编程》《TCP/IP详解》，数据库原理，分布式架构，包括负载均衡，DNS解析，多子域名，无状态应用，缓存层，数据库分片，容错恢复机制，Paxos，Map/Reduce等。 非同一般的学习能力：学习新技术，学习关键技术，多用英文资料。与高手交流。不怕困难。开放的心态。 坚持做正确的事：提升做事效率，前沿的事，知识密集型的事，技术驱动的事。 不断得高对自己的要求标准：Google的自我评分卡，敏锐的技术嗅觉，强调实践，学以致用，永远写代码。《技术领导之路》、《卓有成效的管理者》 推荐阅读：每个程序员都该知道的事 程序员必读书目 计算机专业必知 如何做codereview 语言分析 电子书：Optimizing Software in C++ 答疑解惑：渴望、热情和选择 对学习有热情么？保持热情 隔三差五去面试一次，看看自己的水平 客观审视自己，自己想要什么，注重长期的可能性，多关注得到的东西，不要和大众的思维一样 如何成为一个大家愿意追随的 Leader？ 如何成为leader？帮人解决问题，被人所依赖，赢得他人的信任，开放的心态，甘当铺路石，一起进步 时间管理：同扭曲时间的事儿抗争 主动管理，别被动地被别人安排时间，反转控制 学会说不 给出一个自己可以做到的方案来拒绝做不到的方案 多问为什么，为什么要这样做，目的是什么，如果balaba，会怎么样 想办法把压力还回去 老板看到加班就高兴？ 会上应该讨论方案而不是问题 时间管理：投资赚取时间 系统地学习基础知识 花时间解放自己的生产力 花时间放在让自己成长的事上 花时间建立高效的环境上 时间规划 短作业优先 想清楚再做 关注场景利益规划 用好自己的时间 将军赶路不追小兔，保持专注 形成习惯！ 形成正反馈，要反思复盘 答疑解惑：我们应该能够识别的表象和本质 持续保持兴趣 要用技术解决什么样的问题，场景非常重要 如何降低学习成本，提高易用性，让技术更普及 世界简单粗暴地运行着 Google 评分卡 0 - you are unfamiliar with the subject area. 1 - you can read / understand the most fundamental aspects of the subject area. 2 - ability to implement small changes, understand basic principles and able to figure out additional details with minimal help. 3 - basic proficiency in a subject area without relying on help. 4 - you are comfortable with the subject area and all routine work on it: For software areas - ability to develop medium programs using all basic language features w/o book, awareness of more esoteric features (with book).For systems areas - understanding of many fundamentals of networking and systems administration, ability to run a small network of systems including recovery, debugging and nontrivial troubleshooting that relies on the knowledge of internals. 5 - an even lower degree of reliance on reference materials. Deeper skills in a field or specific technology in the subject area. 6 - ability to develop large programs and systems from scratch. Understanding of low level details and internals. Ability to design / deploy most large, distributed systems from scratch. 7 - you understand and make use of most lesser known language features, technologies, and associated internals. Ability to automate significant amounts of systems administration. 8 - deep understanding of corner cases, esoteric features, protocols and systems including “theory of operation”. Demonstrated ability to design, deploy and own very critical or large infrastructure, build accompanying automation. 9 - could have written the book about the subject area but didn’t; works with standards committees on defining new standards and methodologies. 10 - wrote the book on the subject area (there actually has to be a book). Recognized industry expert in the field, might have invented it. Subject Areas: TCP/IP Networking (OSI stack, DNS etc) Unix/Linux internals Unix/Linux Systems administration Algorithms and Data Structures C C++ Python Java Perl Go Shell Scripting (sh, Bash, ksh, csh) SQL and/or Database Admin Scripting language of your choice (not already mentioned) _ People Management Project Management var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/haozi/1.html":{"url":"note/haozi/1.html","title":"经验之谈","keywords":"","body":"Go 语言，Docker 和新技术 无 程序中的错误处理：错误返回码和异常捕捉 程序中的错误用异常，用户的错误用返回码（错误码返回有可能发生的事情），资源类的错误看情况 一个线程并不能捕获另一个线程的异常 程序中的错误处理：异步编程和最佳实践 通过callback函数 异步编程推荐使用Promise方式处理错误 忽略错误要加上日志 尽可能在错误发生的地方处理错误 尽可能向上返回原始错误 处理错误时要清理已分配的资源 不在循环体里处理错误 分布式系统使用APM相关软件，Zipkin等 魔数 0x5f3759df 浮点数表示法，牛顿法 // 4 times faster than (float)(1.0/sqrt(x)) float Q_rsqrt(float number) { long i; float x2, y; const float threehalfs = 1.5F; x2 = number * 0.5F; y = number; i = *(long *) &y; // evil floating point bit level hacking i = 0x5f3759df - (i >> 1); // what the fuck? y = *(float *) &i; y = y * (threehalfs - (x2 * y * y)); // 1st iteration // y = y * (threehalfs - (x2 * y * y)); // 2nd iteration, this can be removed return y; } 推荐阅读：机器学习 101 关于机器学习这个事，你可以读一读 Machine Learning is Fun! 这篇文章，以及它的中文翻译版 原文资料更多 吴恩达教授（Andrew Ng）在 Coursera 上的机器学习课程非常棒。我强烈建议从此入手。对于任何拥有计算机科学学位的人，或是还能记住一点点数学的人来说，都非常容易入门。这个斯坦福大学的课程后面是有作业的，请尽量拿满分。另外，网易公开课上也有该课程。 卡内基梅隆大学计算机科学学院汤姆·米切尔（Tom Mitchell）教授的机器学习课程 英文原版视频和课件 PDF 。汤姆·米切尔是全球 AI 界顶尖大牛，在机器学习、人工智能、认知神经科学等领域卓有建树，撰写了机器学习方面最早的教科书之一《机器学习》，被誉为入门必读图书。 加利福尼亚理工学院亚瑟·阿布·穆斯塔法（Yaser Abu-Mostafa）教授的 Learning from Data 系列课程 。本课程涵盖机器学习的基本理论和算法，并将理论与实践相结合，更具实践指导意义，适合进阶。 故障处理最佳实践：应对故障 先恢复服务，后debug，服务恢复手段：重启限流、回滚、降级、紧急更新 为每个服务确认关键指标，怎样确认服务健康和运行状态，常见故障怎么应对 设定故障等级，等级是为了确认该故障需要多大规模的人员来处理 故障演练，Chaos Monkey 灰度发布系统，或A/B测试（主要用于比较两种设计的优劣程度） 故障处理最佳实践：故障改进 故障复盘：1）故障处理流程，2）故障原因分析，3）Ask 5 Whys，4）后续整改计划 经验原则：1）举一反三解决当下的故障，2）简化复杂、不合理的技术架构、流程和组织，3）全面改善和优化整改系统 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/haozi/2.html":{"url":"note/haozi/2.html","title":"分布式系统架构的本质","keywords":"","body":"分布式系统架构的冰与火 文章 Martin Fowler：《Mircroservices》 从亚马逊的实践，谈分布式系统的难点 亚马逊的实践 分布式服务的架构需要分布式的团队架构 分布式服务查错不容易 没有专职的测试人员，也没有专职的运维人员，Eat Your Own Dog Food 运维优先，崇尚简化和自动化 内部服务和外部服务一致 分布式系统问题 异构系统的不标准：软件、通讯协议、数据格式、开发运维过程 系统架构中的服务依赖性问题： 故障发生的概率更大 多层架构的运维复杂度更高 其他 HTTP Swagger规范 SLA要求我们定义出关键指标 系统通常分为4层：1）基础层：机器、网络、存储设备，2）平台层：Tomcat、MySQL、Redis、Kafka等，3）应用层：业务软件，4）接入层：接入用户请求的网关、负载均衡或CDN、DNS等 防御编程 分布式系统的技术栈 目的 提升系统的吞吐量：1）缓存（各个层都需要），2）负载均衡（水平扩展），3）异步调用（消息队列），4）数据分区和数据镜像（读写分离，数据一致性问题） 提升系统的稳定性：1）服务拆分（故障隔离，服务模块重用），2）服务冗余（去除单点，弹性伸缩），3）限流降级，4）高可用架构（多租户隔离，灾备多活），5）高可用运维（CI/CD） 关键技术 服务治理。服务拆分、服务发现、服务调用、服务依赖 架构软件管理。服务的版本管理，整个架构的生命周期管理，服务编排、聚合、事务处理，服务调度 DevOps 自动化运维 资源调度管理：云平台IaaS层 整体架构监控（应用层、中间件层、基础层） 流量控制：负载均衡、路由、熔断、降级、限流 分布式系统的“纲” 分布式系统关键技术：全栈监控 全栈监控：各种指标 关联分析 跨系统调用的串联：Zipkin 实时报警和自动处理 系统性能分析 分布式系统关键技术：服务调度 服务关键程度 服务依赖关系：不要有依赖环 服务发现 架构的版本管理 服务应用生命周期全管理 故障迁移 宠物模式：StatefulSet，一定要救活 奶牛模式：Deployment，重新启动一个 分布式系统关键技术：流量与数据调度 服务流控。服务发现、路由、降级、熔断、保护 流量控制。负载均衡、流量分配、流量控制、异地灾备 流量管理。协议转换、请求校验、数据缓存、数据计算 API Gateway 分布式事务一致性的问题：数据高可用 -> 写多分数据 -> 数据一致性问题 -> 性能问题 Master-Slave方案；Master-Master方案，两阶段提交，三阶段提交，Paxos方案 应用层：两阶段提交 数据层：Paxos、Raft、NWR等 状态数据调度：分布式存储系统来解决 洞悉 PaaS 平台的本质 软件能力 提升服务的SLA（99.999% 年down机时间5.26分钟）：1）高可用系统，2）自动化运维 能力和资源的重用或复用：1）软件抽象能力，2）软件标准化能力（通讯协议、开发运维流程），3）过程的自动化 总结：分布式多层系统架构，服务化的能力供应，自动化运维能力 推荐阅读：分布式系统架构经典资料 基础理论 CAP 定理《CAP Confusion： Problems with partition tolerance》《Google：Transaction Across DatatCenter》 Fallacies of Distributed Computing：分布式程序员常有的错误假设 经典资料 Distributed systems theory for the distributed systems engineer：整理了分布式必须掌握的只是列表，构建分布式系统的难点 FLP Impossibility Result An introduction to distributed systems：基础课程提纲，几乎涵盖了所有的知识点 Distributed Systems for fun and profit：一般小书，分布式中的关键问题，时间和复制策略 Distributed Systems: Principles and Paradigms：经典教材 Scalable Web Architecture and Distributed Systems：免费的小册子，中文《可扩展的Web架构和分布式系统》 Principles of Distributed Systems：苏黎世联邦理工学院教材 Making reliable distributed systems in the presence of software errors：Erlang之父力作 Designing Data Intensive Applications：非常好的书，深入到基本数据结构，今年看过的最好的书 推荐阅读：分布式数据调度相关论文 Google File System、MapReduce、BigTable Paxos算法 Neat Algorithms - Paxos Paxos by Examples Raft算法 逻辑钟和向量钟 Gossip协议 分布式数据库 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/haozi/3.html":{"url":"note/haozi/3.html","title":"编程范式游记","keywords":"","body":"编程范式游记（1）：起源 Programming Paradigm 抽象类型：泛型编程（Generic Programming算法的泛型、类型的泛型、数据结构（数据容器）的泛型） c语言1972年诞生 编程范式游记（2）：泛型编程 c++语言1980年发明，《c++语言的设计和演化》 耗子的《c++的坑真多么？》 编程范式游记（3）：类型系统和泛型的本质 屏蔽掉数据的操作细节，抽象，让算法更通用 编程范式游记（4）：函数式编程 更为抽象的泛型 函数编程：stateless、immutable（入参不能动） 优势：无状态，并行执行，随便拷贝代码，函数执行没顺序问题 编程范式游记（5）：修饰器模式 装饰函数 编程范式游记（6）：面向对象编程 设计模式：可复用面向对象软件的基础 Program to an 'interface', not an 'implementation'.\" 使用者不需要知道数据类型、结构、算法的细节。 使用者不需要知道实现细节，只需要知道提供的接口。 利于抽象、封装、动态绑定、多态。 符合面向对象的特质和理念。 Favor 'object composition' over 'class inheritance' 继承需要给子类暴露一些父类的设计和实现细节。 父类实现的改变会造成子类也需要改变。 我们以为继承主要是为了代码重用，但实际上在子类中需要重新实现很多父类的方法。 继承更多的应该是为了多态。 IoC/DIP（控制反转 / 依赖倒置）面向对象编程的核心原则 S.O.L.I.D（单一功能、开闭原则、里氏替换、接口隔离以及依赖反转）面向对象设计的五个基本原则 编程范式游记（7）：基于原型的编程范式 基于原型（prototype）的编程其实也是面向对象编程的一种方式。没有 class 化的，直接使用对象。又叫，基于实例的编程。其主流的语言就是 JavaScript。 编程范式游记（8）：Go 语言的委托模式 这是不是和最一开始的 C++ 的泛型编程很像？也和 map、reduce、filter 这样的只关心控制流程，不关心业务逻辑的做法很像？而且，一开始用一个 UndoableIntSet 来包装 IntSet 类，到反过来在 IntSet 里依赖Undo类，这就是控制反转 IoC。 type UndoableIntSet struct { IntSet // Embedding(delegation) functions []func() } type IntSet struct { data map[int]bool undo Undo } 编程范式游记（9）：编程的本质 任何算法都会有两个部分， 一个是 Logic 部分，这是用来解决实际问题的。另一个是 Control 部分，这是用来决定用什么策略来解决问题。Logic 部分是真正意义上的解决问题的算法，而 Control 部分只是影响解决这个问题的效率。程序运行的效率问题和程序的逻辑其实是没有关系的。我们认为，如果将 Logic 和 Control 部分有效地分开，那么代码就会变得更容易改进和维护。 就像我们面向对象中依赖于接口而不是实现一样，接口是对逻辑的抽象，真正的逻辑放在不同的具现类中，通过多态或是依赖注入这样的控制来完成对数据在不同情况下的不同处理。 Control 是可以标准化的。比如：遍历数据、查找数据、多线程、并发、异步等，都是可以标准化的。因为 Control 需要处理数据，所以标准化 Control，需要标准化 Data Structure，我们可以通过泛型编程来解决这个事。而 Control 还要处理用户的业务逻辑，即 Logic。所以，我们可以通过标准化接口 / 协议来实现，我们的 Control 模式可以适配于任何的 Logic。 Regular Expression Matching Can Be Simple And Fast 如何分离 control 和 logic 呢？我们可以使用下面的这些技术来解耦。 State Machine 状态定义 状态变迁条件 状态的 action DSL – Domain Specific Language HTML，SQL，Unix Shell Script，AWK，正则表达式…… 编程范式 面向对象：委托、策略、桥接、修饰、IoC/DIP、MVC…… 函数式编程：修饰、管道、拼装 逻辑推导式编程：Prolog 这就是编程的本质：Logic 部分才是真正有意义的（What） Control 部分只是影响 Logic 部分的效率（How） 编程范式游记（10）：逻辑编程范式 prolog 编程范式游记（11）：程序世界里的编程范式 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/haozi/4.html":{"url":"note/haozi/4.html","title":"分布式系统设计模式","keywords":"","body":"弹力设计篇 认识故障和弹力设计 容错设计又叫弹力设计，其中着眼于分布式系统的各种“容忍”能力，包括容错能力（服务隔离、异步调用、请求幂等性）、可伸缩性（有 / 无状态的服务）、一致性（补偿事务、重试）、应对大流量的能力（熔断、降级）。可以看到，在确保系统正确性的前提下，系统的可用性是弹力设计保障的重点。 Resiliency（弹力） 隔离设计 Bulkheads 要能做好隔离设计，我们需要有如下的一些设计考量。 我们需要定义好隔离业务的大小和粒度，过大和过小都不好。这需要认真地做业务上的需求和系统分析。 无论是做系统版块还是多租户的隔离，你都需要考虑系统的复杂度、成本、性能、资源使用的问题，找到一个合适的均衡方案，或是分布实施的方案尤其重要，这其中需要你定义好要什么和不要什么。因为，我们不可能做出一个什么都能满足的系统。 隔离模式需要配置一些高可用、重试、异步、消息中间件，流控、熔断等设计模式的方式配套使用。 不要忘记了分布式系统中的运维的复杂度的提升，要能驾驭得好的话，还需要很多自动化运维的工具，尤其是使用像容器或是虚拟机这样的虚拟化技术可以帮助我们更方便地管理，和对比资源更好地利用。否则做出来了也管理不好。 最后，你需要一个非常完整的能够看得到所有服务的监控系统，这点非常重要。 异步通讯设计 Asynchronous 同步调用有四点问题：影响吞吐量、消耗系统资源、只能一对一，以及有多米诺骨牌效应。 异步通讯的三种方式 请求响应式：发送方（sender）会直接请求接收方（receiver），被请求方接收到请求后，直接返回——收到请求，正在处理。 订阅的方式：接收方（receiver）会来订阅发送方（sender）的消息，发送方会把相关的消息或数据放到接收方所订阅的队列中，而接收方会从队列中获取数据。 通过 Broker 的方式：所谓 Broker，就是一个中间人，发送方（sender）和接收方（receiver）都互相看不到对方，它们看得到的是一个 Broker，发送方向 Broker 发送消息，接收方向 Broker 订阅消息。如下图所示。 事件驱动设计：上述的第二种和第三种方式就是比较著名的事件驱动架构（EDA – Event Driven Architecture）。 优点：解耦服务，服务故障隔离，服务不会互相block，服务吞吐量解耦，容易增加Adapter（如日志、认证、版本、限流、降级、熔断等） 缺点：业务流程不再明显易管理，事件可能乱序，事务处理复杂，需要使用两阶段提交来做强一致性，或是退缩到最终一致性 异步通讯的设计重点 异步通讯最重要的是解耦服务间的依赖。最佳解耦的方式是通过 Broker 的机制。 解耦的目的是让各个服务的隔离性更好，这样不会出现“一倒倒一片”的故障。 异步通讯的架构可以获得更大的吞吐量，而且各个服务间的性能不受干扰相对独立。 利用 Broker 或队列的方式还可以达到把抖动的吞吐量变成均匀的吞吐量，这就是所谓的“削峰”，这对后端系统是个不错的保护。 服务相对独立，在部署、扩容和运维上都可以做到独立不受其他服务的干扰。 但我们需要知道这样的方式带来的问题，所以在设计成异步通信的时候需要注意如下事宜。 用于异步通讯的中间件 Broker 成为了关键，需要设计成高可用不丢消息的。另外，因为是分布式的，所以可能很难保证消息的顺序，因此你的设计最好不依赖于消息的顺序。 异步通讯会导致业务处理流程不那么直观，因为像接力一样，所以在 Broker 上需要有相关的服务消息跟踪机制，否则出现问题后不容易调试。 因为服务间只通过消息交互，所以业务状态最好由一个总控方来管理，这个总控方维护一个业务流程的状态变迁逻辑，以便系统发生故障后知道业务处理到了哪一步，从而可以在故障清除后继续处理。 消息传递中，可能有的业务逻辑会有像 TCP 协议那样的 send 和 ACK 机制。比如：A 服务发出一个消息之后，开始等待处理方的 ACK，如果等不到的话，就需要做重传。此时，需要处理方有幂等的处理，即同一件消息无论收到多少次都只处理一次。 幂等性设计 Idempotency 解决超时带来的问题 一种是需要下游系统提供相应的查询接口。上游系统在 timeout 后去查询一下。如果查到了，就表明已经做了，成功了就不用做了，失败了就走失败流程。 另一种是通过幂等性的方式。也就是说，把这个查询操作交给下游系统，我上游系统只管重试，下游系统保证一次和多次的请求结果是一样的。 需要全局ID：在全局唯一 ID 的算法中，这里介绍一个 Twitter 的开源项目 Snowflake 服务的状态 State 关于可扩展的有状态服务，这里强烈推荐 Twitter 的美女工程师 Caitie McCaffrey 的演讲 Youtube 视频《Building Scalable Stateful Service》(演讲 PPT)，其文字版是在 High Scalability 上的这篇文章《Making the Case for Building Scalable Stateful Services in the Modern Era》 有状态的服务，它们通过 Sticky Session、一致性 Hash 和 DHT 等技术实现状态和请求的关联，并将数据同步到分布式数据库中；利用分布式文件系统，还能在节点挂掉时快速启动新实例。 补偿事务 Compensating Transaction 出现了 ACID 的一个变种 BASE。 Basic Availability：基本可用。这意味着，系统可以出现暂时不可用的状态，而后面会快速恢复。 Soft-state：软状态。它是我们前面的“有状态”和“无状态”的服务的一种中间状态。也就是说，为了提高性能，我们可以让服务暂时保存一些状态或数据，这些状态和数据不是强一致性的。 Eventual Consistency：最终一致性，系统在一个短暂的时间段内是不一致的，但最终整个系统看到的数据是一致的。 有趣的是，ACID 的意思是酸，而 BASE 却是碱的意思，因此这是一个对立的东西。其实，从本质上来讲，酸（ACID）强调的是一致性（CAP 中的 C），而碱（BASE）强调的是可用性（CAP 中的 A）。 重试设计 Retry 重试的场景：调用超时、被调用端返回了某种可以重试的错误（如繁忙中、流控中、维护中、资源不足等）；而对于一些别的错误，则最好不要重试，比如：业务级的错误（如没有权限、或是非法数据等错误），技术上的错误（如：HTTP 的 503 等，这种原因可能是触发了代码的 bug，重试下去没有意义）。 重试的策略：Exponential Backoff 的策略，也就是所谓的 \" 指数级退避 \"。 熔断设计 Circuit Breaker 熔断器模式可以防止应用程序不断地尝试执行可能会失败的操作，使得应用程序继续执行而不用等待修正错误，或者浪费 CPU 时间去等待长时间的超时产生。熔断器模式也可以使应用程序能够诊断错误是否已经修正。如果已经修正，应用程序会再次尝试调用操作。 实现熔断器模式使得系统更加稳定和有弹性，在系统从错误中恢复的时候提供稳定性，并且减少了错误对系统性能的影响。它通过快速地拒绝那些试图有可能会导致错误的服务调用，而不会去等待操作超时或者永远不返回结果来提高系统的响应时间。 限流设计 Throttle 限流的策略：拒绝服务、服务降级、特权请求、延时处理、弹性伸缩 限流方式：计数器方式、队列算法、漏斗算法Leaky Bucket、令牌桶算法 Token Bucket、基于响应时间的动态限流 TCP 的那些事（下） 、Reservoir sampling 限流主要是有四个目的。 为了向用户承诺 SLA。我们保证我们的系统在某个速度下的响应时间以及可用性。 同时，也可以用来阻止在多租户的情况下，某一用户把资源耗尽而让所有的用户都无法访问的问题。 为了应对突发的流量。 节约成本。我们不会为了一个不常见的尖峰来把我们的系统扩容到最大的尺寸。而是在有限的资源下能够承受比较高的流量。 在设计上，我们还要有以下的考量。 限流应该是在架构的早期考虑。当架构形成后，限流不是很容易加入。 限流模块必需是非常好的性能，而且对流量的变化也是非常灵敏的，否则太过迟钝的限流，系统早因为过载而挂掉了。 限流应该有个手动的开关，这样在应急的时候，可以手动操作。 当限流发生时，应该有个监控事件通知。让我们知道有限流事件发生，这样，运维人员可以及时跟进。而且还可以自动化触发扩容或降级，以缓解系统压力。 当限流发生时，对于拒掉的请求，我们应该返回一个特定的限流错误码。这样，可以和其它错误区分开来。而客户端看到限流，可以调整发送速度，或是走重试机制。 限流应该让后端的服务感知到。限流发生时，我们应该在协议头中塞进一个标识，比如 HTTP Header 中，放入一个限流的级别，告诉后端服务目前正在限流中。这样，后端服务可以根据这个标识决定是否做降级。 降级设计 degradation 一般来说，我们的降级需要牺牲掉的东西有： 降低一致性。从强一致性变成最终一致性。 停止次要功能。停止访问不重要的功能，从而释放出更多的资源。 简化功能。把一些功能简化掉，比如，简化业务流程，或是不再返回全量数据，只返回部分数据。 我们一般使用 Cache Aside 模式或是 Read Through 模式。也就是下图所示的这个策略。 失效：应用程序先从 cache 取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从 cache 中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。 弹力设计总结 管理设计篇 分布式锁 Distributed Lock A得到锁，超时释放，B得到锁，写入数据，GC后，A仍要写入数据，出错 增加版本号（乐观锁），fence token，timestamp 分布式锁设计的重点 需要给一个锁被释放的方式，以避免请求者不把锁还回来，导致死锁的问题。Redis 使用超时时间，ZooKeeper 可以依靠自身的 sessionTimeout 来删除节点。 分布式锁服务应该是高可用的，而且是需要持久化的。对此，你可以看一下 Redis 的文档 RedLock 看看它是怎么做到高可用的。 要提供非阻塞方式的锁服务。 还要考虑锁的可重入性。 ZooKeeper 在使用起来需要有一些变通的方式，好在 Apache 有 Curator 帮我们封装了各种分布式锁的玩法 配置中心 Configuration Management 配置中心的设计 区分软件的配置：有一种方式是把软件的配置分成静态配置和动态配置。所谓静态配置其实就是在软件启动时的一些配置，运行时基本不会进行修改，也可以理解为是环境或软件初始化时需要用到的配置。例如，操作系统的网络配置，软件运行时 Docker 进程的配置，这些配置在软件环境初始化时就确定了，未来基本不会修改了。而所谓动态配置其实就是软件运行时的一些配置，在运行时会被修改。比如，日志级别、降级开关、活动开关。 按运行环境分。一般来说，会有开发环境、测试环境、预发环境、生产环境。这些环境上的运行配置都不完全一样，但是理论来说，应该是大同小异的。 按依赖区分。一种是依赖配置，一种是不依赖的内部配置。比如，外部依赖的 MySQL 或 Redis 的连接配置。还有一种完全是自己内部的配置。 按层次分。就像云计算一样，配置也可以分成 IaaS、PaaS、SaaS 三层。基础层的配置是操作系统的配置，中间平台层的配置是中间件的配置，如 Tomcat 的配置，上层软件层的配置是应用自己的配置。 我们把软件的配置分成三层。 操作系统层和平台层的配置项得由专门的运维人员或架构师来配置。其中的 value 应该是选项，而不是让用户可以自由输入的，最好是有相关的模板来初始化全套的配置参数。 而应用层的配置项，需要有相应的命名规范，最好有像 C++ 那样的名字空间的管理，确保不同应用的配置项不会冲突。 如果有外部服务依赖的配置，强烈建议不要放在配置中心里，而要放在服务发现系统中。因为一方面这在语义上更清楚一些，另外，这样会减少因为运行不同环境而导致配置不同的差异性（如测试环境和生产环境的不同）。 边车模式 Sidecar 以软件包的方式可以和应用密切集成，有利于资源的利用和应用的性能，但是对应用有侵入，而且受应用的编程语言和技术限制。同时，当软件包升级的时候，需要重新编译并重新发布应用。 以 Sidecar 的方式，对应用服务没有侵入性，并且不用受到应用服务的语言和技术的限制，而且可以做到控制和逻辑的分开升级和部署。但是，这样一来，增加了每个应用服务的依赖性，也增加了应用的延迟，并且也会大大增加管理、托管、部署的复杂度。 边车设计的重点 控制和逻辑的分离。 服务调用中上下文的问题。 熔断、路由、服务发现、计量、流控、监视、重试、幂等、鉴权等控制面上的功能，以及其相关的配置更新，本质来上来说，和服务的关系并不大。 边车作为另一个进程，和服务进程部署在同一个结点中，通过一个标准的网络协议，如 HTTP 来进行通信。这样可以做到低延迟和标准化。 服务网格 Service Mesh Service Mesh 这个服务网络专注于处理服务和服务间的通讯。其主要负责构造一个稳定可靠的服务通讯的基础设施，并让整个架构更为的先进和 Cloud Native。在工程中，Service Mesh 基本来说是一组轻量级的服务代理和应用逻辑的服务在一起，并且对于应用服务是透明的。 The 8 Fallacies of Distributed Computing 目前比较流行的 Service Mesh 开源软件是 Istio 和 Linkerd，我还是推荐大家使用 Rust/Go 语言实现的 lstio 和 Conduit，后者比前者要轻很多。你可以根据你的具体需求挑选，或是自己实现。lstio 是目前最主流的解决方案，其架构并不复杂，其核心的 Sidecar 被叫做 Envoy（使者），用来协调服务网格中所有服务的出入站流量，并提供服务发现、负载均衡、限流熔断等能力，还可以收集大量与流量相关的性能指标。 网关模式 Gateway Gateway 是一个服务器，也可以说是进入系统的唯一节点。这跟面向对象设计模式中的 Facade 模式很像。Gateway 封装内部系统的架构，并且提供 API 给各个客户端。它还可能有其他功能，如授权、监控、负载均衡、缓存、熔断、降级、限流、请求分片和管理、静态响应处理，等等。 网关需要有以下的功能：请求路由，服务注册，负载均衡，弹力设计，安全方面 也可以做灰度发布，API 聚合（使用网关可将多个单独请求聚合成一个请求），API 编排（ DSL 来定义和编排不同的 API） 网关的设计重点 高性能：对于高性能，最好使用高性能的编程语言来实现，如 C、C++、Go 和 Java。网关对后端的请求，以及对前端的请求的服务一定要使用异步非阻塞的 I/O 来确保后端延迟不会导致应用程序中出现性能问题。C 和 C++ 可以参看 Linux 下的 epoll 和 Windows 的 I/O Completion Port 的异步 IO 模型，Java 下如 Netty、Vert.x、Spring Reactor 的 NIO 框架。当然，我还是更喜欢 Go 语言的 goroutine 加 channel 玩法。 高可用： 集群化：网关要成为一个集群，其最好可以自己组成一个集群，并可以自己同步集群数据 服务化：网关还需要做到在不间断的情况下修改配置，一种是像 Nginx reload 配置那样，可以做到不停服务，另一种是最好做到服务化。也就是说，得要有自己的 Admin API 来在运行时修改自己的配置 持续化：比如重启，就是像 Nginx 那样优雅地重启 高扩展：一个好的 Gateway 还需要是可以扩展的，并能进行二次开发的。当然，像 Nginx 那样通过 Module 进行二次开发的固然可以。但我还是觉得应该做成像 AWS Lambda 那样的方式，也就是所谓的 Serverless 或 FaaS（Function as a Service）那样的方式 运维方面 业务松耦合，协议紧耦合。除了服务发现外，网关不应该有第三方服务的依赖 应用监视，提供分析数据。实施分布式链路跟踪 用弹力设计保护后端服务。网关上一定要实现熔断、限流、重试和超时等弹力设计。 DevOps： 架构方面 不要在网关中的代码里内置聚合后端服务的功能 网关应该靠近后端服务，并和后端服务使用同一个内网，这样可以保证网关和后端服务调用的低延迟 网关也需要做容量扩展，所以需要成为一个集群来分担前端带来的流量 对于服务发现，可以做一个时间不长的缓存 为网关考虑 bulkhead 设计方式 安全方面 加密数据 校验用户的请求 检测异常访问 部署升级策略 蓝绿部署是为了不停机，灰度部署是对新版本的质量没信心。而 AB 测试是对新版的功能没信心。注意，一个是质量，一个是功能。AB 测试，其包含了灰度发布的功能 停机部署（Big Bang/Recreate）： 把现有版本的服务停机，然后部署新的版本。 蓝绿部署（Blue/Green/Stage）：部署好新版本后，把流量从老服务那边切过来。 滚动部署（Rolling Update/Ramped）： 一点一点地升级现有的服务。 灰度部署（金丝雀，Canary）：把一部分用户切到新版上来，然后看一下有没有问题。如果没有问题就继续扩大升级，直到全部升级完成。 AB 测试（A/B Testing）：同时上线两个版本，然后做相关的比较。 性能设计篇 缓存 Cache Cache Aside 更新模式 失效：应用程序先从 cache 取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从 cache 中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。 Why does Facebook use delete to remove the key-value pair in Memcached instead of updating the Memcached during write request to the backend? Read/Write Through 更新模式：应用认为后端就是一个单一的存储，而存储自己维护自己的 Cache。 Read Through：当缓存失效的时候（过期或 LRU 换出），Cache Aside 是由调用方负责把数据加载入缓存，而 Read Through 则用缓存服务自己来加载，从而对应用方是透明的。 Write Through：当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后由 Cache 自己更新数据库（这是一个同步操作）。 Write Behind Caching: 更新模式 Write Behind 又叫 Write Back，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库 缓存设计的重点 内存和 IO 密集型的应用 缓存的好坏要看命中率，一般来说命中率到 80% 以上就算很高了 缓存是通过牺牲强一致性来提高性能的 异步处理 Asysnchronous Event Sourcing（事件溯源）设计模式 异步处理的设计要点 异步处理中的事件驱动和事件溯源是两个比较关键的技术 异步处理系统的本质是把被动的任务处理变成主动的任务处理，其本质是在对任务进行调度和统筹管理 数据库扩展 读写分离 CQRS：Command and Query Responsibility Segregation 分库分表 Sharding 数据库分片必须考虑业务，从业务的角度入手，而不是从技术的角度入手 请只考虑业务分片。请不要走哈希散列的分片方式。 秒杀 Flash Sales 在 CDN 上，这 100 万个用户就会被几十个甚至上百个 CDN 的边缘结点给分担了 边缘计算 Edge Computing 物联网（英语：Internet of Things，缩写IoT） 所谓边缘计算，它是相对于数据中心而言。数据中心喜欢把所有的服务放在一个机房里集中处理用户的数据和请求，集中式部署一方面便于管理和运维，另一方面也便于服务间的通讯有一个比较好的网络保障。的确没错。不过，我们依然需要像 CDN 这样的边缘式的内容发布网络，把我们的静态内容推到离用户最近的地方，然后获得更好的性能。 我们可以来算一下，根据我过去服务过的 40 多家公司的经验，可以看到如下的投入： 几十万用户的公司，只需要处理百级 QPS 的量，只需要 10 台左右的服务器； 上百万用户的公司，只需要处理千级 QPS 的量，需要有 50 台左右的服务器； 上千万用户的公司，需要处理万级到十万级 QPS 的量，需要 700 台左右的服务器； 上亿用户的公司，其需要处理百万级 QPS 的量，需要上万台的服务器。 Netflix 的全球边缘架构的 PPT var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/haozi/5.html":{"url":"note/haozi/5.html","title":"程序员练级攻略","keywords":"","body":"程序员练级攻略（2018）：开篇词 Teach Yourself Programming in Ten Years 中英对照版 入门篇 程序员练级攻略（2018）：零基础启蒙 MDN JS 程序员练级攻略（2018）：正式入门 The Key To Accelerating Your Coding Skills 编程技巧：代码大全 JAVA：《Java 核心技术（卷 1）》，既然开始学习 Java 了，那就一定要学 Spring，推荐看看《Spring in Action》或是直接从最新的 Spring Boot 开始，推荐看看《Spring Boot 实战》。 HTTP：HTTP详解 Git：猴子都能懂的 Git 入门 Pro Git JS调试：超完整的Chrome浏览器客户端调试大全 修养篇 程序员练级攻略（2018）：程序员修养 What are some of the most basic things every programmer should know? 97 Things Every Programmer Should Know 英文 坚持 Google 英文关键词，而不是在 Google 里搜中文。 在 GitHub 上只用英文。用英文写代码注释，写 Code Commit 信息，用英文写 Issue 和 Pull Request，以及用英文写 Wiki。 坚持到 YouTube 上每天看 5 分钟的视频。YouTube 上有相关的机器字幕，实在不行就打开字幕。 坚持用英文词典而不是中文的。比如：剑桥英语词典 或是 Dictionary.com 。你可以安装一个 Chrome 插件 Google Dictionary。 坚持用英文的教材而不是中文的。比如：BBC 的 Learning English ，或是到一些 ESL 网站上看看，如 ESL: English as a Second Language 上有一些课程。 花钱参加一些线上的英文课程，用视频和老外练习。 问问题 How To Ask Questions The Smart Way 另外，还有一个经典的问题叫 X-Y Problem 写代码的修养 《重构：改善既有代码的设计》《修改代码的艺术》 《代码整洁之道》《程序员的职业素养》 安全 在代码中没有最基本的安全漏洞问题，也是我们程序员必需要保证的重要大事，尤其是对外暴露 Web 服务的软件，其安全性就更为重要了。对于在 Web 上经常出现的安全问题，有必要介绍一下 OWASP - Open Web Application Security Project。 专业基础篇 程序员练级攻略（2018）：编程语言 系统知识。系统知识是理论知识的工程实践，这里面有很多很多的细节。比如像 Unix/Linux、TCP/IP、C10K 挑战等这样专业的系统知识。这些知识是你能不能把理论应用到实际项目当中，能不能搞定实际问题的重要知识。 《Effective Java》（第三版） 《Java并发编程实战》 《Java 性能权威指南》 《深入理解 Java 虚拟机》 《Java 编程思想》《精通 Spring 4.x》 -《C 程序设计语言》《C 语言程序设计现代方法》《C 陷阱与缺陷》《C++ Primer 中文版》《Effective C++》和《More Effective C++》《深度探索 C++ 对象模型 》C++ FAQ （中文版） Effective Go、Go Concurrency Patterns（幻灯片和演讲视频）、Advanced Go Concurrency Patterns（幻灯片、演讲视频） Go 精华文章列表。 Go 相关博客列表。 Go Talks。 此外，还有个内容丰富的 Go 资源列表 Awesome Go，推荐看看。 程序员练级攻略（2018）：理论学科 编程珠玑 List of Algorithms 程序员练级攻略（2018）：系统知识 《深入理解计算机系统》 《Unix 高级环境编程》。 《Unix 网络编程》 第 1 卷 套接口 API 、第 2 卷 进程间通信 。 《TCP/IP 详解 卷 I 协议》。 快速入门 《图解 TCP/IP》，这本书其实并不是只讲了 TCP/IP，应该是叫《计算机网络》才对，主要是给想快速入门的人看的。 《The TCP/IP Guide》，这本书在豆瓣上的评分 9.2，这里给的链接是这本书的 HTML 英文免费版的，里面的图画得很精彩。 -《Wireshark 数据包分析实战》 C10K、中文 软件设计篇 程序员练级攻略（2018）：软件设计 Wikipedia: Programming paradigm；Six programming paradigms that will change how you think about coding 中文。这篇文章讲了默认支持并发（Concurrent by default）、依赖类型（Dependent types）、连接性语言（Concatenative languages）、声明式编程（Declarative programming）、符号式编程（Symbolic programming）、基于知识的编程（Knowledge-based programming）等六种不太常见的编程范式，并结合了一些你没怎么听说过的语言来分别进行讲述。 Programming Paradigms for Dummies: What Every Programmer Should Know ，这篇文章的作者彼得·范·罗伊（Peter Van Roy）是比利时鲁汶大学的计算机科学教师。他在这篇文章里分析了编程语言在历史上的演进，有哪些典型的、值得研究的案例，里面体现了哪些值得学习的范式。 一些软件设计的相关原则 Don’t Repeat Yourself(DRY) Keep It Simple, Stupid(KISS) Program to an interface, not an implementation 在面向对象的 S.O.L.I.D 原则中会提到我们的依赖倒置原则，就是这个原则的另一种样子。还有一条原则叫 Composition over inheritance（喜欢组合而不是继承） You Ain’t Gonna Need It(YAGNI)，这个原则简而言之为——只考虑和设计必须的功能，避免过度设计。只实现目前需要的功能，在以后你需要更多功能时，可以再进行添加。如无必要，勿增复杂性。软件开发是一场 trade-off 的博弈。 Law of Demeter，迪米特法则 (Law of Demeter)，又称“最少知识原则”（Principle of Least Knowledge），其来源于 1987 年荷兰大学的一个叫做 Demeter 的项目。克雷格·拉尔曼（Craig Larman）把 Law of Demeter 又称作“不要和陌生人说话”。在《程序员修炼之道》中讲 LoD 的那一章将其叫作“解耦合与迪米特法则”。 面向对象的 S.O.L.I.D 原则：SRP（Single Responsibility Principle）职责单一原则；OCP（Open/Closed Principle）开闭原则； LSP（Liskov substitution principle）里氏代换原则；ISP（Interface Segregation Principle）接口隔离原则；DIP（Dependency Inversion Principle）依赖倒置原则； CCP（Common Closure Principle）共同封闭原则：一个包中所有的类应该对同一种类型的变化关闭。一个变化影响一个包，便影响了包中所有的类。一个更简短的说法是：一起修改的类，应该组合在一起（同一个包里） CRP（Common Reuse Principle）共同重用原则：包的所有类被一起重用。如果你重用了其中的一个类，就重用全部。换个说法是，没有被一起重用的类不应该组合在一起。 Hollywood Principle好莱坞原则：好莱坞原则就是一句话——“don’t call us, we’ll call you.”，也就是说，所有的组件都是被动的，所有的组件初始化和调用都由容器负责。 高内聚，低耦合 & - High Cohesion & Low/Loose coupling CoC（Convention over Configuration）惯例优于配置原则：简单点说，就是将一些公认的配置方式和信息作为内部缺省的规则来使用。例如，Hibernate 的映射文件，如果约定字段名和类属性一致的话，基本上就可以不要这个配置文件了。你的应用只需要指定不 convention 的信息即可，从而减少了大量 convention 而又不得不花时间和精力啰里啰嗦的东东。 SoC (Separation of Concerns)关注点分离：SoC 是计算机科学中最重要的努力目标之一。这个原则，就是在软件开发中，通过各种手段，将问题的各个关注点分开。如果一个问题能分解为独立且较小的问题，就是相对较易解决的。问题太过于复杂，要解决问题需要关注的点太多，而程序员的能力是有限的，不能同时关注于问题的各个方面。 DbC（Design by Contract）契约式设计：DbC 的核心思想是对软件系统中的元素之间相互合作以及“责任”与“义务”的比喻。这种比喻从商业活动中“客户”与“供应商”达成“契约”而得来。 ADP（Acyclic Dependencies Principle）无环依赖原则：包（或服务）之间的依赖结构必须是一个直接的无环图形，也就是说，在依赖结构中不允许出现环（循环依赖）。如果包的依赖形成了环状结构，怎么样打破这种循环依赖呢？有两种方法可以打破这种循环依赖关系：第一种方法是创建新的包，如果 A、B、C 形成环路依赖，那么把这些共同类抽出来放在一个新的包 D 里。这样就把 C 依赖 A 变成了 C 依赖 D 以及 A 依赖 D，从而打破了循环依赖关系。第二种方法是使用 DIP（依赖倒置原则）和 ISP（接口分隔原则）设计原则。无环依赖原则（ADP）为我们解决包之间的关系耦合问题。在设计模块时，不能有循环依赖。 一些读物 《领域驱动设计》、《Clean Architecture》 The Twelve-Factor App，如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建 SaaS 应用提供了方法论，这也是架构师必读的文章。（中译版） 这篇文章在业内的影响力很大，必读！ The Problem With Logging ，一篇关于程序打日志的短文，可以让你知道一些可能以往不知道的打日志需要注意的问题。 Concurrent Programming for Scalable Web Architectures ，这是一本在线的免费书，教你如何架构一个可扩展的高性能的网站。其中谈到了一些不错的设计方法和知识。 程序员练级攻略（2018）：Linux系统、内存和网络 Linux 系统相关 Linux Insides ，GitHub 上的一个开源电子书，其中讲述了 Linux 内核是怎样启动、初始化以及进行管理的。 LWN’s kernel page ，上面有很多非常不错的文章来解释 Linux 内核的一些东西。 Linux Performance，这个网站上提供了和 Linux 系统性能相关的各种工具和文章收集，非常不错。 内存相关 首先，LWN.net 上有一系列的 “What every programmer should know about memory” 文章你需要读一下。 Memory Barriers: a Hardware View for Software Hackers。内存的读写屏障是线程并发访问共享的内存数据时，从程序本身、编译器到 CPU 都必须遵循的一个规范。有了这个规范，才能保证访问共享的内存数据时，一个线程对该数据的更新能被另一个线程以正确的顺序感知到。在 SMP（对称多处理）这种类型的多处理器系统（包括多核系统）上，这种读写屏障还包含了复杂的缓存一致性策略。这篇文章做了详细解释。 tcmalloc 是 Google 的内存分配管理模块，全称是 Thread-Caching malloc，基本上来说比 glibc 的 ptmalloc 快两倍以上。 ptmalloc，tcmalloc 和 jemalloc 内存分配策略研究 内存优化总结：ptmalloc、tcmalloc 和 jemalloc 计算机网络 网络学习 计算机网络（第五版） 网络调优 [Making Linux TCP Fast(https://netdevconf.org/1.2/papers/bbr-netdev-1.2.new.new.pdf)] ，一篇非常不错的 TCP 调优的论文。 Monitoring and Tuning the Linux Networking Stack: Receiving Data Monitoring and Tuning the Linux Networking Stack: Sending Data 网络协议 《TCP 的那些事儿（上）》和《TCP 的那些事儿（下）》两篇文章中。如果你看不懂 RFC，你也可以去看我上述的文章。 我个人觉得 TCP 最牛的不是不丢包，而是拥塞控制。对此，如果你感兴趣，可以读一下经典论文《Congestion Avoidance and Control》。 关于 Linux 下的 TCP 参数，你需要仔仔细细地读一下 TCP 的 man page。 对于第 7 层协议，HTTP 协议是重点要学习的。 首先推荐的是《HTTP 权威指南》， Gitbook - HTTP/2 详解 程序员练级攻略（2018）：异步I/O模型和Lock-Free编程 异步 I/O 模型 Thousands of Threads and Blocking I/O: The Old Way to Write Java Servers Is New Again (and Way Better)，这个 PPT 中不仅回顾和比较了各种 I/O 模型，而且还有各种比较细节的方案和说明，是一篇非常不错的文章。 异步 I/O 模型中的 Windows I/O Completion Ports , 你也需要了解一下。如果 MSDN 上的这个手册不容易读，你可以看看这篇文章 Inside I/O Completion Ports。另外，关于 Windows，Windows Internals 这本书你可以仔细读一下，非常不错的。其中有一节 I/O Processing 也是很不错的，这里我给一个网上免费的链接I/O Processing 你可以看看 Windows 是怎么玩的。 IBM - Boost application performance using asynchronous I/O ，这是一篇关于 AIO 的文章。 接下来是 Libevent。你可以看一下其主要维护人员尼克·马修森（Nick Mathewson）写的 libevent 2.0 book。还有一本国人写的电子书 《Libevent 深入浅出》。 再接下来是 Libuv。你可以看一下其官网的 Libuv Design Overview 了解一下。 我简单总结一下，基本上来说，异步 I/O 模型的发展技术是： select -> poll -> epoll -> aio -> libevent -> libuv。Unix/Linux 用了好几十年走过这些技术的变迁，然而，都不如 Windows I/O Completion Port 设计得好（免责声明：这个观点纯属个人观点。相信你仔细研究这些 I/O 模型后，你会得到你自己的判断）。 Lock-Free 编程相关 然后强烈推荐一本免费的电子书：Is Parallel Programming Hard, And, If So, What Can You Do About It? ，这是大牛 保罗·麦肯尼（Paul E. McKenney） 写的书。这本书堪称并行编程的经典书，必看。 Implementing Lock-Free Queues， 这也是一篇很不错的论文，我把它介绍在了我的网站上 ，文章为“无锁队列的实现”。 Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue Algorithms ，这篇论文给出了一个无阻塞和阻塞的并发队列算法。 推荐博客 Preshing on Programming - 加拿大程序员杰夫·普莱辛（Jeff Preshing）的技术博客，主要关注 C++ 和 Python 两门编程语言。他用 C++11 实现了类的反射机制，用 C++ 编写了 3D 小游戏 Hop Out，还为该游戏编写了一个游戏引擎。他还讨论了很多 C++ 的用法，比如 C++14 推荐的代码写法、新增的某些语言构造等，和 Python 很相似。阅读这个技术博客上的内容能够深深感受到博主对编程世界的崇敬和痴迷。 Sutter’s Mill - 赫布·萨特（Herb Sutter）是一位杰出的 C++ 专家，曾担任 ISO C++ 标准委员会秘书和召集人超过 10 年。他的博客有关于 C++ 语言标准最新进展的信息，其中也有他的演讲视频。博客中还讨论了其他技术和 C++ 的差异，如 C# 和 JavaScript，它们的性能特点、怎样避免引入性能方面的缺陷等。 Mechanical Sympathy - 博主是马丁·汤普森（Martin Thompson），他是一名英国的技术极客，探索现代硬件的功能，并提供开发、培训、性能调优和咨询服务。他的博客主题是 Hardware and software working together in harmony，里面探讨了如何设计和编写软件使得它在硬件上能高性能地运行。非常值得一看。 Hints for Computer System Design ，计算机设计的忠告，这是 ACM 图灵奖得主 Butler Lampson 在 Xerox PARC 工作时的一篇论文。这篇论文简明扼要地总结了他在做系统设计时的一些想法，非常值得一读。（用他的话来说，“Studying the design and implementation of a number of computer has led to some general hints for system design. They are described here and illustrated by many examples, ranging from hardware such as the Alto and the Dorado to application programs such as Bravo and Star“。） 程序员练级攻略（2018）：Java底层知识 Java Zone: Introduction to Java Bytecode，这篇文章图文并茂地向你讲述了 Java 字节码的一些细节，是一篇很不错的入门文章。 另外，也推荐一下 JVM Anatomy Park JVM 解剖公园，这是一个系列的文章，每篇文章都不长，但是都很精彩，带你一点一点地把 JVM 中的一些技术解开。 The Garbage Collection Handbook，在豆瓣上的得分居然是 9.9 程序员练级攻略（2018）：数据库 然后推荐《高性能 MySQL》，这本书是 MySQL 领域的经典之作，拥有广泛的影响力。不但适合数据库管理员（DBA）阅读，也适合开发人员参考学习。不管是数据库新手还是专家，都能从本书中有所收获。 如果你对 MySQL 的内部原理有兴趣的话，可以看一下这本书《MySQL 技术内幕：InnoDB 存储引擎》。当然，还有官网的MySQL Internals Manual 。 Why Uber Engineering Switched from Postgres to MySQL ，无意比较两个数据库谁好谁不好，推荐这篇 Uber 的长文，主要是想让你从中学习到一些经验和技术细节，这是一篇很不错的文章。 NoSQL Databases: a Survey and Decision Guidance，这篇文章可以带你自上而下地从 CAP 原理到开始了解 NoSQL 的种种技术，是一篇非常不错的文章。 Distribution, Data, Deployment: Software Architecture Convergence in Big Data Systems，这是卡内基·梅隆大学的一篇讲分布式大数据系统的论文。其中主要讨论了在大数据时代下的软件工程中的一些关键点，也说到了 NoSQL 数据库。 Learn Redis the hard way (in production) at Trivago Elasticsearch: The Definitive Guide这是官网方的 ElasticSearch 的学习资料，基本上来说，看这个就够了。 程序员练级攻略（2018）：分布式架构入门 服务调度，涉及服务发现、配置管理、弹性伸缩、故障恢复等。 资源调度，涉及对底层资源的调度使用，如计算资源、网络资源和存储资源等。 流量调度，涉及路由、负载均衡、流控、熔断等。 数据调度，涉及数据复本、数据一致性、分布式事务、分库、分表等。 容错处理，涉及隔离、幂等、重试、业务补偿、异步、降级等。 自动化运维，涉及持续集成、持续部署、全栈监控、调用链跟踪等。 注意 分布式系统之所以复杂，就是因为其太容易也太经常出错了。这意味着，你要把处理错误的代码当成正常功能的代码来处理。 开发一个健壮的分布式系统的成本是单体系统的几百倍甚至几万倍。这意味着，我们要自己开发一个，需要能力很强的开发人员。 非常健壮的开源的分布式系统并不多，或者说基本没有。这意味着，如果你要用开源的，那么你需要 hold 得住其源码。 管理或是协调多个服务或机器是非常难的。这意味着，我们要去读很多很多的分布式系统的论文。 在分布式环境下，出了问题是很难 debug 的。这意味着，我们需要非常好的监控和跟踪系统，还需要经常做演练和测试。 在分布式环境下，你需要更科学地分析和统计。这意味着，我们要用 P90 这样的统计指标，而不是平均值，我们还需要做容量计划和评估。 在分布式环境下，需要应用服务化。这意味着，我们需要一个服务开发框架，比如 SOA 或微服务。 在分布式环境下，故障不可怕，可怕的是影响面过大，时间过长。这意味着，我们需要花时间来开发我们的自动化运维平台。 分布式架构入门 Scalable Web Architecture and Distributed Systems，这篇文章会给你一个大概的分布式架构是怎么来解决系统扩展性问题的粗略方法。 Scalability, Availability & Stability Patterns ，这个 PPT 能在扩展性、可用性、稳定性等方面给你一个非常大的架构设计视野和思想，可以让你感受一下大概的全景图。 我更强烈推荐 GitHub 上的一篇文档 - System Design Primer ，这个仓库主要组织收集分布式系统的一些与扩展性相关的资源，它可以帮助你学习如何构建可扩展的架构。 分布式理论 首先，你需要看一下 An introduction to distributed systems。 这只是某个教学课程的提纲，我觉得还是很不错的，几乎涵盖了分布式系统方面的所有知识点，而且辅以简洁并切中要害的说明文字，非常适合初学者提纲挈领地了解知识全貌，快速与现有知识结合，形成知识体系。 然后，你需要了解一下拜占庭将军问题（Byzantine Generals Problem）。这个问题是莱斯利·兰波特（Leslie Lamport）于 1982 年提出用来解释一致性问题的一个虚构模型（论文地址）。 Dr.Dobb’s - The Byzantine Generals Problem The Byzantine Generals Problem Practicle Byzantine Fault Tolerance 8 条荒谬的分布式假设（Fallacies of Distributed Computing）”。 原文有更多的推荐资料 拜占庭容错系统研究中有三个重要理论：CAP、FLP 和 DLS。 程序员练级攻略（2018）：分布式架构经典图书和论文 Distributed Systems for fun and profit，这是一本免费的电子书。作者撰写此书的目的是希望以一种更易于理解的方式，讲述以亚马逊的 Dynamo、谷歌的 Bigtable 和 MapReduce 等为代表的分布式系统背后的核心思想。 Designing Data Intensive Applications Kafka: a Distributed Messaging System for Log Processing The Log: What every software engineer should know about real-time data’s unifying abstraction，这篇文章好长，不过这是一篇非常好非常好的文章，这是每个工程师都应用知道的事，必看啊。你可以看中译版《日志：每个软件工程师都应该知道的有关实时数据的统一概念》。 直接看原文吧 程序员练级攻略（2018）：分布式架构工程设计 Designs, Lessons and Advice from Building Large Distributed Systems，Google 杰夫·迪恩（Jeff Dean）2009 年一次演讲的 PPT。2010 年，斯坦福大学请杰夫·迪恩到大学里给他们讲了一节课，你可以在 YouTube 上看一下，Building Software Systems At Google and Lessons Learned，其回顾了 Google 发展的历史。 The Twelve-Factor App ，如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建 SaaS 应用提供了方法论，是架构师必读的文章。（中译版）这篇文章在业内的影响力很大很大，必读！ Notes on Distributed Systems for Young Bloods ，给准备进入分布式系统领域的人的一些忠告。 On Designing and Deploying Internet-Scale Services（中译版），微软 Windows Live 服务平台的一些经验性的总结文章，很值得一读。 设计模式 Cloud Design Patterns Patterns for distributed systems，这是一个 PPT，其中讲了一些分布式系统的架构模式，你可以顺着到 Google 里去搜索。 一致性哈希 Consistent Hashing，这是一个一致性哈希的简单教程，其中还有代码示例。 缓存 缓存更新的套路，这是我在 CoolShell 上写的缓存更新的几个设计模式，包括 Cache Aside、Read/Write Through、Write Behind Caching。 Design Of A Modern Cache ，设计一个现代化的缓存系统需要注意到的东西。 消息队列 Understanding When to use RabbitMQ or Apache Kafka ，什么时候使用 RabbitMQ，什么时候使用 Kafka，通过这篇文章可以让你明白如何做技术决策。 LinkedIn: Running Kafka At Scale ，Linkedin 公司的 Kafka 架构扩展实践。 Exactly-once Semantics are Possible: Here’s How Kafka Does it ，怎样用 Kafka 让只发送一次的语义变为可能。这是业界中一个很难的工程问题。 性能 Understand Latency ，这篇文章收集并整理了一些和系统响应时间相关的文章，可以让你全面了解和 Latency 有关的系统架构和设计经验方面的知识。 Common Bottlenecks ，文中讲述了 20 个常见的系统瓶颈。 各公司的架构实践 High Scalability ，这个网站会定期分享一些大规模系统架构是怎样构建的，下面是迄今为止各个公司的架构说明。 程序员练级攻略（2018）：微服务 微服务是分布式系统中最近比较流行的架构模型，也是 SOA 架构的一个进化。微服务架构并不是银弹，所以，也不要寄希望于微服务构架能够解决所有的问题。微服务架构主要解决的是如何快速地开发和部署我们的服务 首先，你需要看一下，Martin Fowler 的这篇关于微服务架构的文档 - Microservice Architecture （中译版），这篇文章说明了微服务的架构与传统架构的不同之处在于，微服务的每个服务与其数据库都是独立的，可以无依赖地进行部署。 微服务架构 接下来，你可以看一下 IBM 红皮书：Microservices Best Practices for Java ，这本书非常好，不但有通过把 Spring Boot 和 Dropwizard 来架建 Java 的微服务，而且还谈到了一些标准的架构模型，如服务注册、服务发现、API 网关、服务通讯、数据处理、应用安全、测试、部署、运维等，是相当不错的一本书。 Go kit 微服务和 SOA 在对微服务有了一定的认识以后，一定有很多同学分不清楚微服务和 SOA 架构，对此，你可以看一下这本电子书 - 《Microservices vs. Service-Oriented Architecture》。通过这本书，你可以学到，服务化架构的一些事实，还有基础的 SOA 和微服务的架构知识，以及两种架构的不同。这本书的作者马克·理查兹（Mark Richards）同学拥有十年以上的 SOA 和微服务架构的设计和实现的经验。 设计模式和最佳实践 Microservice Patterns，微服务架构的设计模式和最佳实践。 Microservice Antipatterns and Pitfalls，微服务架构的一些已知的反模式和陷阱。 Microservice Architecture: All The Best Practices You Need To Know，这是一篇长文，里面讲述了什么是微服务、微服务架构的优缺点、微服务最大的挑战和解决方案是什么、如何避免出错，以及构建微服务架构的最佳实践等多方面的内容。推荐阅读。 程序员练级攻略（2018）：容器化和自动化运维 可以阅读 Docker 官方文档 Docker Documentation 了，这是学习 Docker 最好的方式。 还有一些不错的与 Docker 网络有关的文章你需要阅读及实践一下。 A container networking overview Docker networking 101 - User defined networks Understanding CNI (Container Networking Interface) Using CNI with Docker Docker 有下面几种网络解决方案：Calico 、Flannel 和 Weave，你需要学习一下。另外，还需要学习一下 netshoot 。这是一个很不错的用来诊断 Docker 网络问题的工具集。 最佳实践 Best Practices for Dockerfile ，Docker 官方文档里的 Dockerfile 的最佳实践。 Docker Best Practices ，这里收集汇总了存在于各个地方的使用 Docker 的建议和实践。 学习 kubernetes，有两个免费的开源电子书。 《Kubernetes Handbook》，这本书记录了作者从零开始学习和使用 Kubernetes 的心路历程，着重于经验分享和总结，同时也会有相关的概念解析。希望能够帮助你少踩坑，少走弯路，还会指引你关注 kubernetes 生态周边，如微服务构建、DevOps、大数据应用、Service Mesh、Cloud Native 等领域。 《Kubernetes 指南》，这本书旨在整理平时在开发和使用 Kubernetes 时的参考指南和实践总结，形成一个系统化的参考指南以方便查阅。 Kubernetes 的官方网站：Kubernetes.io，上面不但有全面的文档 ，也包括一个很不错的 官方教程。 网络相关的文章 要学习 Kubernetes，你只需要读一下，下面这个 Kubernetes 101 系列的文章。 下面是 Github 上和 Docker & Kubernetes 相关的 Awesome 系列。 Awesome Docker。 Awesome Kubernetes。 The New Stack eBook Series ，非常完整和详实的 Docker 和 Kubernetes 生态圈的所有东西。 程序员练级攻略（2018）：机器学习和人工智能 关于机器学习，你可以读一读 Machine Learning is Fun!，这篇文章（中文翻译版）恐怕是全世界最简单的入门资料了。 吴恩达教授（Andrew Ng）在 Coursera 上的免费机器学习课程 非常棒。网易公开课 Deep Learning by Google，Google 的一个关于深度学习的在线免费课程，其支持中英文。这门课会教授你如何训练和优化基本神经网络、卷积神经网络和长短期记忆网络。你将通过项目和任务接触完整的机器学习系统 TensorFlow。 如果你想了解更全的机器学习的算法列表，你可以看一下 Wikipedia 上的 List of Machine Learning Algorithms。 在 A Tour of Machine Learning Algorithms，这篇文章带你概览了一些机器学习算法，其中还有一个 \" 脑图 \" 可以下载，并还有一些 How-To 的文章供你参考。 对于初学者来说，动手是非常非常重要的，不然，你会在理论的知识里迷失掉自己，这里有篇文章 \"8 Fun Machine Learning Projects for Beginners\"，其中为初学者准备了 8 个很有趣的项目，你可以跟着练练。 程序员练级攻略（2018）：前端基础和底层原理 首先，前端的三个最基本的东西 HTML5、CSS3 和 JavaScript（ES6）是必需要学好的。这其中有很多很多的技术，比如，CSS3 引申出来的 Canvas（位图）、SVG（矢量图） 和 WebGL（3D 图），以及 CSS 的各种图形变换可以让你做出非常丰富的渲染效果和动画效果。 JavaScript 的核心原理。这里我会给出好些网上很不错的讲 JavaScript 的原理的文章或图书，你一定要学好语言的特性和其中的各种坑。 浏览器的工作原理。这也是一块硬骨头，我觉得这是前端程序员需要了解和明白的东西，不然，你将无法深入下去。 网络协议 HTTP。也是要着重了解的，尤其是 HTTP/2，还有 HTTP 的几种请求方式：短连接、长连接、Stream 连接、WebSocket 连接。 前端性能调优。有了以上的这些基础后，你就可以进入前端性能调优的主题了，我相信你可以很容易上手各种性能调优技术的。 框架学习。我只给了 React 和 Vue 两个框架。就这两个框架来说，Virtual DOM 技术是其底层技术，组件化是其思想，管理组件的状态是其重点。而对于 React 来说，函数式编程又是其编程思想，所以，这些基础技术都是你需要好好研究和学习的。 UI 设计。设计也是前端需要做的一个事，比如像 Google 的 Material UI，或是比较流行的 Atomic Design 等应该是前端工程师需要学习的。 推荐资料 HTML5 权威指南，本书面向初学者和中等水平 Web 开发人员，是牢固掌握 HTML5、CSS3 和 JavaScript 的必读之作。书看起来比较厚，是因为里面的代码很多。 在《程序员练级攻略（2018）》系列文章最开始，我们就推荐过 CSS 的在线学习文档，这里再推荐一下 MDN Web Doc - CSS 。 你需要学会使用 LESS 和 SaSS 这两个 CSS 预处理工具，其可以帮你提高很多效率。 JavaScript: The Good Parts，中文翻译版为《JavaScript 语言精粹》。这是一本介绍 JavaScript 语言本质的权威图书，值得任何正在或准备从事 JavaScript 开发的人阅读，并且需要反复阅读。学习、理解、实践大师的思想，我们才可能站在巨人的肩上，才有机会超越大师，这本书就是开始。 Secrets of the JavaScript Ninja，中文翻译版为《JavaScript 忍者秘籍》，本书是 jQuery 库创始人编写的一本深入剖析 JavaScript 语言的书。适合具备一定 JavaScript 基础知识的读者阅读，也适合从事程序设计工作并想要深入探索 JavaScript 语言的读者阅读。这本书有很多晦涩难懂的地方，需要仔细阅读，反复琢磨。 Effective JavaScript，Ecma 的 JavaScript 标准化委员会著名专家撰写，作者凭借多年标准化委员会工作和实践经验，深刻辨析 JavaScript 的内部运作机制、特性、陷阱和编程最佳实践，将它们高度浓缩为极具实践指导意义的 68 条精华建议。 “How JavaScript Works” 是一组非常不错的文章（可能还没有写完），强烈推荐。这一系列的文章是 SessionStake 的 CEO 写的，现在有 13 篇，我感觉可能还没有写完。这个叫 亚历山大·兹拉特科夫（Alexander Zlatkov） 的 CEO 太猛了。 你需要了解一下浏览器是怎么工作的，所以，你必需要看《How browsers work》。这篇文章受众之大，后来被人重新整理并发布为《How Browsers Work: Behind the scenes of modern web browsers》，其中还包括中文版。这篇文章非常非常长，所以，你要有耐心看完。如果你想看个精简版的，可以看我在 Coolshell 上发的《浏览器的渲染原理简介》或是看一下这个幻灯片。 High Performance Browser Networking，本书是谷歌公司高性能团队核心成员的权威之作，堪称实战经验与规范解读完美结合的产物。本书目标是涵盖 Web 开发者技术体系中应该掌握的所有网络及性能优化知识。 另外，HTTP/2也是 HTTP 的一个新的协议，于 2015 年被批准通过，现在基本上所有的主流浏览器都默认启用这个协议。所以，你有必要学习一下这个协议。下面相关的学习资源。Gitbook - HTTP/2 详解 An introduction to Websockets，一个 WebSocket 的简单教程。 程序员练级攻略（2018）：前端性能优化和框架 Web Performance in Action，这本书目前国内没有卖的。你可以看电子版本，我觉得是一本很不错的书，其中有 CSS、图片、字体、JavaScript 性能调优等。 Designing for Performance ，这本在线的电子书很不错，其中讲了很多网页优化的技术和相关的工具，可以让你对整体网页性能优化有所了解。 High Performance JavaScript，这本书在国内可以买到，能让你了解如何提升各方面的性能，包括代码的加载、运行、DOM 交互、页面生存周期等。雅虎的前端工程师尼古拉斯·扎卡斯（Nicholas C. Zakas）和其他五位 JavaScript 专家介绍了页面代码加载的最佳方法和编程技巧，来帮助你编写更为高效和快速的代码。你还会了解到构建和部署文件到生产环境的最佳实践，以及有助于定位线上问题的工具。 High Performance Web Sites: Essential Knowledge for Front-End Engineers，这本书国内也有卖，翻译版为《高性能网站建设指南：前端工程师技能精髓》。作者给出了 14 条具体的优化原则，每一条原则都配以范例佐证，并提供了在线支持。 Browser Diet ，前端权威性能指南（中文版）。这是一群为大型站点工作的专家们建立的一份前端性能的工作指南。 PageSpeed Insights Rules，谷歌给的一份性能指南和最佳实践。 Best Practices for Speeding Up Your Web Site，雅虎公司给的一份 7 个分类共 35 个最佳实践的文档。 程序员练级攻略（2018）：UI/UX设计 Don’t Make Me Think，这是我看的第一本和设计相关的书。这本书对我的影响也比较深远。这本书践行了自己的理论，整本书短小精悍，语言轻松诙谐，书中穿插大量色彩丰富的屏幕截图、趣味丛生的卡通插图以及包含大量信息的图表，使枯燥的设计原理变得平易近人。 The Psychology Principles Every UI/UX Designer Needs to Know，这篇文章讲述了 6 大用户界面用户体验设计的心理学原则。 18 designers predict UI/UX trends for 2018， 我倒不觉得这篇文章中所说的 UI/UX 是在 2018 年的趋势，我反而觉得，这 18 条原则是指导性的思想。 The Evolution of UI/UX Designers Into Product Designers，这篇文章是 Adobe 公司的一篇博客，其在回顾整个产品设计的演化过程中有一些不错的思考和想法，并提供了一些方法论。 程序员练级攻略（2018）：技术资源集散地 Coding Horror ，这是杰夫·阿特伍德（Jeff Atwood）于 2004 年创办的博客，记录其在软件开发经历中的所思所想、点点滴滴。时至今日，该博客每天都有近 10 万人次的访问量，读者纷纷参与评论，各种观点与智慧在这里不断地激情碰撞。其博文选集在中国被翻译成《高效能程序员的修练》，在豆瓣上有 8.3 的高分。2008 年，他和 Joel Spolsky 联合创办了 StackOverflow 问答网站，为程序员在开发软件时节省了非常多的时间，并开启了“StackOverflow Copy + Paste 式编程”。 Joel on Software，Joel Spolsky 的这个博客在全世界都有很多的读者和粉丝，其博文选集在中国被翻译成《软件随想录》在豆瓣上有 8.7 的高分。这是一本关于软件技术、人才、创业和企业管理的随想文集，作者以诙谐幽默的笔触将自己在软件行业的亲身感悟娓娓道来，观点新颖独特，简洁实用。 Clean Coder Blog，这是编程大师“Bob 大叔”的博客，其真名叫 Robert C. Martin，世界级软件开发大师，设计模式和敏捷开发先驱，敏捷联盟首任主席，C++ Report 前主编，被后辈程序员尊称为“Bob 大叔”。其博文选集在中国被翻译成《程序员的职业素养》，在豆瓣上有 8.8 的高分。 Martin Fowler，这是另外一个程序员大师，Martin 主要专注于面向对象分析与设计、统一建模语言、领域建模，以及敏捷软件开发方法，包括极限编程。他的《重构》、《分析模式》、《企业应用架构模式》、《领域特定语言》和《NoSQL 精粹》都是非常不错的书。在他的博客上有很多很多的编程和架构模式方法可以学习。 Paul Graham Essays，美国著名程序员、风险投资家、博客和技术作家。《黑客与画家》是他的著作之一。2005 年他与人共同创建了著名的创业投资公司 Y Combinator，是初创公司最想被投的。他有几篇创业方面的文章都很经典，如果你想创业，可以读一读这几篇：《How to Get Startup Ideas》、《Do Things that Don’t Scale》、《Startup = Growth》。Paul Graham 的文章以清新自然，思想深刻见长。不仅可以跟 Paul Graham 学创业，学思考，学技术，更可以学习写作。 Steve Yegge，Steve Yegge 这个人算是一个知名的程序员了，在 Amazon 呆过，现在在 Google，他的文章都是长篇大论，最知名的文章就是对 Amazon 和 Google 平台的吐槽，这篇文章引发了大家的讨论和议论。 Bruce Eckel’s Programming Blog，《Thinking in Java》作者的博客，他之前的博客在 artima - Computing Thoughts 。 Herb Sutter，C++ 大拿，C++ 标准委员会专家，微软软件架构师。《Exceptional C++ 》、《More Exceptional C++》、《Exceptional C++ Style》作者。 Eli Bendersky’s website，这位老哥从 2003 年就一直写博客到今天，其中的文章都非常不错，原理型的，主要是 C、C++ 和 Python 相关的。里面有很多干货。 Peter Krumins’ blog ，这位老哥从 2007 年开始写博客，他博客里好玩的东西太多了。 Brendan D. Gregg，Brendan 是 Netflix 的工程师，他的博客里有大量的非常非常不错的文章，基本上都是和 Linux 性能分析相关的，这是一个如果你要玩底层性能分析一定不能错过的博客。 - Evan Klitzke ，主要讨论 Linux 和 C++ 相关的内容。 Julia Evans，主要讨论 Linux debug 工具和网络相关的内容。 null program，和 C/C++ 相关的一个博客。其中关于 Linux 系统调用、GPU、无锁编程、JIT 编译的一些文章非常不错。 Fluent {C++}，博主是 Murex 的首席工程师，主要玩 C++，在这个博客里有很多很不错的 C++ 相关的文章。 Preshing on Programming，这也是一个和 C/C++ 相关的博客，其中有很多的干货。 Programming is Terrible，这个博客有很多强观点的文章，主要是软件开发中的一些教训。 Accidentally Quadratic，姑且翻译成事故二次方，这里有好些非常有趣的文章。 Hacker Noon，这是一个一堆人在写的博客，里面有很多质量很高的文章。 其实还有很多不错的博客，不过，现在国外不错的博客都在一个叫 Medium的网站，我也发现我 Google 很多东西时都会到这个网站上。这个网站上的内容不只有技术的，还有很多很多其他方面的内容，比如文化、艺术、科学等等。这个网站就是一个博客发布系统，其是由 Twitter 联合创始人埃文·克拉克·威廉姆斯（Evan Clark Williams）和克里斯多福·艾萨克·比兹·斯通（Christopher Isaac Biz Stone）创办的，这两个人觉得 Twitter 上全是垃圾没有营养的信息。所以，创办了 Medium，这个平台上有专业和非专业的贡献者，亦有受雇的编者。 各大公司技术博客 随后是 Airbnb、AWS、Cloudera、Dropbox、Facebook、Google 等各个公司的技术博客，跟随这些公司的博客，你不但可以看到这些公司的工程技术，还能掌握到一些技术方向和趋势。 如何读论文：下面有几篇文章，教你一些读论文的方法，非常不错。 How to read an academic article Advice on reading academic papers Advice on reading academic papers How to read and understand a scientific paper Should I Read Papers? The Refreshingly Rewarding Realm of Research Papers 论文集散地：要成长为一个高手，论文是你一定要读的。下面是一些非常不错的计算机方面的论文集散地。 2 Minute Papers，这是一个 YouTube 的频道，其会给出一些非常不错的和计算机相关的论文介绍，让你了解目前最有意思的一些科学突破，每次两分钟左右。 Best Paper Awards in Computer Science，从 1996 年以来，获奖的计算机科学方面的论文收集。 Usenix: Best Papers，Usenix 上推荐的最佳论文。 The Morning Paper，该博客会每天推送一篇论文，特别棒。 程序员面试攻略：面试前的准备 一般来说，简历需要包括以下几项内容。 自我简介。这个自我简介是用最简单的话来说明自己的情况，不超过 200 字。比如：10+ 年的软件开发经验（说明你的主业），4+ 年的团队 leader 经验（说明你的领导力），擅长高可用高性能的分布式架构（说明你的专业和专攻），多年互联网和金融行业背景（说明你的行业背景），任职于 XXX 公司的 XX 职位（说明你的职业），负责 XXX 平台或系统（说明你的业务场景） 技术技能栈。其中包括你擅长和会用的编程语言（如 Java、Go、Python 等），编程框架或一些重要的库（如 Spring Boot、Netty、React.js、gRPC 等），熟悉的一些技术软件（如 Redis、Kafka、Docker 等），设计或架构（如面向对象设计、分布式系统架构、异步编程、高性能调优等）。 技术领域。前端、算法、机器学习、分布式、底层、数据库等。 业务领域。一方面是行业领域，如金融、电商、电信等，另一方面是业务领域，如 CRM、支付、物流、商品等。 经验和软技能。带过多少人的团队、有多少年的项目管理经验、学习能力如何、执行力怎么样、设计过什么样的系统。（不要太多，几句话就好。） 技术知识准备 你写上了 Java，那么 Java 的基本语法都要了解，并发编程、NIO、JVM 等，你多少要有点儿了解，Spring、Netty 这些框架也要了解。 你写上了 Go，那么至少得把官网上的 Effective Go 给看了。 你写上了 Redis，那么除了 Redis 的数据结构，Redis 的性能优化、高可用配置、分布式锁什么的，你多少也要把官网上的那几篇文章读一读。 你写上了面向对象，那么怎么着也得把《设计模式》中的 23 个模式了解一下。 你写上了分布式架构，那么 CAP 理论、微服务架构、弹力设计、Spring Cloud、Cloud Native 这些架构就要做到心里有数。 你写上网络编程，那么 TCP/IP 的三次握手，四次挥手，两端的状态变化你得知道吧，Socket 编程的那几个系统调用，还有 select、poll、epoll 这些异步 IO 多路复用的东西，你得知道。 程序员面试攻略：面试中的技巧 一般来说，面试结束的时候，都会问你有没有什么问题。不要放弃这个机会。 如果你面得比较好，这个时候可以问几个尖锐的问题，这样有利于后面谈 offer 和岗位（抓住机会反转被动为主动）。比如，我就问过国外某一线公司的面试官下面两组问题： 你们公司有多少一线开发经理还在写代码？你们的一线经理都没有时间来写代码了，不知道细节怎么做好管理？另外是不是说明你们公司有大量的内耗？ 任何公司都有好的有不好的，你能不能分享一下你最喜欢这个公司的地方和最不喜欢的地方？ 对于技术的热情或初心体现在你生活和工作中的哪里？这个问题其实是想了解一下你的性格，以及对生活和工作的态度。这个问题会伴随着很多细节上的追问。所以，你要小心回答，而且是要带感情的，但一定要是真实的。 一般来说，热情和初心不是停留在嘴上的，而是要表现在行动上的，你需要给出几个曾经发生过的示例。这些示例可以是：你死磕某个事解决某个难题不认输的精神；你坚持做某件事，无论风吹雨打，无论有没有激励；你在某个逆境中依然没有放弃依然努力的态度；在面对压力时，你勇于承担责任的精神；你严谨细心、精益求精的做事风格；面对诱惑能沉得住气，不浮躁…… 总结一下，对技术的热情或初心，需要表现在这么几个特质上：执着、坚持、坚韧、不服输、担当、不妥协、不浮燥……我说一句，我相信每个人或多或少都会有这些特质，这是你的亮点，要小心呵护。不然，你跟一条咸鱼就没什么两样了。 你在一家公司呆了接近 10 年为什么没有做到管理层？你又是怎么保持竞争力的？一般来说，不想做管理的程序员也挺多的，在技术的方向上勤勤恳恳深耕细作，会是一个非常难得的优秀工程师。专注于技术，不分心，不断地在技术上的深度和广度上钻研，这就是保持竞争力最好的方式。所以，其实这个问题挺好回答的。 程序员面试攻略：面试风格 国内：基础知识扎实、有深度，多看技术书 国外：实践，解题思路 有些很有经验的面试官会从一个很简单的编码题开始，然后不断地加需求，或是改需求。一旦你发现这个事的时候，我给你的建议是不要马上实现新的需求，而是停下来，和面试官讨论需求，感觉一下未来可能的需求变化，然后开始重构代码，抽象该抽象的代码，将接口和实现分离，把程序逻辑和业务功能分离。 在设计和架构中，一般会涉及面向对象方面、数据库设计方面和系统架构方面的内容。系统架构方面的内容问得也很多，基本上都在问一些和高并发、高可用、高性能和大规模分布式相关的架构。但是，在你解题前，你一定要问清楚需求，不要仓促 jump into conclusion。先调研需求，最好再问一下，为什么要做这个需求？做这个需求的意义是什么？ 当你了解完需求后，你还可以挑战一下，如果是这个需求的话，为什么不用另外一种方式或架构？这些问题，都是加分项。搞清楚需求后，你要开始设计系统了。设计系统时，你不要只是拍脑袋，还需要做一点容量计算。如果数据不完整，你直接跟面试官说清楚就好了，有数据上的支持会让你更好地设计好你的架构，而且，这会是非常大的加分项。 另外，在设计系统时，还要考虑到系统未来的扩展性，也就是未来如果又加入一些别的东西进来，或是量变得很大了，你的系统是否可以容易地进行功能扩展或性能扩展。这个架构问题，如果你没有足够丰富的经验，或是严谨的思考，并不容易做得出来。 Problem Solving 是一些国外公司尤其是 Amazon 最喜欢面的一个环节了。国外的这些大公司都认为他们要解决的问题是没有人解决过的，所以他们需要的人才也是能解决自己从来没有见过的问题的人。一般来说，面试官会给你一个你从来没有见过的问题，而且是很难的问题，很明显是一个只有工程师才能解的问题。 程序员面试攻略：实力才是王中王 想取得良好的面试效果，也是需要多加练习的，隔三岔五就出去面试一下，积累面试经验的同时，也了解一下市场行情。然后探讨一个有些敏感的话题“跳槽和加薪”，我认为，先去国外，然后在需要职业成长的时候，被国内公司重金请回来，会比直接在国内的公司里发展要好一些。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/haozi/6.html":{"url":"note/haozi/6.html","title":"高效学习","keywords":"","body":"端正学习态度 如果你去研究一下古今中外的成功人士，就会发现，他们基本上都是非常自律的，也都是非常热爱学习的。他们可以沉得下心来不断地学习，在学习中不断地思考、探索和实践。 被动学习：如听讲、阅读、试听、演示，学习内容的平均留存率为 5%、10%、20% 和 30%。 主动学习：如通过讨论、实践、教授给他人，会将原来被动学习的内容留存率从 5% 提升到 50%、75% 和 90%。 浅度学习和深度学习 知识采集。信息源是非常重要的，获取信息源头、破解表面信息的内在本质、多方数据印证，是这个步骤的关键。 知识缝合。所谓缝合就是把信息组织起来，成为结构体的知识。这里，连接记忆，逻辑推理，知识梳理是很重要的三部分。 技能转换。通过举一反三、实践和练习，以及传授教导，把知识转化成自己的技能。这种技能可以让你进入更高的阶层。 学习是为了找到方法 学习是为了找到原理 学习是为了了解自己 学习是为了改变自己 源头、原理和知识地图 注重基础和原理。最最关键的是，这些基础知识和原理性的东西和技术，都是经历过长时间的考验的，所以，这些基础技术也有很多人类历史上的智慧结晶，会给你很多启示和帮助。比如：TCP 协议的状态机，可以让你明白，如果你要设计一个异步通信协议，状态机是一件多么重要的事，还有 TCP 拥塞控制中的方式，让你知道，设计一个以响应时间来限流的中件间是什么样的。 使用知识图。通过“顺藤摸瓜”的方式，从知识树的主干开始做广度或是深度遍历，于是我就得到了一整棵的知识树。这种“顺藤摸瓜”的记忆方式让我记住了很多知识。最重要的是，当出现一些我不知道的知识点时，我就会往这棵知识树上挂，而这样一来，也使得我的学习更为系统和全面。 深度，归纳和坚持实践 系统地学习 这个技术出现的背景、初衷和要达到什么样的目标或是要解决什么样的问题。 这个技术的优势和劣势分别是什么，或者说，这个技术的 trade-off 是什么。 这个技术适用的场景。所谓场景一般分别两个，一个是业务场景，一个是技术场景。 技术的组成部分和关键点。 技术的底层原理和关键实现。 已有的实现和它之间的对比。 举一反三 联想能力。这种能力的锻炼需要你平时就在不停地思考同一个事物的不同的用法，或是联想与之有关的别的事物。对于软件开发和技术学习也一样。 抽象能力。抽象能力是举一反三的基本技能。平时你解决问题的时候，如果你能对这个问题进行抽象，你就可以获得更多的表现形式。 自省能力。所谓自省能力就是自己找自己的难看。当你得到一个解的时候，要站在自己的对立面来找这个解的漏洞。 例如 对于一个场景，制造出各种不同的问题或难题。 对于一个问题，努力寻找尽可能多的解，并比较这些解的优劣。 对于一个解，努力寻找各种不同的测试案例，以图让其健壮。 总结和归纳 把你看到和学习到的信息，归整好，排列好，关联好，总之把信息碎片给结构化掉，然后在结构化的信息中，找到规律，找到相通之处，找到共同之处，进行简化、归纳和总结，最终形成一种套路，一种模式，一种通用方法。 对自己的知识进行总结和归纳是提高学习能力的一个非常重要的手段。这是把一个复杂问题用简单的语言来描述的能力。 学习的开始阶段，可以不急于总结归纳，不急于下判断，做结论，而应该保留部分知识的不确定性，保持对知识的开放状态。 实践出真知 实践出真知也就是英文中的 Eat your own dog food 那些大公司里的开发人员，写完代码，自己不测试，自己也不运维，我实在不知道他们怎么可能明白什么是好的设计，好的软件？ 坚持不懈 如何学习和阅读代码 书和文档是人对人说的话，代码是人对机器说的话（注：代码中有一部份逻辑是控制流程的逻辑，不是业务逻辑）。所以， 如果你想知道人为什么要这么搞，那么应该去看书（像 Effective C++、Code Complete、Design Pattern、Thinking in Java 等），看文档。 如果你要知道让机器干了什么？那你应该看代码！（就像 Linus 去看 zlib 的代码来找性能问题。） 读代码的前提 相关的语言和基础技术的知识。 软件功能。你先要知道这个软件完成的是什么样的功能，有哪些特性，哪些配置项。你先要读一遍用户手册，然后让软件跑起来。 相关文档。读一下相关的内部文档，Readme 也好，Release Notes 也好，Design 也好，Wiki 也好。 代码的组织结构。也就是代码目录中每个目录是什么样的功能，每个文档是干什么的。 阅读代码的方法 一般采用自顶向下，从总体到细节的“剥洋葱皮”的读法。 画图是必要的，程序流程图，调用时序图，模块组织图…… 代码逻辑归一下类，排除杂音，主要逻辑才会更清楚。 debug 跟踪一下代码是了解代码在执行中发生了什么的最好方式。 了解这个软件的代码的构成 接口抽象定义 模块粘合层 业务流程 具体实现 代码逻辑 出错处理 数据处理 重要的算法 底层交互 运行时调试 面对枯燥和量大的知识 认真阅读文档 小技巧 用不同的方式来学习同一个东西。比如：通过看书，听课，创建脑图，写博客，讲课，解决实际问题，等等。 总结压缩信息。当你获得太多的信息时，你需要有一个“压缩算法”。 把未知关联到已知。把你新学的知识点关联到已知的事物上来。比如，你在学习 Go 语言，你就把一些知识关联到自己已经学过的语言上比如 C 和 Java。通过类比，你会学得更扎实，也会思考得更多。 用教的方式来学习。你想想，如果你过几天要在公开场合对很多人讲一个技术，那么这个压力会让你学得更好。 学以致用。把学到的东西用起来，没有什么比用起来能让你的知识更巩固的了。在实践中，你才会有更为真实的体会，你才会遇到非常细节和非常具体的问题，这些都会让你重新思考，或深化学习。 不要记忆。聪明的人不会记忆知识的，他们会找方法，那些可以推导出知识或答案的方法。这也是为什么外国人特别喜欢方法论。 多犯错误。犯错会让你学得到更多，通过错误总结教训，你会比没有犯过错的人体会得更深。但是千万不要犯低级错误，也不要同一个错误犯两次。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/haozi/7.html":{"url":"note/haozi/7.html","title":"高效沟通","keywords":"","body":"Talk和Code同等重要 不要想当然地认为别人理解了你说的话 沟通阻碍和应对方法 在沟通之前，首先要想清楚沟通的目的是什么，然后整理自己的措辞。如果是一些比较重要的沟通，最好可以把自己的想法写下来，然后放一会儿，再回过头来看，想象一下如果是别人对自己讲这些话，自己会怎么理解。 当别人没有表达清楚的时候，你要及时打断对方，跟对方说，你没有听懂，你不知道这是什么意思，是否可以重新澄清一下 信息太多：给出主要信息 信息交互：找到对方的兴趣点，降低表达自己真实想法的门槛，培养让大家畅所欲言的自由环境，把自己的答案变成问题，让其它人有参与感，这样才可能有好的沟通，也能够有好的结果。‘ 沟通方式及技巧 尊重对方、倾听对方和情绪控制 我可以不同意你，但是会捍卫你说话的权利。即便在你不认同对方观点的情况下，也要尊重对方的表达，认真聆听，这个时候有可能你会发现不一样的东西，从而改变自己最初不准确的认知。 赢得对方的尊重需要先尊重对方。在你对他人表现出足够的尊重之后，同时你也能够赢得对方的尊重，他会更乐于跟你交谈，而且交流的内容也会更为细致和深入，从而实现良好的沟通效果。 《沟通的艺术》一书中将“倾听”定位为至少与“说”同等重要的沟通形式，足以见其重要性。作者认为，倾听与听或者听到有很大不同，它是解读别人所说信息的过程，包含听到、专注、理解、回应和记忆五大元素。 面试的时候，一般来说会面试的面试官基本上都不多说话，都是在听你讲，你讲的越多，他就了解你越多 沟通原则 不要过早或者过度打岔和反驳。 求同存异，冷静客观。 沟通技巧 引起对方的兴趣 直达主题，强化观点，deal with ambiguity 很多时候，整个世界都是模糊的、有歧义的 基于数据和事实，要尽量少说“可能、也许、我觉得就这样” 沟通技术 有逻辑的表达，更容易说服对方。信息全面准确，更有利于让沟通的双方清楚定位问题，从而更高效地解决问题。 信息要全面、准确。这里重点提一下 X/Y 问题。X/Y 问题是一件非常讨厌的事情。有时候我们拿着 Y 问题去找别人，问到一半才知道，我们原来要问的是 X 问题。 在和人争论时，如果要反驳，那一定是低维度反驳，越细节越好。而在说服对方时，则要在高维度说服对方，越宏观越好 一定要是有思想深度的金句，才有力量。推荐你看三本书《清醒思考的艺术》、《简单逻辑学》和《重来》。 我是先被《重来》洗脑了，这本书帮我开拓了眼界，打破了我既有的思维模式，让我反思过去习以为常的每一件事。同时书中给出了实用、可操作的建议，让我头一次从心底感受到，原来世界还可以如此不同。 然后，我看了《清醒思考的艺术》，这本书作者以显微镜般的观察发现人们常犯的 52 个思维错误，并一一列出。帮人们认识到错误的思维是如何发生，从而避免掉入思维陷阱中。看这本书的过程中，我能明显感觉到自己的思维方式在被重新构造。 随后是《简单逻辑学》。逻辑学是很枯燥的，但这本书的作者以其简练而又充满趣味的笔触，将逻辑学活化为一种艺术，从它的基本原理，到论证，到非逻辑思维的根源，再到 28 种就发生在人们身边的非逻辑思维形式，带领我们进入这个精彩无比的逻辑世界，体会妙趣横生的思维交锋，跨过无处不在的逻辑陷阱，让人沉醉其中，欲罢不能。 好老板要善于提问 引导，用提问的方式，“倒逼”员工找到答案，从而提高员工的参与感和成就感。 管理者要想尽一切办法让员工自己思考问题，想出答案；而不是灌输，什么事儿都是自己在想，自己讲给员工听 如果这么做的话，会有一个什么问题，而这个问题很重要，如何解决？然后，他会给出解决这个问题的方法。但这么做又会带来另一个问题，直到把他逼到你想要的答案上去。 倾听，心态平和，毫无偏见，全面接收和理解对方的信息，而不是只听自己想听的信息。 共情，又被称为同理心，或者换位思考，它指的是站在对方立场设身处地思考问题的一种方式。换句话说，在人际交往过程中，你需要能够体会他人的情绪和想法、理解他人的立场和感受，并站在他人的角度思考和处理问题。 高维，提升自己的格局观，能从全局利益、长远利益思考问题，解决问题。 反馈，建立反馈机制，及时发现问题、解决问题，形成正向循环。 不管你遇到什么问题，如果自己在那儿憋一个小时找不到解决方案，或者说没有任何思路，就要反馈到高级工程师这边来。 如果跟高级工程师在一起两个小时内，找不到任何解决方案或者没有思路，那么就要反馈到一线 leader。 如果一线 leader、高级工程师，花了三个小时，依然找不到方案，那么这个事就可能是个大事了，要向上级反馈了。 好好说话的艺术 与员工沟通 一对一会议：好的一对一会议是以员工为中心的，而不是以管理者为中心的。一对一会议时，管理者需要做的是倾听，而非“喋喋不休”地教育。 频率是每半个月一次 了解：工作状态、个人发展、公司组织、Leader 自己 直言的人不是坏人，没有让你去猜 及时反馈，不要秋后算账 与客户沟通 做足功课，了解客户的痛点或是 KPI 是与客户沟通的第一步，也是最关键的一步，不仅可以引起对方的兴趣，还能决定见面时沟通的内容。兵法有云：知己知彼方能百战不殆。 我们可以和客户一起分析，哪种选择更为合理、可行，将选择权交给客户。这里记住，永远不要跟客户说不，要有条件地说是，告诉客户不同的期望要有不同的付出和不同的成本。不要帮客户做决定，而是给客户提供尽可能多的选项，让客户来做决定。 讨价还价是这个世界能运转的原因之一，要学会使用。 小心 X/Y 问题，找到 X 问题。在《沟通技术》一文中，我提到过 X/Y 问题。 与老板沟通 了解老板的老板的需求 赢得老板的信任 非暴力“怼”老板：沉默是金 结束语 这个世界不存在知识不够的情况，真的还没有到知识被少数精英的攥在手里面不给大家的情况，这个世界上的知识就像阳光和空气一样，根本不需要你付费，你就可以获得的。 不要说，某某技术因为太复杂了所以是“反人类的”，那些“硬核技术”不是反人类的，是“反低能人类”的。所以，别把自己归到那个类别中。要学会不断地挑战自己，挑战自己就是不让自己舒舒服服地像个僵尸一样地活着，而是改变自己让自己像凤凰一样在浴火中涅槃重生！ 成长快乐 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/mysql/":{"url":"note/mysql/","title":"mysql","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/mysql/lecture-on-mysql-1.html":{"url":"note/mysql/lecture-on-mysql-1.html","title":"mysql实战45讲1","keywords":"","body":"01 | 基础架构:一条SQL查询语句是如何执行的? MySQL可以分为Server层和存储引擎层两部分。 Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数(如日期、时间、数学和加密函数等)，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、 Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了默认存储引擎。 客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数wait_timeout控制 的，默认值是8小时。 一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。 大多数情况下我会建议你不要使用查询缓存。原因？ 02 | 日志系统:一条SQL更新语句是如何执行的? 更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主 角:redo log(重做日志，物理日志)和 binlog(归档日志，逻辑日志)。 redo log用于保证crash-safe能力。innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。这个参数我建议你设置成1，这样可以保证MySQL异常重启之后数据不丢失。 sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数我也建 议你设置成1，这样可以保证MySQL异常重启之后binlog不丢失。 update 的过程，两阶段提交 执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器;否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redolog里面，此时redolog处 于prepare状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的binlog，并把binlog写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的redolog改成提交(commit)状态，更新完成。 03 | 事务隔离:为什么你改了我还看不见? 当数据库上有多个事务同时执行的时候，就可能出现脏读(dirty read)、不可重复读(non-repeatable read)、幻读(phantom read)的问题，为了解决这些问题，就有了“隔离级别”的概念。 show variables like 'transaction_isolation'; select @@global.tx_isolation; 查看当前隔离级别；设置 set session transaction isolatin level repeatable read; SQL标准的事务隔离级别包括:读未提交(read uncommitted)、读提交(read committed)、可重复读(repeatable read)和串行化(serializable ) 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一 致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突 的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离 级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级 别下，这个视图是在每个SQL语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离 级别下直接返回记录上的最新值，没有视图概念;而“串行化”隔离级别下直接用加锁的方式来避 免并行访问。 Oracle数据库的默认隔离级别其 实就是“读提交”，因此对于一些从Oracle迁移到MySQL的应用，为保证数据库隔离级别的一致，你一定要记得将MySQL的隔离级别设置为“读提交”。 MySQL的事务启动方式有以下几种: 显式启动事务语句，begin 或 start transaction。配套的提交语句是commit，回滚语句是 rollback。 set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。 在mysql命令行的默认下，事务都是自动提交的，sql语句提交后马上会执行commit操作。开启一个事务必须使用begin，start transaction，或执行 set autocommit=0； commit （commit work） commit work与completion_type的关系，commit work是用来控制事务结束后的行为，是chain还是release的，可以通过参数completion_type来控制，默认为0（或者NO_CHAIN），表示没有任何操作 与commit效果一样。当completion_type=1的时候 04 | 深入浅出索引(上) 以InnoDB的一个整数字段索引为例，这个N差不多是1200。这棵树高是4的时候，就可以存 1200的3次方个值，这已经17亿了。考虑到树根的数据块总是在内存中的，一个10亿行的表上一 个整数字段的索引，查找一个值最多只需要访问3次磁盘。 索引类型分为主键索引和非主键索引。 主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引(clustered index)。 非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引 (secondary index)。 由于InnoDB是索引组织表，一般情况下我会建议你创建一个自增主键，这样非主键索引占用的空间最小。 有同学问到为什么要重建索引。我们文章里面有提到，索引可能因为删除，或者页分 裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。 05 | 深入浅出索引(下) 从二级索引回到主键索引树搜索的过程，我们称为回表。 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。 如果有根据身份证号查询市民信息的需求， 我们只要在身份证号字段上建立索引就够了。而再建立一个(身份证号、姓名)的联合索引，是不是浪费空间?如果现在有一个高频请求，要根据市民的身份证号查询他的姓名，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。 最左前缀原则 在建立联合索引的时候，如何安排索 引内的字段顺序。这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了(a,b)这个联合索引后，一般就不需要单独在a上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。 其次，考虑的原则就是空间了。比如上面这个市民表的情况，name字段是比age字段 大的 ，那我就建议你创建一个(name,age)的联合索引和一个(age)的单字段索引。 索引下推 在MySQL 5.6之前，只能从ID3开始一个个回表。到主键索引上找出数据行，再对比字段值。而MySQL 5.6 引入的索引下推优化(index condition pushdown)， 可以在索引遍历过程中，对索 引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 06 | 全局锁和表锁 :给表加个字段怎么有这么多阻碍? 根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类。 全局锁的典型使用场景是，做全库逻辑备份。MySQL提供了一个加全局读锁的方法，命令是Flush tables with read lock(FTWRL)。 官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导 数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。 为什么不使用set global readonly=true的方式呢? 一是，在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备 库。因此，修改global变量的方式影响面更大，我不建议你使用。 二是，在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么 MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个 库长时间处于不可写状态，风险较高。 MySQL里面表级别的锁有两种:一种是表锁，一种是元数据锁(meta data lock，MDL)。 表锁的语法是 lock tables ...read/write，可以用unlock tables主动释放锁， 也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写 外，也限定了本线程接下来的操作对象。 另一类表级的锁是MDL(metadata lock)。MDL不需要显式使用，在访问一个表的时候会被 自动加上。MDL的作用是，保证读写的正确性。 MDL会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。 07 | 行锁功过： 怎么减少行锁对性能的影响？ 在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。 死锁和死锁检测 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout来设置。 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。 在InnoDB中，innodb_lock_wait_timeout的默认值是50s，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且innodb_deadlock_detect的默认值本身就是on。 怎么解决由这种热点行更新导致的性能问题呢？ 一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险， 另一个思路是控制并发度。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有10个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。 08 | 事务到底是隔离的还是不隔离的？ 在MySQL里， 有两个“视图”的概念： 一个是view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view …， 而它的查询方法与表一样。 另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现 事务在启动的时候就“拍了个快照”。 注意， 这个快照是基于整库的。 一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况： 版本未提交，不可见； 版本已提交，但是是在视图创建后提交的，不可见； 版本已提交，而且是在视图创建前提交的，可见。 update更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read），总是读取已经提交完成的最新版本。除了update语句外，select语句如果加锁，也是当前读。所以，如果把事务A的查询语句select * from t where id=1修改一下，加上lock in share mode 或for update。 而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是： 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图； 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。 09 | 普通索引和唯一索引，应该怎么选择? 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中 的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样 就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内 存，然后执行change buffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正 确性。 虽然名字叫作change buffer，实际上它是可以持久化的数据。也就是 说，change buffer在内存中有拷贝，也会被写入到磁盘上。将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。除了访问这个数据 页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭(shutdown)的过程中，也会执行merge操作。 change buffer的使用场景 因为merge的时候是真正进行数据更新的时刻，而change buffer的主要目的就是将记录的变更动 作缓存下来，所以在一个数据页做merge之前，change buffer记录的变更越多(也就是这个页面 上要更新的次数越多)，收益就越大。因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。 普通索引和唯一索引应该怎么选择。其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。 如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭change buffer。而在 其他情况下，change buffer都能提升更新性能。特别地，在使用机械硬盘时，change buffer这个机制的收效是非常显著的。所以，当你有一个 类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索 引，尽量使用普通索引，然后把change buffer 尽量开大，以确保这个“历史数据”表的数据写入 速度。 10 | MySQL为什么有时候会选错索引? 对于由于索引统计信息不准确导致的问题，你可以用analyze table解决。 set long_query_time=0; 是将慢查询日志的阈值设置为0，表示这个线程接下来的语句都会被记录入慢查询日志中; 这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越 好。而一个索引上不同的值的个数，我们称之为“基数”(cardinality)。也就是说，这个基数越 大，索引的区分度越好。我们可以使用show index方法，看到一个索引的基数。 而对于其他优化器误判的情况，你可以 在应用端用force index来强行指定索引 也可以通过修改语句来引导优化器 还可以通过增加或者删除索 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/mysql/lecture-on-mysql-2.html":{"url":"note/mysql/lecture-on-mysql-2.html","title":"mysql实战45讲2","keywords":"","body":"11 | 怎么给字符串字段加索引? 直接创建完整索引，这样可能比较占用空间; alter table SUser add index index2(email(6)); 创建的index2 索引里面，对于每个记录都是只取前6个字节。直接创建完整索引，这样可能比较占用空间; 使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀 索引时需要考虑的一个因素。回表带来的性能损失。 如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理 方法呢?这种方法，既可以占用更小的空间，也能达到相同的查询效率。 第一种方式是使用倒序存储。select field_list from t where id_card = reverse('input_id_card_string'); 第二种方式是使用hash字段。alter table t add id_card_crc int unsigned, add index(id_card_crc); 然后每次插入新记录的时候，都同时用crc32()这个函数得到校验码填到这个新字段 12 | 为什么我的MySQL会“抖”一下? 你不难想象，平时执行很快的更新操作，其实就是在写内存和日志，而MySQL偶尔“抖”一下的那个瞬间，可能就是在刷脏页(flush)。 flush 的时机 对应的就是InnoDB的redo log写满了。这时候系统会停止所有更新操作，把 checkpoint往前推进，redo log留出空间可以继续写。 “redo log写满了，要flush脏页”，这种情况是InnoDB要尽量避免的。因为出现这种情况 的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更 新数会跌为0。 对应的就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。 对应的就是MySQL认为系统“空闲”的时候。 对应的就是MySQL正常关闭的情况。这时候，MySQL会把内存的脏页都flush到磁 盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。 InnoDB刷脏页的控制策略 innodb_io_capacity这个参数了，它会告诉InnoDB你的磁盘能力。这个值我建议你设 置成磁盘的IOPS。磁盘的IOPS可以通过fio这个工具来测试 参数innodb_max_dirty_pages_pct是脏页比例上限，默认值是75%。InnoDB会根据当前的脏页比例(假设为M)，算出一个范围在0到100之间的数字 要尽量避免这种情况，你就要合理地设置innodb_io_capacity的值，并且平时要多关注脏页比 例，不要让它经常接近75%。 -- 计算脏页比例 select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'INNODB_BUFFER_POOL_PAGES_DIRTY' select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'INNODB_BUFFER_POOL_PAGES_TOTAL' select @a/@b; 一旦一个查询请求需要在执行过程中先flush掉一个脏页时，这个查询就可能要比平时慢了。而 MySQL中的一个机制，可能让你的查询会更慢:在准备刷一个脏页的时候，如果这个数据页旁 边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉;而且这个把“邻居”拖下水的逻辑还 可以继续蔓延。在InnoDB中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为1的时候会有上述 的“连坐”机制，值为0时表示不找邻居，自己刷自己的。如果使用的是SSD这类IOPS比较高的设备的话，我就建议你把innodb_flush_neighbors的值 设置成0。在MySQL 8.0中，innodb_flush_neighbors参数的默认值已经是0了。 13 | 为什么表数据删掉一半，表文件大小不变? 表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table控制的,将innodb_file_per_table设置为ON，是推荐做法, 这个参数设置为ON表示的是，每个InnoDB表数据存储在一个以 .ibd为后缀的文件中。 delete命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件 的大小是不会变的。也就是说，通过delete命令是不能回收表空间的。这些可以复用，而没有被 使用的空间，看起来就像是“空洞”。 可以使用 alter table A engine=InnoDB 命令来重建表。在MySQL 5.5版本之前，这个命 令的执行流程跟我们前面描述的差不多，区别只是这个临时表B不需要你自己创建，MySQL会自 动完成转存数据、交换表名、删除旧表的操作。花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表A的话，就会造成数据丢失。因此，在整个DDL过程中，表A中不能有更新。也就是说，这个 DDL不是Online的。 线上执行这个过程，如果想要比较安全的操作的话，我推荐你使用GitHub开源的gh-ost来做。 根据表A重建出来的数据是放在“tmp_file”里的，这个临时文件是InnoDB在内部创建出 来的。整个DDL过程都在InnoDB内部完成。对于server层来说，没有把数据挪动到临时表，是 一个“原地”操作，这就是“inplace”名称的来源。 号外 从MySQL 5.6版本开始，alter table t engine = InnoDB(也就是recreate)默认的就是上面图4 的流程了; analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程 中加了MDL读锁; optimize table t 等于recreate+analyze。 为什么 alter table t engine = InnoDB 之后表变大了？ 大家都提到了一个点，就是这个表，本身就已经没有空洞的了，比如说刚刚做过一次重建表操作。 在DDL期间，如果刚好有外部的DML在执行，这期间可能会引入一些新的空洞。 在重建表的时候，InnoDB不会把整张表占满，每个页留了1/16给后续的更新用。也就是说，其实重建表之后不是“最”紧凑的。 14 | count(*)这么慢，我该怎么办? MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数， 效率很高; 而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出 来，然后累积计数。 为什么InnoDB不跟MyISAM一样，也把数字存起来呢? 这是因为即使是在同一个时刻的多个查询，由于多版本并发控制(MVCC)的原因，InnoDB表“应该返回多少行”也是不确定的。 show table status命令显示的行 数也不能直接代替 count(*)，里面的 TABLE_ROWS 是采样估计值。 把计数放在Redis里面，不能够保证计数和MySQL表里的数据精确一致的原因，是这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。而把计数值也放在 MySQL中，就解决了一致性视图的问题。计数值和业务在事务里统一更新。 性能排序：按照效率排序的话，count(字段)，所以我建议你，尽量使用count(*)。 15 | 答疑文章(一):日志和索引相关问题 MySQL怎么知道binlog是完整的? 一个事务的binlog是有完整格式的: statement格式的binlog，最后会有COMMIT; row格式的binlog，最后会有一个XID event。 如果是现在常见的几个TB的磁盘的话，就不要太小气了，直接将redo log设置为4个文件、每个文件1GB吧。 真正把日志写到redo log文件(文件名是 ib_logfile+数字)，是在执行commit语句的时候做的。 16 | “order by”是怎么工作的? 全字段排序： sort_buffer_size，就是MySQL为排序开辟的内存(sort_buffer)的大小。如果要排序的数据量 小于sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不 利用磁盘临时文件辅助排序。sort_buffer_size，就是MySQL为排序开辟的内存(sort_buffer)的大小。如果要排序的数据量 小于sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不 利用磁盘临时文件辅助排序。 rowid排序：max_length_for_sort_data，是MySQL中专门控制用于排序的行数据的长度的一个参数。它的意 思是，如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法。新的算法放入sort_buffer的字段，只有要排序的列sort_key 和主键id，然后回表读取所有的字段。 可以优化索引，譬如设置覆盖索引，但维护覆盖索引也有代价，需要权衡。 17 | 如何正确地显示随机消息? 直接使用order by rand()，这个语句需要Using temporary 和 Using filesort，查询的执行代价往往是比较大的。所以，在设计的时候你要量避开这种写法。 从words表中，按主键顺序取出所有的word值。对于每一个word值，调用rand()函数生成一 个大于0小于1的随机小数，并把这个随机小数和word分别存入临时表的R和W字段中 内存临时表：对于内存表，回表过程只是简单地根据数据行的位 置，直接访问内存得到数据，不会导致多访问磁盘。 磁盘临时表：tmp_table_size这个配置限制了内存临时表的大小，默认值是16M。如果临时表大小超过了tmp_table_size，那么内存临时表就会转成磁盘临时表。 MySQL 5.6版本引入的一个新的排序算法， 即:优先队列排序算法。 随机排序的方法（随机不均匀） 取得这个表的主键id的最大值M和最小值N; 用随机函数生成一个最大值到最小值之间的数X=(M-N)*rand()+N; 取不小于X的第一个ID的行。 随机排序的方法2，扫表多 -- 按顺序一个一个地读出来，丢掉前Y个，然后把下一个记录作为 返回结果， -- 因此这一步需要扫描Y+1行。再加上，第一步扫描的C行，总共需要扫描C+Y+1行 select count(*) into @C from t; set @Y = floor(@C * rand()); set @sql = concat(\"select * from t limit \", @Y, \",1\"); prepare stmt from @sql; execute stmt; deallocate prepare stmt; 18 | 为什么这些SQL语句逻辑相同，性能却差异巨大? 条件字段函数操作 select count(*) from tradelog where month(t_modified)=7; 不使用 t_modified 的索引 select * from tradelog where id + 1 = 10000 也不会用 id 上的索引 隐式类型转换 select * from tradelog where tradeid=110717; tradeid的字段类型是varchar(32)，默认的会将字符串转换成数字 隐式字符编码转换：和条件字段函数类似，但这里是隐式的字符集转换。 select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id =2; 在这个执行计划里，是从tradelog表中取tradeid字段，再去trade_detail表里查询匹配字段。因此，我们把tradelog称为驱动表，把trade_detail称为被驱动表，把tradeid称为关联字段。 时间上MySQL优化器执行过程中，where 条件部分， a=b和 b=a的写法是一样的。 19 | 为什么我只查一行的语句，也执行这么慢? MetaData Lock即元数据锁，在数据库中元数据即数据字典信息包括db,table,function,procedure,trigger,event等。Metadata lock主要为了保证元数据的一致性,用于处理不同线程操作同一数据对象的同步与互斥问题。 查询长时间不返回 等MDL锁：show processlist检测 等flush flush tables t with read lock; flush tables with read lock; 等行锁：用下面的语言检测select * from t sys.innodb_lock_waits where locked_table=`'test'.'t'`\\G 查询慢 select * from t where c=50000 limit 1; select * from t where id=1; 800ms, select * from t where id=1 lock in share mode，执行时扫描行数也是1行，执行时间是0.2毫秒，原因第一条 sql，一致性读，undo log 太多，第2条sql 是当前读很快（循环执行 100万次 update t set c=c+1 where id = 1） 20 | 幻读是什么，幻读有什么问题? 幻读指的是一个事务在前后两次查 询同一个范围的时候，后一次查询看到了前一次查询没有看到的行 幻读有什么问题? 首先是语义上的。session A在T1时刻就声明了，“我要把所有d=5的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。 其次，是数据一致性的问题。 产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记 录之间的“间隙”。因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是间隙锁(Gap Lock)，gap 加在对应的索引上？。 行锁有冲突关系的是“另外一个行锁”。但是间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操 作。 间隙锁和行锁合称next-key lock，每个next-key lock是前开后闭区间。也就是说，我们的表t初始 化以后，如果用select * from t for update要把整个表所有记录锁起来，就形成了7个next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。 间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话， 就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把binlog格式设置 为row。这也是现在不少公司使用的配置组合。 事务提交时候才能看到 binlog？ var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/mysql/lecture-on-mysql-3.html":{"url":"note/mysql/lecture-on-mysql-3.html","title":"mysql实战45讲3","keywords":"","body":"21 | 为什么我只改一行的语句，锁这么多? 我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。 原则1：加锁的基本单位是next-keylock。希望你还记得，next-keylock是前开后闭区间。 原则2：查找过程中访问到的对象才会加锁。 优化1：索引上的等值查询，给唯一索引加锁的时候，next-keylock退化为行锁。 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。 lock in share mode只锁覆盖索引，但是如果是for update就不一样 了。 执行 for update时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。锁是加在索引上的;同时，它给我们的指导是，如果你要用lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不 存在的字段。 next-key lock实际上是由间隙锁加行锁实现的。如果切换到读提交隔离级别(read-committed)的话，就好理解了，过程中去掉间隙锁的部分，也就是只剩下行锁的部分。其实读提交隔离级别在外键场景下还是有间隙锁，相对比较复杂。另外，在读提交隔离级别下还有一个优化，即:语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。也就是说，读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提交隔离级别的原因。 在删除数据的时候尽量加limit。这样不仅可以控制删除 数据的条数，让操作更安全，还可以减小加锁的范围。 mysql 扫描索引时候，需要扫到哪一行，就要给哪一行加上 next-keylock，然后按上面的原则优化 22 | MySQL有哪些“饮鸩止渴”提高性能的方法? 短连接模型存在一个风险，就是一旦数据库处理得慢一些，连接数就会暴涨。 max_connections参数，用来控制一个MySQL实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。 在MySQL中，会引发性能问题的慢查询，大体有以下三种可能: 索引没有设计好 alter table 增加索引 SQL语句没写好 可以用 sql 重写： insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values(); call query_rewrite.flush_rewrite_rules(); MySQL选错了索引 force index 23 | MySQL是怎么保证数据不丢的? binlog的写入逻辑 事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。系统给binlog cache分配了一片内存，每个线程一个，参数binlog_cache_size 用于控制单个线程内binlog cache所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。事务提交的时候，执行器把binlog cache里的完整事务写入到binlog中，并清空binlog cache。 图中的write，指的就是指把日志写入到文件系统的page cache。图中的fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为fsync才占磁盘的 IOPS。 sync_binlog=0的时候，表示每次提交事务都只write，不fsync; sync_binlog=1的时候，表示每次提交事务都会执行fsync; sync_binlog=N(N>1)的时候，表示每次提交事务都write，但累积N个事务后才fsync。 在出现IO瓶颈的场景里，将sync_binlog设置成一个比较大的值，可以提升性能。在实际 的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成0，比较常见的是将其 设置为100~1000中的某个数值。将sync_binlog设置为N，对应的风险是:如果主机发生异常重启，会丢失最近N个事务的 binlog日志。redo log的写入机制 事务在执行过程中，生成的redo log是要先写到redo log buffer的 redo log可能存在的三种状态 存在redologbuffer中，物理上是在MySQL进程内存中 写到磁盘(write)，但是没有持久化(fsync)，物理上是在文件系统的pagecache里面 持久化到磁盘，对应的是harddisk 为了控制redo log的写入策略，InnoDB提供了innodb_flush_log_at_trx_commit参数，它有三种 可能取值: 设置为0的时候，表示每次事务提交时都只是把redolog留在redologbuffer中; 设置为1的时候，表示每次事务提交时都将redolog直接持久化到磁盘; 设置为2的时候，表示每次事务提交时都只是把redolog写到pagecache。 InnoDB有一个后台线程，每隔1秒，就会把redo log buffer中的日志，调用write写到文件系统的 page cache，然后调用fsync持久化到磁盘。事务执行中间过程的redo log也是直接写在redo log buffer中的，这些redo log也会被后台 线程一起持久化到磁盘。也就是说，一个没有提交的事务的redo log，也是可能已经持久化到磁 盘的。 除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log写入到磁盘中。 一种是，redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候， 后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是write，而 没有调用fsync，也就是只留在了文件系统的page cache。 另一种是，并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁 盘。假设一个事务A执行到一半，已经写了一些redo log到buffer中，这时候有另外一个线程 的事务B提交，如果innodb_flush_log_at_trx_commit设置的是1，那么按照这个参数的逻 辑，事务B要把redo log buffer里的日志全部持久化到磁盘。这时候，就会带上事务A在redo log buffer里的日志一起持久化到磁盘。 如果把innodb_flush_log_at_trx_commit设置成1，那么redo log在prepare阶段就要持久化一次， 因为有一个崩溃恢复逻辑是要依赖于prepare 的redo log，再加上binlog来恢复的。 通常我们说MySQL的“双1”配置，指的就是sync_binlog和innodb_flush_log_at_trx_commit都设 置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是redo log(prepare 阶 段)，一次是binlog。 组提交(group commit)机制 redo log 和 binlog 都有组提交机制 日志逻辑序列号(log sequence number，LSN)的概念。LSN是单调 递增的，用来对应redo log的一个个写入点。每次写入长度为length的redo log， LSN的值就会加 上length。 一次组提交里面，组员越多，节约磁盘IOPS的效果越好。第一个事务写完redo log buffer以后，接下来这个fsync越晚调用，组员可能 越多，节约IOPS的效果就越好。 如果你想提升binlog组提交的效果，可以通过设置 binlog_group_commit_sync_delay和 binlog_group_commit_sync_no_delay_count来实现。 binlog_group_commit_sync_delay参数，表示延迟多少微秒后才调用fsync; binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调用fsync。 这两个条件是或的关系，也就是说只要有一个满足条件就会调用fsync。 如果你的MySQL现在出现了性能瓶颈，而且瓶颈在IO 上，可以通过哪些方法来提升性能呢?针对这个问题，可以考虑以下三种方法: 设置 binlog_group_commit_sync_delay（延迟多少微秒后才调用fsync）和 binlog_group_commit_sync_no_delay_count参数（等待这么长时间，表示累积多少次以后才调用fsync），减少binlog的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。 将sync_binlog设置为大于1的值(比较常见是100~1000)。这样做的风险是，主机掉电时 会丢binlog日志。 将innodb_flush_log_at_trx_commit设置为2。这样做的风险是，主机掉电的时候会丢数据。 不建议你把innodb_flush_log_at_trx_commit 设置成0。因为把这个参数设置成0，表示redo log只保存在内存中，这样的话MySQL本身异常重启也会丢数据，风险太大。而redo log写到文 件系统的page cache的速度也是很快的，所以将这个参数设置成2跟设置成0其实性能差不多， 但这样做MySQL异常重启时就不会丢数据了，相比之下风险会更小。 25 | MySQL是怎么保证高可用的? 主备延迟的来源 首先，有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。 第二种常见的可能了，即备库的压力大 第三种可能了，即大事务：因为主库上必须等事务执行完成才会写入binlog，再传给备库，另一种典型的大事务场景，就是大表DDL。 在实际的应用中，我更建议使用可靠性优先的策略。毕竟保证数据准确，应该是数据库服务的底 线。在这个基础上，通过减少主备延迟，提升系统的可用性。 一般现在的数据库运维系统都有备库延迟监控，其实就是在备库上执行 show slave status，采集seconds_behind_master的值。 26 | 备库为什么会延迟好几个小时? work线程的个数，就是由参数 slave_parallel_workers决定的。根据我的经验，把这个值设置为8~16之间最好(32核物理机的 情况)，毕竟备库还有可能要提供读查询，不能把CPU都吃光了。 多线程复制呢?这是因为单线程复制的能力全面低于多线程复制，对于更新压力较大 的主库，备库是可能一直追不上主库的。从现象上看就是，备库上seconds_behind_master的值 越来越大。 官方MySQL5.6版本，支持了并行复制，只是支持的粒度是按库并行。理解了上面介绍的按表分发策略和按行分发策略，你就理解了，用于决定分发策略的hash表里，key就是数据库名。 MariaDB是这么做的: 在一组里面一起提交的事务，有一个相同的commit_id，下一组就是commit_id+1; commit_id直接写到binlog里面; 传到备库应用的时候，相同commit_id的事务分发到多个worker执行; 这一组全部执行完成后，coordinator再去取下一批。 MySQL 5.7的并行复制策略 配置为DATABASE，表示使用MySQL5.6版本的按库并行策略; 配置为 LOGICAL_CLOCK，表示的就是类似MariaDB的策略。不过，MySQL 5.7这个策 略，针对并行度做了优化。这个优化的思路也很有趣儿。 MySQL 5.7.22的并行复制策略 基于WRITESET的并行复制。 相应地，新增了一个参数binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。 COMMIT_ORDER，表示的就是前面介绍的，根据同时进入prepare和commit来判断是否可 以并行的策略。 WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的hash值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的writeset没有交集，就可以并 行。 WRITESET_SESSION，是在WRITESET的基础上多了一个约束，即在主库上同一个线程 先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/mysql/lecture-on-mysql-4.html":{"url":"note/mysql/lecture-on-mysql-4.html","title":"mysql实战45讲4","keywords":"","body":"27 | 主库出问题了，从库怎么办? GTID的全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。 实例B上执行start slave命令，取binlog的逻辑是这样的： 实例B指定主库A’，基于主备协议建立连接。 实例B把set_b发给主库A’。 实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的集合，判断A’本地是否包含了这个差集需要的所有binlog事务。 如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误； 如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B； 之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。 28 | 读写分离有哪些坑? 读写分离的方案 客户端直连方案 带proxy的架构，对客户端比较友好 解决主从延迟方案 强制走主库方案；（其实这个方案是用得最多的。） sleep方案； 判断主备无延迟方案； 配合semi-sync方案； 等主库位点方案 在主库执行完插入之后，执行show master status，然后根据 file pos 去从库执行 select master_pos_wait(file, pos[, timeout])； 如果返回值 >=0，说明数据同步了。 等GTID方案。 你只需要将参数session_track_gtids设置为OWN_GTID，然后通过API接口mysql_session_track_get_first从返回包解析出GTID的值即可。 select wait_for_executed_gtid_set(gtid_set, 1)； semi-sync做了这样的设计: 事务提交的时候，主库把binlog发给从库； 从库收到binlog以后，发回给主库一个ack，表示收到了； 主库收到这个ack以后，才能给客户端返回“事务完成”的确认。 但是，semi-sync+位点判断的方案，只对一主一备的场景是成立的。在一主多从场景中，主库只 要等到一个从库的ack，就开始给客户端返回确认。 有的方案看上去是做了妥协，有的方案看上去不那么靠谱儿，但都是有实际应用场景的，你需要根据业务需求选择。 29 | 如何判断一个数据库是不是出问题了? 查询判断：select 1； 不能检测因为并发查询限制带来的问题 MHA默认用了这个 我们设置innodb_thread_concurrency参数的目的是，控制InnoDB的并发线程上限。也就是说，一旦并发线程数达到这个值，InnoDB在接收到新请求的时候，就会进入等待状态，直到有线程 退出。通常情况下，我们建议把innodb_thread_concurrency设置为64~128之间的值。这时，你 一定会有疑问，并发线程上限数设置为128够干啥，线上的并发连接数动不动就上千了。 并发连接和并发查询，并不是同一个概念。你在show processlist的结果里，看到的几千个连 接，指的就是并发连接。而“当前正在执行”的语句，才是我们所说的并发查询。 查询判断：select * from mysql.health_check；，不能确认是否能更新，如磁盘慢，binlog不能写入等 更新判断：update mysql.health_check set t_modified=now()；，主从冲突，可能需要多行 insert into mysql.health_check(id, t_modified) values (@@server_id, now()) on duplicate key update t_modified=now()； 更新语句，如果失败或者超时，就可以发起主备切换了，为什么还会有判定 慢的问题呢? 一个日志盘的IO利用率已经是100%的场景，但我们的update 成功了，得出系统正常的结论。 mysql 内部统计，使用 performance_schema 如果打开所有的performance_schema项，性能大概会下降10%左右 30 | 答疑文章(二):用动态的观点看加锁 31 | 误删数据后除了跑路， 还能怎么办？ 我们提到如果是使用delete语句误删了数据行， 可以用Flashback工具通过闪回把数据恢复回来。Flashback恢复数据的原理， 是修改binlog的内容， 拿回原库重放。 而能够使用这个方案的前提是，需要确保binlog_format=row和 binlog_row_image=FULL。 恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。 delete全表是很慢的， 需要生成回滚日志、 写redo、 写binlog。 所以，从性能角度考虑，你应该优先考虑使用truncate table或者drop table命令。 延迟复制备库： 延迟复制的备库是一种特殊的备库， 通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有N秒的延迟。 预防误删库/表的方法 只给业务开发同学DML权限，而不给truncate/drop权限。而如果业务开发人员有DDL需求的话，也可以通过开发管理系统得到支持。 DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。 在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。 改表名的时候，要求给表名加固定的后缀（比如加_to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且管理系删除表的时候，只能删除固定后缀的表。 rm 删除：一个有高可用机制的MySQL集群来说， 最不怕的就是rm删除数据了。只要不是恶意地把整个集群删除，而只是删掉了其中某一个节点的数据的话，HA系统就会开始工作，选出一个新的主库， 从而保证整个集群的正常工作。 32 | 为什么还有kill不掉的语句？ 在MySQL中有两个kill命令：一个是kill query+线程id，表示终止这个线程中正在执行的语句；一个是kill connection +线程id，这里connection可缺省，表示断开这个线程的连接，当然如果这个线程有语句正在执行， 也是要先停止正在执行的语句的。 当用户执行kill query thread_id_B时， MySQL里处理kill命令的线程做了两件事： 把session B的运行状态改成THD::KILL_QUERY(将变量killed赋值为THD::KILL_QUERY)； 给session B的执行线程发一个信号。 当 session E执行kill connection 命令时， 是这么做的： 把12号线程状态设置为KILL_CONNECTION； 关掉12号线程的网络连接。 因为有这个操作， 所以你会看到， 这时候session C收到了断开连接的提示 如果一个线程的状态是KILL_CONNECTION， 就把Command列显示成Killed 只有等到满足进入InnoDB的条件后， session C的查询语句继续执行， 然后才有可能判断到线程状态已经变成了KILL_QUERY或者KILL_CONNECTION， 再进入终止逻辑阶段。 MySQL客户端发送请求后， 接收服务端返回结果的方式有两种： 一种是本地缓存， 也就是在本地开一片内存， 先把结果存起来。 如果你用API开发， 对应的就是mysql_store_result 方法。 另一种是不缓存， 读一个处理一个。 如果你用API开发， 对应的就是mysql_use_result方法。 除了加-A以外， 加–quick(或者简写为-q)参数， 也可以跳过这个阶段。 但是， 这个–quick是一个更容易引起误会的参数， 也是关于客户端常见的一个误解。为什么要给这个参数取名叫作quick呢？ 这是因为使用这个参数可以达到以下三点效果： 就是前面提到的， 跳过表名自动补全功能。 mysql_store_result需要申请本地内存来缓存查询结果， 如果查询结果太大， 会耗费较多的本地内存， 可能会影响客户端本地机器的性能； 是不会把执行命令记录到本地的命令历史文件 33 | 我查这么多数据， 会不会把数据库内存打爆？ 对于正常的线上业务来说， 如果一个查询的返回结果不会很多的话， 我都建议你使用mysql_store_result这个接口， 直接把查询结果保存到本地内存。 仅当一个线程处于“等待客户端接收结果”的状态， 才会显示\"Sending to client\"； 而如果显示成“Sending data”， 它的意思只是“正在执行” 可以在 show engine innodb status 结果中， 查看一个系统当前的BP命中率。 一般情况下， 一个稳定服务的线上系统， 要保证响应时间符合要求的话， 内存命中率要在99%以上。 InnoDB Buffer Pool的大小是由参数 innodb_buffer_pool_size确定的， 一般建议设置成可用物理内存的60%~80% InnoDB内存管理用的是最近最少使用 (Least RecentlyUsed, LRU)算法， 这个算法的核心就是淘汰最久未使用的数据。 在InnoDB实现上， 按照5:3的比例把整个LRU链表分成了young区域和old区域。 图中LRU_old指向的就是old区域的第一个位置， 是整个链表的5/8处。 也就是说， 靠近链表头部的5/8是young区域， 靠近链表尾部的3/8是old区域。 要访问数据页P3， 由于P3在young区域， 因此和优化前的LRU算法一样， 将其移到链表头部， 变成状态2。 之后要访问一个新的不存在于当前链表的数据页， 这时候依然是淘汰掉数据页Pm， 但是新插入的数据页Px， 是放在LRU_old处。 处于old区域的数据页， 每次被访问的时候都要做下面这个判断： 若这个数据页在LRU链表中存在的时间超过了1秒， 就把它移动到链表头部； 如果这个数据页在LRU链表中存在的时间短于1秒， 位置保持不变。 1秒这个时间， 是由参数innodb_old_blocks_time控制的。 其默认值是1000， 单位毫秒。 34 | 到底可不可以使用join? 使用join语句，性能比强行拆成多个单表执行SQL语句的性能要好； 如果使用join语句的话，需要让小表做驱动表。（可以使用被驱动表的索引） 能不能使用join语句? 如果可以使用IndexNested-LoopJoin算法，也就是说可以用上被驱动表上的索引，其实是没问题的； 如果使用BlockNested-LoopJoin算法，扫描行数就会过多。尤其是在大表上的join操作，这 样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种join尽量不要用。所以你在判断要不要使用join语句时，就是看explain结果里面，Extra字段里面有没有出现“Block Nested Loop”字样。 如果要使用join，应该选择大表做驱动表还是选择小表做驱动表? 如果是IndexNested-LoopJoin算法，应该选择小表做驱动表； 如果是BlockNested-LoopJoin算法：在join_buffer_size足够大的时候，是一样的； 在join_buffer_size不够大的时候(这种情况更常见)，应该选择小表做驱动表。 在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与join的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。 35 | join语句怎么优化? BKA优化是MySQL已经内置支持的，建议你默认使用； BNL算法效率低，建议你都尽量转成BKA算法。优化的方向就是给被驱动表的关联字段加上 索引； 基于临时表的改进方案，对于能够提前过滤出小数据的join语句来说，效果还是很好的； MySQL目前的版本还不支持hashjoin，但你可以配合应用端自己模拟出来，理论上效果要好 于临时表的方案。 36 | 为什么临时表可以重名? 临时表在使用上有以下几个特点: 建表语法是create temporary table...。 一个临时表只能被创建它的session访问，对其他线程不可见。由于临时表只能被创建它的session访问，所以在这个session结束的时候，会自动删除临时表。 临时表可以与普通表同名。 sessionA内有同名的临时表和普通表的时候，show create语句，以及增删改查语句访问的是临时表。 show tables命令不显示临时表。 如果当前的binlog_format=row，那么跟临时表有关的语句，就不会记录到binlog 里。也就是说，只在binlog_format=statment/mixed 的时候，binlog中才会记录临时表的操作。 为什么不能用rename修改临时表的改名。在实现上，执行rename table语句的时候，要求按照“库名/表名.frm”的规则去磁盘找文件，但是临时表在磁盘上的frm文件是放在tmpdir目录下的，并且文件名的规则是“#sql{进程id}{线程id} 序列号.frm”，因此会报“找不到文件名”的错误。 37 | 什么时候会使用内部临时表? 基于上面的union、union all和group by语句的执行过程的分析，我们来回答文章开头的问题: MySQL什么时候会使用内部临时表? 如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果； join_buffer是无序数组，sort_buffer是有序数组，临时表是二维表结构； 如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union 需要用到唯一索引约束， group by还需要用到另外一个字段来存累积计数。 建议 如果对group by语句的结果没有排序要求，要在语句后面加order by null； 尽量让group by过程用上表的索引，确认方法是explain结果里没有Usingtemporary和Using filesort； 如果group by需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大tmp_table_size参数，来避免用到磁盘临时表； 如果数据量实在太大，使用SQL_BIG_RESULT这个提示，来告诉优化器直接使用排序算法得到group by的结果。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/mysql/lecture-on-mysql-5.html":{"url":"note/mysql/lecture-on-mysql-5.html","title":"mysql实战45讲5","keywords":"","body":"38 | 都说InnoDB好，那还要不要使用Memory引擎? InnoDB和Memory引擎的数据组织方式的不同 InnoDB引擎把数据放在主键索引上，其他索引上保存的是主键id，称之为索引组织表(Index Organizied Table)。 Memory引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，称之为堆组织表(Heap Organizied Table)。 为什么不建议你在生产环境上使用内存表 锁粒度问题； 内存表不支持行锁，只支持表锁。因此，一张表只要有更新，就会堵住其他所有在这个表上的读写操作。 数据持久化问题。 由于重启会丢数据，如果一个备库重启，临时表会导致主备同步线程停止；如果主库跟这个备库是双M架构，还可能导致主库的内存表数据被删掉。 39 | 自增主键为什么不是连续的? 不同的引擎对于自增值的保存策略不同。 MyISAM引擎的自增值保存在数据文件中。 InnoDB引擎的自增值，其实是保存在了内存里，并且到了MySQL 8.0版本后，才有了“自增值 持久化”的能力，也就是才实现了“如果发生重启，表的自增值可以恢复为MySQL重启前的值”。 在MySQL 5.7及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一 次打开表的时候，都会去找自增值的最大值max(id)，然后将max(id)+1作为这个表当前的自增值。 唯一键冲突是导致自增主键id不连续。 事务回滚也会产生主键id不连续。如果硬要连续，会导致冲突、性能问题。 主键分配策略导致。insert...select，实际上往表t2中插入了4行数据。但是，这四行数据是分三次申请的自增id，第一 次申请到了id=1，第二次被分配了id=2和id=3， 第三次被分配到id=4到id=7。 MySQL 5.1.22版本开始引入的参数innodb_autoinc_lock_mode，控制了自增值申请时的锁范围。从并发性能的角度考虑，建议将其设置为2，同时将binlog_format设置为row。 40 | insert语句的锁为什么这么多? insert ...select 是很常见的在两个表之间拷贝数据的方法。在可重复读隔离级别下，这个语句会给select的表里扫描到的记录和间隙加读锁。 而如果insert和select的对象是同一个表，则有可能会造成循环写入。这种情况下，需要引入用户临时表来做优化。 insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的next-key lock(S锁)。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。 41 | 怎么最快地复制一张表? mysqldump –single-transaction的作用是，在导出数据的时候不需要对表加表锁，而是使用START TRANSACTION WITH CONSISTENT SNAPSHOT的方法； 物理拷贝表的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况， 用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：必须是全表拷贝，不能只拷贝部分数据； 需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用； 由于是通过拷贝物理文件实现的，源表和目标表都是使用InnoDB引擎时才能使用。 用mysqldump生成包含INSERT语句文件的方法，可以在where参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用join这种比较复杂的where条件写法。 用select...intooutfile的方法是最灵活的，支持所有的SQL写法。但这个方法的缺点之一是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。 后两种方式都是逻辑备份方式，是可以跨引擎使用的。 42 | grant之后要跟着flush privileges吗? create user 'ua'@'%' identified by 'pa'； grant all privileges on *.* to 'ua'@'%' with grant option； revoke all privileges on *.* from 'ua'@'%'； grant语句会同时修改数据表和内存，判断权限的时候使用的是内存数据。因此，规范地使用 grant和revoke语句，是不需要随后加上flush privileges语句的。 flush privileges语句本身会用数据表的数据重建一份内存权限数据，所以在权限数据可能存在不 一致的情况下再使用。而这种不一致往往是由于直接用DML语句操作系统权限表导致的，所以尽量不要使用这类语句。 43 | 要不要使用分区表? 44 | 答疑文章(三):说一说这些好问题 在MySQL里，NULL跟任何值执行等值 判断和不等值判断的结果，都是NULL。这里包括， select NULL = NULL 的结果，也是返回 NULL。 不需要执行聚合函数时，distinct 和group by这两条语句的语义和执行流程是相同的，因此执行性能也相同。 45 | 自增id用完怎么办? Xid和InnoDB的trx_id是两个容易混淆的概念。 Xid是由server层维护的。InnoDB内部使用Xid，就是为了能够在InnoDB事务和server之间做关联。但InnoDB自己的trx_id是另外维护的。 只读事务不分配trx_id，有什么好处呢? 可以减小事务视图里面活跃事务数组的大小。因为当前正在运行的只读事务，是不影响数据的可见性判断的。所以，在创建事务的一致性视图时，InnoDB就只需要 拷贝读写事务的trx_id。 可以减少trx_id的申请次数。在InnoDB里，即使你只是执行一个普通的select 语句，在执行过程中，也是要对应一个只读事务的。所以只读事务优化后，普通的查询语句不需要申请trx_id，就大大减少了并发事务申请trx_id的锁冲突。 每种自增id有各自的应用场景，在达到上限后的表现也不同: 表的自增id达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。 row_id达到上限后，则会归0再重新递增，如果出现相同的row_id，后写的数据会覆盖之前 的数据。 Xid只需要不在同一个binlog文件中出现重复值即可。虽然理论上会出现重复值，但是概率极 小，可以忽略不计。 InnoDB的max_trx_id递增值每次MySQL重启都会被保存起来，所以我们文章中提到的脏读 的例子就是一个必现的bug，好在留给我们的时间还很充裕。 thread_id是我们使用中最常见的，而且也是处理得最好的一个自增id逻辑了。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/mysql/locks-in-mysql.html":{"url":"note/mysql/locks-in-mysql.html","title":"mysql锁分析","keywords":"","body":"CREATE TABLE `t` ( `id` int(11) NOT NULL, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `c` (`c`) ) ENGINE=InnoDB; insert into t values(0,0,0), (5,5,5), (10,10,10), (15,15,15), (20,20,20), (25,25,25); select * from t where c >= 15 and c 由于是order by c desc，第一个要定位的是索引c上“最右边的”c=20的行，所以会加上间隙锁 (20,25) 和next-key lock (15,20]。 在索引c上向左遍历，要扫描到c=10才停下来，所以next-keylock会加到(5,10]。 在扫描过程中，c=20、c=15、c=10这三行都存在值，由于是select *，所以会在主键id上加三个行锁。 最后的锁： 索引c上 (5, 25)，主键索引上id=15、20两个行锁。 select * from t where c >= 15 and c (10,15] (15,20] (20,25] -> (20,25) [15],[20] 主键锁 update t set d = d+1 where id = 7; (5,10] -> (5,10) select id from t where c = 5 lock in share mode; (0,5] (5,10] -> (5,10) 只锁了c上的索引 lock in share mode只锁覆盖索引，但是如果是for update就不一样 了。 执行 for update时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的 select * from t where id=10 for update; select * from t where id>=10 and id (5,10] -> [10] 因为 id 为唯一索引 (10,15] 首次session A定位查找id=10的行的时候，是当做等值查询来判断的，而向右扫描到id=15的时候，用的是范围查询判断。 select * from t where c >= 10 and c (5,10] (10,15] select * from t where id > 10 and id (10, 15] (15, 20] -> (15,20] 因为id是唯一索引，所以应该没有这个锁，但实际上 mysql 有这个锁，可能是个bug insert into t values(30,10,30); delete from t where c = 10; (c=5,id=5)到(c=10,id=10)这个next-key lock 退化成(c=10,id=10) 到 (c=15,id=15)的间隙锁 delete from t where c = 10 limit 2; 索引c上的加锁范围就变成了从(c=5,id=5)到(c=10,id=30)这个前开后闭区间 select id from t where c = 10 lock in share mode session B的“加next-key lock(5,10] ”操作，实际上分成了两步，先是加(5,10)的间隙锁，加锁成功;然后加c=10的行锁，这时候才被锁住的。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/cpp/":{"url":"note/cpp/","title":"cpp","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/cpp/optimizing-cpp.html":{"url":"note/cpp/optimizing-cpp.html","title":"optimizing cpp笔记","keywords":"","body":"optimizing cpp 笔记 作者：Agner Fog，原书见这里 CPU密集型工作，64位系统比32位系统可提升5-10%的性能 64位系统使得地址无关代码更有效 Gnu编译器通常使用内置代码代替，性能不好，可使用选项-fno-builtin 一般dll占用更多的内存 优化之前，先找到瓶颈 一般，level-1 cache 8~64KB；level-2 256KB float 加法可能需要3~5个clock double precision和单精度浮点数加法耗时一样 模板比多态系能更高 如果没有大的数组，可以肯定所有的变量都会在level-1 cache中，存取速度非常快 静态变量分为3种：1）常量，2）初始化变量；3）未初始化变量。有时可以将静态变量copy到stack中，放到level-1 cache中，加快存取 64位系统一般有14个整数寄存器，16个浮点数寄存器 volatile 标记一个变量可能被另一个线程更改，但不意味着是原子变量 thread local变量性能不好，应该尽量不使用 class里的变量根据声明顺序存储 用常量做除法，性能更好 不要signed和unsigned混用；signed整数转换成float比unsigned整数快，signed转换成整数需要4-16个clock x = array[i++]比x = array[++i]更高效，后者读取x必须在i计算完后，而前者可以并行 使用智能指针为了避免内存泄露 浮点数转为整数需要50~100个clock 和0比较比和其他整数比较更高效 返回复杂类型时，是通过一个隐藏的指针返回的 如果一个类有至少一个虚函数，会有指向虚表的指针 线程安全的函数不能使用static变量 异常处理本意使用来优雅处理很少出现的错误，如果使用了RAII程序是异常安全的，析构函数抛出异常可能引起系统崩溃 如果函数调用了exit()，abort()，_endthread()等，不保证所有对象的析构函数会被调用 不使用异常处理的代码更高效 建议关闭RTTI机制 除非程序使用了异常处理，否则不要使用stack frame 链接的顺序通常和makefile里出现的顺序一致 把变量存在static内存，可能会引起cache失效问题，当数组为2的指数倍大小时，注意cache失效的问题 中断异步处理中，不要直接去处理业务逻辑，而是标记收到事件了，在更低优先级的事件循环函数中具体处理 Why is template metaprogramming so complicated? Because the C++ template feature was never designed for this purpose. It just happened to be possible. const int min = 100, max = 110; int i; if (i >= min && i struct Sfloat { unsigned int fraction:23; // fractional part unsigned int exponent:8; // exponent + 0x7F unsigned int sign:1; // sign bit }; struct Sdouble { unsigned int fraction:52; // fractional part unsigned int exponent:11; // exponent + 0x3FF unsigned int sign:1; // sign bit }; struct Slongdouble { unsigned int fraction:63; // fractional part unsigned int one:1; // always 1 if nonzero and normal unsigned int exponent:15; // exponent + 0x3FFF unsigned int sign:1; // sign bit }; var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/cpp/datetime.html":{"url":"note/cpp/datetime.html","title":"datetime函数","keywords":"","body":"datetime函数 c 标准库 // 时间字符串转换成UNIX时间戳 struct tm tm; if (strptime(\"2016-01-21 17:38:12\", \"%F %T\", &tm) != NULL) { time_t ts = mktime(&tm); } // UNIX时间戳转换成时间字符串 // NOTE: localtime is not thread safe, use localtime_r instead char buff[32]; strftime(buff, sizeof(buff), \"%F %T\", localtime(&ts)); boost::posix_time #include using namespace boost::posix_time; // 构造 ptime t(time_from_string(\"2002-01-20 23:59:59.000\")); ptime t(from_iso_string(\"20020131T235959\")); ptime from_time_t(time_t t); // 字符串转换 std::string to_simple_string(ptime); // 2002-Jan-01 10:00:01.123456789 std::string to_iso_string(ptime); // 20020131T100001,123456789 std::string to_iso_extended_string(ptime); // 2002-01-31T10:00:01,123456789 boost::gregorian #include using namespace boost::gregorian; // 构造 date d(from_simple_string(\"2016-12-13\")); date d(from_string(\"2002/1/25\")); date d(from_undelimited_string(\"20020125\")); // 字符串转换 std::string to_simple_string(date d); // \"2002-Jan-01\" std::string to_iso_string(date d); // \"20020131\" std::string to_iso_extended_string(date d); // \"2002-01-31\" var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/cpp/thread.html":{"url":"note/cpp/thread.html","title":"std::thread","keywords":"","body":"C++0x std::thread 一个简单的线程安全的队列实现 #include #include #include class ThreadSafeQueue { public: ThreadSafeQueue() {} void push(int data) { // 操作 data_queue_ 前需要加锁，执行完 notify_one 后需要释放锁， // 因为 data_cond_.wait 函数返回之前需要重新加锁 std::lock_guard lk(mut_); data_queue_.push(data); data_cond_.notify_one(); } void wait_and_pop(int* value) { // 进入 wait 后，首先解锁，将本线程挂到条件变量等待列表上， // 解锁之后，push 才有可能获取到锁，向 queue 里写入数据 // 在 wait 返回之前需要重新加锁，注意如果有多个线程等待 // 条件变量，也需要一个一个地获得锁，这样一次只会有一个 // 线程能取数据 // 注意：wait 函数有可能返回多次，有些返回并不是 push 中的 // data_cond_.notify_one 唤醒的 std::unique_lock lk(mut_); data_cond_.wait(lk, [this]{return !data_queue_.empty();}); *value = std::move(data_queue_.front()); data_queue_.pop(); } bool empty() const { std::lock_guard lk(mut_); return data_queue_.empty(); } private: mutable std::mutex mut_; std::queue data_queue_; std::condition_variable data_cond_; }; var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/cpp/gtest-template.html":{"url":"note/cpp/gtest-template.html","title":"gtest示例","keywords":"","body":"GTest示例 class FooTest : public ::testing::Test { protected: // Per-test-case set-up. // Called before the first test in this test case. // Can be omitted if not needed. static void SetUpTestCase() { shared_resource_ = new ...; } // Per-test-case tear-down. // Called after the last test in this test case. // Can be omitted if not needed. static void TearDownTestCase() { delete shared_resource_; shared_resource_ = NULL; } // You can define per-test set-up and tear-down logic as usual. virtual void SetUp() { ... } virtual void TearDown() { ... } // Some expensive resource shared by all tests. static T* shared_resource_; }; T* FooTest::shared_resource_ = NULL; TEST_F(FooTest, Test1) { // ... you can refer to shared_resource here ... } TEST_F(FooTest, Test2) { // ... you can refer to shared_resource here ... } class Environment { public: virtual ~Environment() {} // Override this to define how to set up the environment. virtual void SetUp() {} // Override this to define how to tear down the environment. virtual void TearDown() {} }; var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/cpp/c++-interview.html":{"url":"note/cpp/c++-interview.html","title":"c++面试题","keywords":"","body":"c++ 面试题 面试官向谁负责。通常应聘者会面试几轮，收集多个面试官的 feedback，交给 hire manager 或 hire committee 决定是否录用。也就是说面试官无权单独决定是否录用这个候选人。在此前提下，面试官的任务是收集足够多的有效信息（包括面试题、答案、答题过程等等），供 hire manager 或 hire committee 决断。因此，面试题要有说服力。应聘者答上了这道面试题，能说明什么，如果没答上来，又能说明什么。不符合这一要求的不是好题目。 难度与区分度。难度定位在“一个合格的 C++ 程序员应该掌握的基本知识”，是招能用 C++ 干活的人，不是招标准控或语言律师。所有人都能做出来和所有人都做不出来的题目，没有区分度，不是好题目。所有应聘者都能通过或者所有应聘者都被刷掉的面试官也不是好面试官。 公平性与可重复性。技术面试题应该有比较公认的正确答案，怎么样算答得好，不仅由面试官一个人做出判断，hire manager 和 hire committee 也能重复这一判断。一套好题目，能起到筛选多个面试者的作用，比如“眼前这个应聘者的回答与过去六个月里的应聘者相比，处于前 10 % 的位置”，这就是不错的客观标杆。 相比起大方向的理解，细节问题例如虚表是如何实现的，或者某个关键字怎么用，某个设计模式怎么实现这类问题实在意义不大。程序员不是编译器，不应该考程序员模拟编译器的水平。程序员是人，软件工程终极的目标是服务于人，应该考程序员作为人机交互中人的一端表现出的水平，即我们为什么要用C++，以及为什么C++是这样用的。 听说过c++ 说一下你对 static 的理解:static 有什么作用，static变量什么时候初始化，模板里的 static 变量是怎么实例化的？ static 变量，静态局部变量保存在全局数据区(静态区)，而不是保存在栈中，每次的值保持到下一次调用，直到下次赋新值。 static 成员变量，定义必须在类定义体的外部，在类的内部只是声明，声明必须加static，定义不需要。 static 成员函数，同样的和成员变量一样，跟类相关的，跟具体的类的对象无关，可以通过类名来调用。static成员函数里面不能访问非静态成员变量，也不能调用非静态成员函数。 在一个文件里使用 static 修饰的变量或函数，只能在本文件内被访问，可以使用匿名空间来替代。 类中的 static 变量、方法可以被继承，但如果子类重新声明了该static变量、方法，则使用新的变量、方法。 在模板里的 static 变量，其定义必须放在 .h 文件中，编译时不会导致变量重复定义的错误。以GCC为例，在编译时，实例化时会在符号表里添加一个“弱符号weak symbols”，这个弱符号链接时不会导致重复定义，linker会选择一个实例，丢弃其他的（假定他们都是一样的）。 https://stackoverflow.com/questions/1553854/template-static-variable 关键字 const 是什么含意？ const 名叫常量限定符，用来限定特定变量，以通知编译器该变量是不可修改的。习惯性的使用 const，可以避免在函数中对某些不应修改的变量造成可能的改动。 关键字const的作用是为给读你代码的人传达非常有用的信息，实际上，声明一个参数为常量是为了告诉了用户这个参数的应用目的。 通过给优化器一些附加的信息，使用关键字const也许能产生更紧凑的代码。 合理地使用关键字const可以使编译器很自然地保护那些不希望被改变的参数，防止其被无意的代码修改。简而言之，这样可以减少bug的出现。 关键字 volatile 有什么作用，可以和 const 一起使用么，volatile变量意味着线程安全（atomic）么？ 如果一个基本变量被volatile修饰，编译器将不会把它保存到寄存器中，而是每一次都去访问内存中实际保存该变量的位置上。这一点就避免了没有volatile修饰的变量在多线程的读写中所产生的由于编译器优化所导致的灾难性问题。所以多线程中必须要共享的基本变量一定要加上volatile修饰符。 explicit 关键字的作用？ 用于构造函数，按默认规定，只用传一个参数的构造函数也定义了一个隐式转换。但在大部分情况中，隐式转换却容易导致错误（不是语法错误，编译器不会报错）。隐式转换总是在我们没有察觉的情况下悄悄发生，除非有心所为，隐式转换常常是我们所不希望发生的。通过将构造函数声明为explicit（显式）的方式可以抑制隐式转换 static_cast, dynamic_cast, const_cast, reinterpret_cast 分别用在哪种场合？ static_cast 用于类层次结构中，基类和子类之间指针和引用的转换；用于基本数据之间的类型转换；把void转换为目标类型的指针，是及其不安全的。 dynamic_cast主要用于类层次间的上行转换和下行转换，还可以用于类之间的交叉转换。 const_cast 该运算符用来修改类型的const或volatile属性。除了const 或volatile修饰之外， type_id和expression的类型是一样的。 reinpreter_cast 它可以把一个指针转换成一个整数，也可以把一个整数转换成一个指针（先把一个指针转换成一个整数，在把该整数转换成原类型的指针，还可以得到原先的指针值）。可能导致不可移植。 在C++ 程序中调用被 C 编译器编译后的函数，为什么要加 extern “C”声明？ 函数和变量被C++编译后在符号库中的名字与C语言的不同，被extern “C”修饰的变量和函数是按照C语言方式编译和连接的。由于编译后的名字不同，C++程序不能直接调用C 函数。C++提供了一个C 连接交换指定符号extern“C”来解决这个问题。 main 函数执行以前，还会执行什么代码？main函数执行完，还能有其他函数执行么？ 全局对象的构造函数会在main 函数之前执行。atexit注册的函数会在main函数之后执行。 指针引用的区别 引用就是某个目标变量的“别名”(alias)，对应用的操作与对变量直接操作效果完全相同。申明一个引用的时候，切记要对其进行初始化。引用声明完毕后，相当于目标变量名有两个名称，即该目标原名称和引用名，不能再把该引用名作为其他变量名的别名。声明一个引用，不是新定义了一个变量，它只表示该引用名是目标变量名的一个别名，它本身不是一种数据类型，因此引用本身不占存储单元，系统也不给引用分配存储单元。不能建立数组的引用。 重载（overload)和重写(override，有的书也叫做“覆盖”）的区别？ 重载：是指允许存在多个同名函数，而这些函数的参数表不同（或许参数个数不同，或许参数类型不同，或许两者都不同）。重写：是指子类重新定义父类虚函数的方法。 重载：编译器根据函数不同的参数表，对同名函数的名称做修饰，然后这些同名函数就成了不同的函数（至少对于编译器来说是这样的）。如，有两个同名函数：function func(p:integer):integer;和function func(p:string):integer;。那么编译器做过修饰后的函数名称可能是这样的：int_func、str_func。对于这两个函数的调用，在编译器间就已经确定了，是静态的。也就是说，它们的地址在编译期就绑定了（早绑定），因此，重载和多态无关。 重写：和多态真正相关。当子类重新定义了父类的虚函数后，父类指针根据赋给它的不同的子类指针，动态的调用属于子类的该函数，这样的函数调用在编译期间是无法确定的（调用的子类的虚函数的地址无法给出）。因此，这样的函数地址是在运行期绑定的（晚绑定）。 有哪几种情况只能用intialization list 而不能用assignment? 当类中含有const、reference 成员变量；基类的构造函数都需要初始化表。 聊一下#define的特点 说了一下预处理进行替换及define的优缺点，当多处使用同一个值使用define进行一次替换就行，函数也可以做到一次替换，为什么用define不用函数 C++中为什么用模板类。 可用来创建动态增长和减小的数据结构 它是类型无关的，因此具有很高的可复用性。 它在编译时而不是运行时检查数据类型，保证了类型安全 它是平台无关的，可移植性 可用于基本数据类型 说下你对内存的了解？描述内存分配方式以及它们的区别？ C++编程中的内存基本构造 在C++中内存分成5个区，分别是堆、栈、全局/静态存储区、常量存储区和代码区； 栈，就是那些由编译器在需要的时候分配，在不需要的时候自动清楚的变量的存储区，里面的变量通常是局部变量、函数参数等。 堆，就是那些由new分配的内存块，他们的释放编译器不去管，由我们的应用程序去控制，一般一个new就要对应一个delete。如 果程序员没有释放掉，那么在程序结束后，操作系统会自动回收。 全局/静态存储区，全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在 C++里面没有这个区分了，他们共同占用同一块内存区。 常量存储区，这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改（当然，你要通过非正当手段也可以修改）。 代码区 （.text段），存放代码（如函数），不允许修改（类似常量存储区），但可以执行（不同于常量存储区）。 构造函数可否是虚函数，为什么？析构函数呢，可否是纯虚的呢？ 构造函数不能为虚函数，要构造一个对象，必须清楚地知道要构造什么，否则无法构造一个对象。析构函数可以为纯虚函数。 什么是内存泄漏？面对内存泄漏和指针越界，你有哪些方法？你通常采用哪些方法来避免和减少这类错误？ 什么是虚函数，什么是虚继承，虚函数的实现机制 虚函数和虚继承对于一个类求sizeof的影响有什么差别 基类的有1个虚函数，子类还需要申明为virtual吗？为什么。 不申明没有关系的。 不过，我总是喜欢显式申明，使得代码更加清晰。 如何解决多继承造成的类成员重复的问题？ 使用虚继承 C++里的多态是怎么实现的？动态绑定是如何实现的？ 静态多态和动态多态。静态多态是指通过模板技术或者函数重载技术实现的多态，其在编译器确定行为。动态多态是指通过虚函数技术实现在运行期动态绑定的技术。 STL vector在resize时是原来的多少倍？ new 和 malloc 有什么区别 STL里的内存池实现 STL里set和map是基于什么实现的。红黑树的特点？ std::sort() 的平均复杂度、最坏复杂度（答 O(N^2) 和 O(N log N) 都算对） 会c++ 为什么C calling convention的参数进栈顺序是从右向左的。 class作为map/unordered_map的key分别需要实现什么？ 使用过可变长模板吗？使用在什么场合？ 自动化对象生命期管理，智能指针，循环引用，weak_ptr。 实现一个不能被继承的类 template class A { friend T; // 注意这里不需要class关键字 // 将构造函数和析构函数都声明是私有的 private : A() {} ~A() {} }; // 这里一定需要使用虚继承，只有使用虚继承，它的子类才会直接调用A类的 // 构造函数，这样才会报错，如果是普通继承，那么通过B类调用A类的构造 // 函数时不会报错的 // 注意：在虚继承中，虚基类是由最终的派生类初始化的，换句话说，最终 // 派生类的构造函数必须要调用虚基类的构造函数。对最终的派生类来说， // 虚基类是间接基类，而不是直接基类。这跟普通继承不同，在普通继承中， // 派生类构造函数中只能调用直接基类的构造函数，不能调用间接基类的。 class B: public virtual A { }; class C: public B { }; 怎么实现一个class，禁止分配在栈上 参考singleton的实现 如何实现shared_ptr 如何实现 bind？注意点 返回函数对象，使用变参模板 C++是不是类型安全的？ 不是。两个不同类型的指针之间可以强制转换（用reinterpret cast)。C#是类型安全的。 new 实际上执行了什么操作，可能在什么步骤出现异常(operator new 和 new 操作符有什么区别？ placement new？) // new是new操作符：和sizeof()一样，不能改变 // 1.调用operator new申请空间， 2.调用构造函数 string *ps = new string(\"Memory\"); // placement new new(buffer) Widget(widgetSize) 怎么突破 private 的限制访问变量 虚继承的细节 c++迭代器失效问题，一个list，将指定值删除 list 的 insert()/erase() 与 vector 相比哪个快。（这个不是那么简单。） 标准库的线程安全性 比较了解c++ 为什么C++的member function template不能是virtual的 问题的意思是，为什么在C++里面，一个类的成员函数不能既是 template 又是 virtual 的。比如，下面的代码是不合法的： class Animal { public: template virtual void make_sound(){ //... } }; 原因如下：因为C++的编译与链接模型是\"分离\"的(至少是部分原因吧)。 从Unix/C开始，一个C/C++程序就可以被分开编译，然后用一个linker链接起来。这种模型有一个问题，就是各个编译单元可能对另一个编译单元一无所知。 一个 function template最后到底会被 instantiate 为多少个函数，要等整个程序(所有的编译单元)全部被编译完成才知道。 同时，virtual function的实现大多利用了一个\"虚函数表\"的东西，这种实现中，一个类的内存布局(或者说虚函数表的内存布局)需要在这个类编译完成的时候就被完全确定。 所以，由上面的矛盾可知，C++ 的 member function 不能既是 template 又是 virtual 的。 C++为什么要有class？ 考对oop基础的理解，而不是考死语法。可引申出动态多态，RAII，类型系统，隐式成员等一票问题。大牛还是菜鸡，用这一个问题就暴露了。 类是C++用来实现OOP封装、继承和多态的核心机制。C++用虚函数实现多态，用RAII（和析构，异常机制）实现自动资源管理，用拷贝和移动定义资源的复制和转移，进而用隐式成员（Rule of 5，析构，拷贝构造，拷贝赋值，移动构造，移动赋值）来帮助用户省去手写冗余代码，最终达到不多写一个字的资源管理。如果说面向对象的概念已经有些过时了，资源管理却是永不过时的，也是C++从机制上不同于C的最主要一点。有些人写的糟糕C++代码其实是把写面向过程套了一层class的皮、滥用多态让代码纠缠不清、最终既不仅没有简化逻辑，也没有简化资源管理。 初始化列表的异常怎么捕获 Foo::Foo(int num) try: items_(new int[num]) { cout 什么是完美转发？ 模板函数形参形如 T&&，结合库函数 std::forward 来将参数实现类型的完美转发。std::move可将左值强制转为右值。左值可以取地址，一般在等号左边，右值不可取地址，一般在等号右边，如返回的临时变量，字面值都是右值。 怎么在编译器判断一个类中有没有定义某个特定的方法 主要是一些边角的语法或者是不常见的问题 逗号表达式，位域 dynamic_cast是怎么实现的？这是难题。能有思路就说明有读过ABI了。我自己不止一次被人问到过，第一次没答上来。 对于常见的主流编译器，写不写inline有什么影响 构造函数中调析构函数会有什么结果 用template 写factorial。 C++ 03有什么你不喜欢的语法或者功能？ c++实现一个复数类 #include class Rational { public: Rational(); Rational(int x); Rational(int x, int y); Rational(const Rational& r); const Rational& operator=(int x); const Rational& operator=(const Rational& r); virtual ~Rational(); bool operator== (const Rational& other) const; friend const Rational operator+ (const Rational& r1, const Rational& r2); friend const Rational operator- (const Rational& r1, const Rational& r2); friend const Rational operator* (const Rational& r1, const Rational& r2); friend const Rational operator/ (const Rational& r1, const Rational& r2); friend std::ostream& operator(std::istream&, Rational& r); private: static int gcd(int p, int q); int num; //numerator int div; //divisor }; int main(int argc, char* argv[]) { Rational a(1, 3); //a等于三分之一 Rational b = 3; //b等于3，3也是有理数 b = a; Rational c(a+b+Rational(1,3)); //有理数可以做加法 std::cout d; std::cout enable_share_from_this 是做什么的，请举一个场景说明？ 让一个被shared_ptr管理生命周期的类能够在自己的成员函数内部访问shared_ptr。 然后就开始聊多线程编程模式、线程安全等问题。我觉得这个问题是一个很好的问题，从语言出发，扩展到工程经验和对编程的理解。而且弱指针确实是c++非常有特色的一个特性。 为什么stl中的内存分配器要设计为一个模板参数而不是一个构造函数参数？ 这个就属于瞎聊了，各抒己见呗。最后扯到类型系统如何帮助程序员排错之类的问题。 指针是什么？你能不用指针写C++程序吗？指针好还是不好？ 这个问题不仅考C基础和计算机原理基础，还可引申出引用，拷贝和移动语义，const correctness，value semantic等一票基础问题。 经典问题：vector和list有什么区别？ 一个不了解C++如何控制资源颗粒度的程序员恐怕不是一个好的C++程序员。可引申出一大票算法和数据结构问题。 C++为什么要有类型？ 考对静态类型语言的理解和权衡，可引申出类型安全，泛型，模板元编程，编译时计算，静态多态等一众问题。 相比起大方向的理解，细节问题例如虚表是如何实现的，或者某个关键字怎么用，某个设计模式怎么实现这类问题实在意义不大。程序员不是编译器，不应该考程序员模拟编译器的水平。程序员是人，软件工程终极的目标是服务于人，应该考程序员作为人机交互中人的一端表现出的水平，即——我们为什么要用C++，以及为什么C++是这样用的。 我一般会循序渐进的问问题，以C++的虚函数为例。 了解多态么？它是怎么实现的？什么时候应该使用它？ 在语言层面，虚函数是怎样实现的？为什么还要区分虚函数和普通函数，都成虚函数不好么？ 虚表里存储的是什么？ 如果基类定义先声明了f函数后声明了g函数，子类定义会反过来（真正面试的时候会有样例代码给出），那么虚表里第一项是什么？ 如果有多继承，虚表内会怎样？ 等等。 这只是个大体思路，关键是看求职者的现场反应能力和链接能力，比如： 第一题，如果提到静态多态，并且简单询问后确认懂得什么是静态多态，则有额外加分。 第二题，提到和其他语言的对比（如java oc python 等），有额外加分。 第四题，关键不在于答案，而在于回答的思路。如果在回答出大体原理之后加以说明这东西是undefined，不应该依赖于这个结果，有额外加分。 第五题，如果一开始求职者不太了解这个事情，但是通过我简单的提示，能够沿着这个思路走下去，无论对错，均有额外加分。 如果在面试中会询问到了求职者之前没有思考过的问题，我会给出适当的提示，逼迫其现场思考\\ 如果中间被求职者带跑了，比如问第一题的时候扯到模板元编程了，我的态度就是随着他跑，在他自己最擅长的领域才能看出他的思路究竟是怎样的。 总之，尽量通过方方面面探知求职人员对技术核心思想的把握能力，如果在面试之前他就考虑的很透彻，这是上上之选（原因是其会自己沿着正确的方向独立思考），如果在面试中可以现场考虑出大概，这是上之选（原因是其逻辑思维还不错）。 思维方式很重要，某种程度上，这东西决定一个人的命运。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/go/":{"url":"note/go/","title":"go","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/go/go-interview.html":{"url":"note/go/go-interview.html","title":"go面试题","keywords":"","body":"go 面试题 什么是goroutine，他与process， thread有什么区别？ 什么是channel，为什么它可以做到线程安全？ 了解读写锁吗，原理是什么样的，为什么可以做到？ 如何用channel实现一个令牌桶？ 如何调试一个go程序？ 如何写单元测试和基准测试？ goroutine 的调度是怎样的？ golang 的内存回收是如何做到的？ cap和len分别获取的是什么？ netgo，cgo有什么区别？ 什么是interface？ goroutine 泄露、调优 golang 性能调优常用手段 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/redis/":{"url":"note/redis/","title":"redis","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/redis/redis-memory.html":{"url":"note/redis/redis-memory.html","title":"Redis内存管理","keywords":"","body":"Redis内存管理和持久化 支持的数据类型： string、list、set、hash、sorted set 数据结构 typedef struct redisObject { unsigned type, // 4字节，数据类型(String,List,Set,Hash,Sorted Set) unsigned encoding, // 4字节，编码方式 unsigned lru, // 24字节 int refcount, // 对象引用计数 void *ptr, // 数据具体存储的指向 } robj; 编码方式 RAW：RedisObject的ptr指向名为sds的空间，包含Len和Free头部和buf的实际数据，Free采用了某种预分配（若Len=1M，则Free分配1M空间；SDS的长度为Len+Free+buf+1(额外的1字节用于保存空字符)） EMBSTR：与RedisObject在连续的一块内存空间，省去了多次内存分配；条件是字符串长度 INT：字符串的特殊编码方式，若存储的字符串是整数时，则ptr本身会等于该整数，省去了sds的空间开销；实际上Redis在启动时会默认创建10000个RedisObject，代表0-10000的整数 ZipList(压缩列表)：除了一些标志性字段外用一块类似数组的连续空间来进行存储，缺点是读写时整个压缩列表都需要更改，一般能达到10倍的压缩比。Hash默认值为512，List默认是64 Hash Table：默认初始大小为4，使用链地址法解决hash冲突；rehash策略：将原来表中的数据rehash并放入新表，之后替换；大量rehash可能会造成服务不可用，因此Redis使用渐进式rehash策略，分批进行 过期清理 Redis对于过期键有三种清除策略： 被动删除：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key 只有key被操作时(如GET)，REDIS才会被动检查该key是否过期，如果过期则删除之并且返回NIL 这种删除策略对CPU是友好的，删除操作只有在不得不的情况下才会进行，不会对其他的expire key上浪费无谓的CPU时间 但是这种策略对内存不友好，一个key已经过期，但是在它被操作之前不会被删除，仍然占据内存空间 主动删除：由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期主动淘汰一批已过期的key 系统空闲时做后台定时清理任务（时间限制为25%的CPU时间）；Redis后台清理任务默认100ms执行1次，25%限制是表示25ms用来执行key清理 依次遍历所有db； 从db中随机取得20个key，判断是否过期，若过期，则剔除； 若有5个以上的key的过期，则重复步骤2，否则遍历下一个db 清理过程中若达到了时间限制，则退出清理过程 当前已用内存超过maxmemory限定时，触发主动清理策略 volatile-lru：只对设置了过期时间的key进行LRU（默认值） allkeys-lru：删除lru算法的key volatile-random：随机删除即将过期key allkeys-random：随机删除 volatile-ttl：删除即将过期的 noeviction：永不过期，返回错误 持久化 持久化对过期key的处理 持久化key之前，会检查是否过期，过期的key不进入RDB文件 从RDB文件恢复数据到内存数据库 数据载入数据库之前，会对key先进行过期检查，如果过期，不导入数据库（主库情况） 从内存数据库持久化数据到AOF文件，当key过期后，还没有被删除，此时进行执行持久化操作 当key过期后，在发生删除操作时，程序会向aof文件追加一条del命令 aof重写时，会先判断key是否过期，已过期的key不会重写到aof文件 Redis支持四种持久化方式；如下： 定时快照方式(snapshot)[RDB方式] 基于语句追加文件的方式(aof) 虚拟内存(vm)，已被放弃 Diskstore方式，实验阶段 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/ceph/":{"url":"note/ceph/","title":"ceph","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/ceph/introduction-to-ceph.html":{"url":"note/ceph/introduction-to-ceph.html","title":"ceph 简介","keywords":"","body":"Ceph 简介 Ceph 是一个统一的分布式存储系统，设计初衷是提供较好的性能、可靠性和可扩展性。Ceph 项目最早起源于 Sage 就读博士期间的工作（最早的成果于2004年发表），并随后贡献给开源社区。在经过了数年的发展之后，目前已得到众多云计算厂商的支持并被广泛应用。 本文试图简单明了的介绍 ceph 的基本概念和组件，以对 ceph 有全面清晰的了解。 1. 核心组件 一个 ceph 集群通常有多个组件（进程），包括 monitor、osd、mds、radosgw 等，如下图所示： MON： Monitor 监控整个集群的状态，维护集群的 Cluster MAP，保证集群数据的一致性。Cluster MAP 描述了对象块存储的物理位置（OSD的元数据） 一个 Ceph 集群需要多个 Monitor 通过 Paxos 协议组成的小集群 对应进程为 ceph-mon OSD： Object Storage Device 用于集群中所有数据与对象的存储，处理集群数据的复制、恢复、回填、再均衡。并向其他 OSD 守护进程发送心跳，向 Mon 提供监控信息 一个 Ceph 集群一般都有很多 OSD，一般一块磁盘对应一个 OSD 对应进程为 ceph-osd MDS： Ceph Metadata Server 为 Ceph 文件系统提供元数据计算、缓存与同步，在 ceph 中，元数据也是存储在 OSD 节点中的，MDS 类似于元数据的代理缓存服务器 MDS 进程并不是必须的进程，只有需要使用 CephFS 时，才需要配置 MDS 节点 对应进程为 ceph-mds RGW： RADOS gateway RADOS 对象存储的一个 HTTP REST 网关，是 Ceph 分布式存储系统的一部分。它是用 libfcgi 实现的一个 FastCGI 模块，可联合任何支持 FastCGI 功能的网页服务器使用 对应进程为 radosgw MGR： Ceph Manager Daemon ceph luminous 版本中新增加的组件 该组件的主要作用是分担和扩展 monitor 的部分功能，减轻 monitor 的负担，让更好地管理 ceph 存储系统 对应进程为 ceph-mgr 2. 整体架构 Ceph 的底层是 RADOS，RADOS 本身也是分布式存储系统，Ceph 所有的存储功能都是基于 RADOS 实现。RADOS 采用 C++ 开发，所提供的原生 librados API 包括 C 和 C++两种。Ceph 的上层应用调用本机上的 librados API，再由后者通过 socket 与 RADOS 集群中其他节点通信并完成各种操作。 RADOS：RADOS 全称 Reliable Autonomic Distributed Object Store，是对象存储集群的核心组件，Ceph 集群的精华，用户实现数据分配、Failover 等集群操作 Libradio：Librados 是 Rados提供库，因为 RADOS 是协议很难直接访问，因此上层的 RBD、RGW 和 CephFS 都是通过 librados 访问的，目前提供 PHP、Ruby、Java、Python、C 和 C++ 支持 Ceph 目前提供三种存储方式接口： 对象存储（RGW，RADOS gateway）： Ceph 对象存储服务提供了 REST 风格的 API ，它有与 Amazon S3 和 OpenStack Swift 兼容的接口。也就是通常意义的键值存储，其接口就是简单的 GET、PUT、DEL 和其他扩展； 块存储（RBD，RADOS block device）： RBD 通过 Linux 内核客户端和 QEMU/KVM 驱动来提供一个分布式的块设备。RBD 是通过 librbd 库对应用提供块存储，主要面向云平台的虚拟机提供虚拟磁盘；目前 RBD 提供了两个接口，一种是直接在用户态实现， 通过 QEMU Driver 供 KVM 虚拟机使用；另一种是在操作系统内核态实现了一个内核模块，通过该模块可以把块设备映射给物理主机，由物理主机直接访问； 文件系统存储（Ceph File System）： Ceph FS 通过 Linux 内核客户端和 FUSE 来提供一个兼容 POSIX 的文档系统。Ceph 文档系统服务提供了兼容 POSIX 的文档系统，可以直接挂载为用户空间文档系统； 3. 存储过程 pool 是存储对象的逻辑分区，它规定了数据冗余的类型和对应的副本分布策略。创建 pool 的时，需要指定副本数 size、 PG 数量 pg-num、PGP 数量 pgp-num 和副本分布策略（副本 replicated 或 纠删码 erasure）。简单来说，PG 是指定存储池存储对象的目录有多少个，相同 PG 内的对象都会放到相同的硬盘上，PGP 是存储池 PG 的 OSD 分布组合个数。 当一个 file 存入 pool 时，有3个步骤： 把 file 切分为 RADOS 层的 object 每个 object 通过哈希算法映射到唯一的 PG 每个 PG 通过 CRUSH 算法映射到实际存储单元 OSD 下面是一段伪代码，简要描述了 ceph 的数据存储流程： locator = object_name obj_hash = hash(locator) pg = obj_hash % num_pg osds_for_pg = crush(pg) # returns a list of osds primary = osds_for_pg[0] replicas = osds_for_pg[1:] object 是 ceph 最底层的存储单元，每个 object 包含元数据和原始数据，object 一般为 2MB 或 4MB。但 object 不会直接存储进 OSD 中，原因主要有2点： object 很小，在一个大规模的集群中可能有几百到几千万个 object，遍历 object 寻址速度缓慢 如果将 object 直接通过某种固定映射的哈希算法映射到 OSD 上，当这个 OSD 损坏时，对象无法自动迁移至其他 OSD 上面（映射函数不允许） 为了解决上述问题，ceph 引入了归置组的概念 PG，PG 是一个逻辑概念，它在数据寻址时类似于数据库中的索引：每个对象都会固定映射进一个 PG 中。PG 和 OSD 间是多对多的映射关系，在数据迁移时，也是以 PG 作为基本单位进行迁移，ceph 不会直接操作 object。 PGP 是 PG 存放 OSD 的一种排列组合，比如有 3 个osd，osd.1、osd.2 和 osd.3，副本数是2，如果 PGP 的数目为1，那么 PG 存放的 OSD 组合就只有一种，可能是[osd.1,osd.2]，所有的 PG 主从副本分别存放到 osd.1 和 osd.2，如果 PGP 设为 2， OSD 组合有两种，可能是 [osd.1,osd.2] 和 [osd.1,osd.3]，在一个 PGP 组合中，第一个 osd 是主，后面的为副本。一般讲将 PG 和 PGP 的数量设置为相等。 4. 其他 PG 寻址使用的 CRUSH 算法是 ceph 的两大创新之一。简单来说，ceph 摒弃了传统的集中式存储元数据寻址的方案，转而使用 CRUSH 算法完成数据的寻址操作。CRUSH 在一致性哈希基础上很好的考虑了容灾域的隔离，能够实现各类负载的副本放置规则，例如跨机房、机架感知等。CRUSH 算法有相当强大的扩展性，理论上支持数千个存储节点。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/ceph/deploy-ceph.html":{"url":"note/ceph/deploy-ceph.html","title":"部署 ceph 集群","keywords":"","body":"使用 ceph-deploy 部署 ceph 集群 1. 环境准备 将 https://download.ceph.com/rpm-luminous/el7/x86_64/ 上某一版本的所有 rpm 下载到本地，并制作 yum 本地安装源，并复制到所有 ceph 节点上。 以下步骤每个 ceph 节点机器上都需要执行 增加 ceph 源 源文件 /etc/yum.repos.d/ceph.repo，内容如下： [ceph] name=ceph baseurl=file:///home/cepher/ceph-12.2.5 enabled=1 gpgcheck=0 priority=1 增加 epel 源 EPEL (Extra Packages for Enterprise Linux)是基于Fedora的一个项目，为“红帽系”的操作系统提供额外的软件包，适用于 RHEL、CentOS 和 Scientific Linux。 源文件 /etc/yum.repos.d/epel.repo，内容如下： [epel-7-epel] name=Mirror of epel-7-epel baseurl=http://repo.sogou/pub/repo.epel/7/$basearch/epel gpgcheck=0 cost=2000 enabled=1 [epel-7-epel-source] name=Mirror of epel-7-epel-source baseurl=http://repo.sogou/pub/repo.epel/7/$basearch/epel-source gpgcheck=0 cost=2000 enabled=1 设置 hostname Cluster Map 中会使用主机 hostname 作为名称表示，因此 hostname 需要好好规划。 192.168.1.1 admin-node 192.168.1.2 node1 # 主机名也要改为 node1 192.168.1.3 node2 192.168.1.4 node3 配置 NTP 保证所有 ceph 节点的时间都是同步的，各 osd 节点间需要设置时间同步，节点时钟偏差过大会引起 pg 异常。 关闭 iptables 和 selinux 2. 安装 ceph-deploy 工具 ceph-deploy 是 ceph 官方提供的部署工具，它通过 ssh 远程登录其它各个节点上执行命令完成部署过程，在 admin-node 节点安装 ceph-deploy 命令，并配置 admin-node 到所有ceph节点 的 ssh 秘钥登录 yum install ceph-deploy –y ssh-keygen ssh-copy-id 在某些发行版（如 CentOS ）上，执行 ceph-deploy 命令时，如果 ceph 节点默认设置了 requiretty 那就会遇到报错。可以这样禁用此功能：执行 sudo visudo ，找到 Defaults requiretty 选项，把它改为 Defaults:ceph !requiretty 3. 安装 ceph 集群 在执行 ceph-deploy 的过程中会生成一些配置文件，建议在 admin-node 节点创建一个目录，例如 my-cluster。 mkdir /home/cepher/my-cluster cd /home/cepher/my-cluster 下面的部署操作都要在 my-cluster 目录下操作 创建 ceph 集群 ceph-deploy new node1 node2 node3 # 不要重复执行该命令，会生成新的秘钥环 # 默认ceph使用集群名ceph，可以使用下面命令创建一个指定的ceph集群名称 # ceph-deploy --cluster {cluster-name} new {host [host], ...} my-cluster 目录下应该有一个 ceph 配置文件、一个 monitor 密钥环和一个日志文件。修改刚生成的配置文件，在 ceph.conf 中加入： osd pool default size = 2 # 默认副本数从 3 改成 2 mon osd down out interval = 0 # 关闭自动迁移 mon osd down out subtree limit = host # 不进行自动迁移的最小 bucket osd pool default min size = 1 # I/O 不阻塞的最小副本数，默认是 0 osd pool default pg num = 128 # pool 的 pg 数量 osd pool default pgp num = 128 # pool 的 pgp 数量 public network = 192.168.1.0/24 # 公共网络 cluster network = 192.168.1.0/24 # 集群网络 注意 ceph.conf 配置文件中的参数名称如果带有 default 则表示是默认设置，它不会立即生效，而是在你创建新的 pool 或其他东西的时候才生效，而一般名称中没有 default 的可能是全局参数，push 之后立即生效 安装 ceph 组件 使用 --no-adjust-repos 参数忽略设置 ceph 源 ceph-deploy install node1 node2 node3 --no-adjust-repos 初始化 moniter 节点 ceph-deploy mon create-initial # 上面命令效果如下 # 1.write cluster configuration to /etc/ceph/{cluster}.conf # 2.生成/var/lib/ceph/mon/ceph-node1/keyring # 3.systemctl enable ceph-mon@node1 # 4.systemctl start ceph-mon@node1 初始化 OSD 节点 创建 OSD ceph-deploy osd prepare node2:sdb:sdc node3:sdb:sdc # 创建 GPT 分区、创建文件系统 ceph-deploy osd activate node2:sdb:sdc node3:sdb:sdc # 激活 OSD 以上两条命令可以直接用 ceph-deploy osd create node2:sdb:sdc node3:sdb:sdc 这条命令代替 如果不是以一整块盘为一个 osd 而是以一个分区为一个 osd 的话，就需要提前手动分好区（包括日志盘或分区，注意分区时要保证分区对齐，建议从1M处开始分） node2:sdb1:sdc 中sdb1表示osd，sdc表示该osd的日志盘，也可以不指定日志盘，与osd共享空间，即node2:sdb1，此时不能用ceph-deploy osd create命令代替prepare和activate 将各节点的 ceph 磁盘挂载目录（/var/lib/ceph/osd/ceph-xx）添加到 /etc/fstab 中 安装 mgr 服务 luminous 版需要安装 mgr 服务，ceph-mgr 目前的主要功能是把集群的一些指标暴露给外界使用，在 monitor 节点上装 mgr 服务： ceph-deploy mgr create monitor-node 4. 其他 允许一主机以管理员权限执行 ceph 命令 ceph-deploy admin {host-name [host-name]...} # 拷贝 ceph.conf 和 client.admin.keyring 到远程主机上 把改过的配置文件分发给集群内各主机 ceph-deploy --overwrite-conf config push node{1..3} 清除磁盘操作 # 查看某节点上所有磁盘 ceph-deploy disk list {node-name [node-name]...} # 清除指定磁盘上的分区，用于重装ceph集群 ceph-deploy disk zap {osd-server-name}:{disk-name} ceph-deploy disk zap node1:/dev/vdb monitor 操作 # 从某个节点上移除 mon 进程 ceph-deploy mon destroy {host-name [host-name]...} var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/ceph/using-ceph-rbd.html":{"url":"note/ceph/using-ceph-rbd.html","title":"使用 ceph rbd 块设备","keywords":"","body":"Ceph 客户端安装及 RBD 挂载 安装 ceph 客户端 使用命令 modprobe rbd 确认内核是支持 rbd，如不支持考虑升级内核 联系 ceph 管理员安装 ceph 客户端，获取 ceph 用户名以及权限文件 ceph.client.rbd.keyring，将权限文件放到 /etc/ceph 目录下 执行命令 ceph -s --id rbd # 用户名为 rdb，如果命令正常输出，表明此 client 所在机器可以访问并使用 ceph 集群 RBD 块存储映射 设置完本地访问 ceph 的认证权限外，需要将本地指定目录挂载与 ceph 提供的 rbd 镜像地址进行关联，以便开发的服务可以写本地指定的目录（目录会自动同步到 ceph 存储集群）挂载步骤如下： 挂载 rbd 与 ceph 管理员沟通，所使用服务的业务需求：如资源池名称 pool-name、镜像名称 image-name、副本数、空间大小等 建立映射，客户端机器上执行 rbd map ${pool-name}/${image-name} --id rbd，执行完毕后会输出类似于 /dev/rbd0 （类似rbd0，rbd1…本地可以生成多份映射关系） 执行 mkfs.xfs /dev/rbd0 进行文件系统初始化（初始化为 xfs 格式即可，只有在第一次使用时需要格式化，再次格式化会丢失数据） 本地创建目录 mkdir /data/yourapp （即应用程序读写数据或日志目录） 本地目录与 rbd 对应 ceph 集群进行映射关联，执行 mount /dev/rbd0 /data/yourapp 至此，在此客户端机器上即可安装服务，服务对 /data/yourapp 目录的所有操作（文件操作等）都会同步到 ceph 集群，当本地机器故障后，可以另一台 client 上重新设置并部分服务，其对应原来机器操作的数据不会丢失可以继续使用。 自动挂载设置 设置自动 map，修改 /etc/ceph/rbdmap，增加如下内容： rbd/test1 id=rbd,keyring=/etc/ceph/ceph.client.rbd.keyring 自动挂载块设备，在 /etc/fstab 增加如下内容： /dev/rbd/rbd/test1 /mnt/rbd-test1 xfs defaults,noatime,_netdev 0 0 设置 rbdmap 开机启动 systemctl enable rbdmap 设置开机启动后，磁盘总是挂载不上，发现 systemctl is-enable rbdmap 是 static 状态，不是 enable，经查，这里的 static 是指 Unit 的文件中没有 [Install] 区域，因此需要添加此区域，即 /usr/lib/systemd/system/rbdmap.servic 中增加如下内容： [Install] WantedBy=multi-user.target 重启机器 reboot 或 systemctl restart rbdmap 附：管理员操作 创建 pool ceph osd pool create rbd 64 ceph osd pool application enable rbd rbd ceph osd pool set rbd size 3 # 设置副本数为 3 生成客户端 keyring ceph auth get-or-create client.rbd -o ./ceph.client.rbd.keyring # 导出秘钥 ceph auth caps client.rbd mon 'allow r' osd 'allow rwx pool=rbd' # 修改权限 ceph.client.rbd.keyring 如下： [client.rbd] key = AQD+Qo5cdS0mOBAA6bPb/KKzSkSvwCRfT0nLXA== caps mon = \"allow r\" caps osd = \"allow rwx pool=rbd\" 创建 image rbd create --size 1024 foo # 创建 rbd image 参考：https://www.cnblogs.com/zyxnhr/p/10549727.html var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/ceph/config-rgw-with-nginx.html":{"url":"note/ceph/config-rgw-with-nginx.html","title":"配置 nginx 和 rgw","keywords":"","body":"通过 nginx 访问 ceph.radosgw 增加配置 找2台机器（配置了 admin key 使之可访问 ceph 集群的），如 ttt_40_111、bjzw_98_111，将 ceph.conf 增加下列配置： [client.radosgw.ttt_40_111] host = ttt_40_111 user = root keyring = /etc/ceph/ceph.client.radosgw.keyring rgw host = 0.0.0.0 rgw port = 8001 log file = /var/lib/ceph/radosgw/radosgw.log rgw print continue = false debug rgw = 1 [client.radosgw.ttt_98_111] host = ttt_98_111 user = root keyring = /etc/ceph/ceph.client.radosgw.keyring rgw host = 0.0.0.0 rgw port = 8001 log file = /var/lib/ceph/radosgw/radosgw.log rgw print continue = false debug rgw = 1 生成 keyring 分别在2台机器上执行命令生成 keyring ceph-authtool --create-keyring /etc/ceph/ceph.client.radosgw.keyring ceph-authtool -n client.radosgw.ttt_98_111 \\ --gen-key /etc/ceph/ceph.client.radosgw.keyring ceph-authtool -n client.radosgw.ttt_98_111 \\ --cap osd 'allow rwx' --cap mon 'allow rw' --cap mds 'allow rw' \\ /etc/ceph/ceph.client.radosgw.keyring 分别在2台机器上执行，将 radosgateway 的 keyring 加到 ceph 集群的 keyring 中： ceph -k /etc/ceph/ceph.client.admin.keyring auth add \\ client.radosgw.ttt_98_111 -i /etc/ceph/ceph.client.radosgw.keyring 因为在添加时需要拥有 ceph 集群的 admin key，方能有权限操作 ceph 集群，所以事先找个2台就是能够访问 ceph 的，其它机器的话再单独配置 admin key 访问权限即可 启动 radosgw # @后面是ceph.conf中[client.radosgw.ttt_98_111]里除了client 的后面部分 systemctl restart ceph-radosgw@radosgw.ttt_98_111 systemctl status ceph-radosgw@radosgw.ttt_98_111 # 查看状态 检查端口 netstat -tunlp | grep radosgw，输出如下： tcp 0 0 0.0.0.0:7480 0.0.0.0:* LISTEN 48269/radosgw tcp 0 0 0.0.0.0:8001 0.0.0.0:* LISTEN 48269/radosgw 一般只会输出 7480，但我们配置中加了8001这个，其目的就是为了后面 nginx 的转发到这个端口 配置 nginx 增加 /usr/local/nginx/conf/vhosts/rgw.conf，内容如下： upstream bk_radosgw { server ttt_40_111:8001; server ttt_98_111:8001; } server { listen *:8080; location / { include fastcgi_params; fastcgi_pass_header Authorization; fastcgi_pass_request_headers on; fastcgi_pass bk_radosgw; } } 创建 rgw 使用的用户并授权 radosgw-admin user create --uid=fe.ceph --display-name=fe.ceph # 名字叫 fe.ceph radosgw-admin caps add --uid=fe.ceph --caps=\"users=read, write\" radosgw-admin caps add --uid=fe.ceph --caps=\"usage=read, write\" radosgw-admin user info --uid=fe.ceph # 查看 access_key 调用示例 curl 10.153.44.42:8080/fe.ceph/user?format=json 其中 10.153.44.42 为启动的 nginx 机器，正常返回如下示： { \"Code\":\"NoSuchBucket\", \"BucketName\":\"fe.ceph\", \"RequestId\":\"tx000000000000000000005-005a97d0ef-20bcef-default\", \"HostId\":\"20bcef-default-default\" } 性能提升 如果性能不高的话，原因是 ceph RGW 在写大量文件时, 写 index 成了磁盘 io 瓶颈，解决方法是将 index 进行分片，修改配置文件, 开启 index 分片(/etc/ceph/ceph.conf): [global] ... rgw_override_bucket_index_max_shards=8 重启rgw sudo systemctl restart ceph-radosgw＠××× var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/net/":{"url":"note/net/","title":"网络","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/net/about-tcp.html":{"url":"note/net/about-tcp.html","title":"TCP小结","keywords":"","body":"TCP 小结 TCP状态迁移图 SYN Flood攻击 新建连接时，如果server端收到client的SYN包后回复了SYN/ACK，但client掉线了，server端没收到client的ACK，这个连接处于一个中间状态，即没成功，也没失败。于是，server端如果在一定时间内没有收到ACK的TCP会重发SYN-ACK。在Linux下，默认重试次数为5次，重试的间隔时间从1s开始每次都翻售，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 2^6 -1 = 63s，TCP才会把断开这个连接。 一些恶意的人就为此制造了SYN Flood攻击——给服务器发了一个SYN后，就下线了，于是服务器需要默认等63s才会断开连接，这样，攻击者就可以把服务器的syn连接的队列耗尽，让正常的连接请求不能处理。于是，Linux下给了一个叫tcp_syncookies的参数来应对这个事——当SYN队列满了后，TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来，然后服务端可以通过cookie建连接（即使你不在SYN队列中）。 请注意，请先千万别用tcp_syncookies来处理正常的大负载的连接的情况。因为，synccookies是妥协版的TCP协议，并不严谨。对于正常的请求，你应该调整三个TCP参数可供你选择，第一个是：tcp_synack_retries 可以用他来减少重试次数；第二个是：tcp_max_syn_backlog，可以增大SYN连接数；第三个是：tcp_abort_on_overflow 处理不过来干脆就直接拒绝连接了。 关于MSL和TIME_WAIT MSL 是Maximum Segment Lifetime英文的缩写，中文可以译为“报文最大生存时间”，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。 从TIME_WAIT状态到CLOSED状态，有一个超时设置，这个超时设置是 2*MSL（RFC793定义了MSL为2分钟，Linux设置成了30s）为什么要这有TIME_WAIT？为什么不直接给转成CLOSED状态呢？主要有两个原因：1）TIME_WAIT（收到了对方发来的FIN，发送了ACK）确保有足够的时间让对端收到了ACK，如果被动关闭的那方没有收到ACK，就会触发被动端重发FIN，一来一去正好2个MSL，2）有足够的时间让这个连接不会跟后面的连接混在一起（有些自做主张的路由器会缓存IP数据包，如果连接被重用了，那么这些延迟收到的包就有可能会跟新连接混在一起）。 关于TIME_WAIT数量太多。从上面的描述我们可以知道，TIME_WAIT是个很重要的状态，但是如果在大并发的短链接下，TIME_WAIT就会太多，这也会消耗很多系统资源。处理方式都是教你设置两个参数，一个叫tcp_tw_reuse，另一个叫tcp_tw_recycle的参数，这两个参数默认值都是被关闭的，后者recyle比前者resue更为激进，resue要温柔一些。另外，如果使用tcp_tw_reuse，必需设置tcp_timestamps=1，否则无效。这里，你一定要注意，打开这两个参数会有比较大的坑——可能会让TCP连接出一些诡异的问题（因为如上述一样，如果不等待超时重用连接的话，新的连接可能会建不上。正如官方文档上说的一样“It should not be changed without advice/request of technical experts”）。 拥塞控制 拥塞控制主要是四个算法： 慢热启动算法 – Slow Start 拥塞避免算法 – Congestion Avoidance 拥塞状态时的算法 快速恢复算法 – Fast Recovery 重传 快速重传机制 于是，TCP引入了一种叫Fast Retransmit 的算法，不以时间驱动，而以数据驱动重传。也就是说，如果，包没有连续到达，就ack最后那个可能被丢了的包，如果发送方连续收到3次相同的ack，就重传。Fast Retransmit的好处是不用等timeout了再重传。 SACK 方法 另外一种更好的方式叫：Selective Acknowledgment (SACK)（参看RFC 2018），这种方式需要在TCP头里加一个SACK的东西，ACK还是Fast Retransmit的ACK，SACK则是汇报收到的数据碎版。参看下图：(更详细的确认ack) 信号处理 在网络编程中，SIGPIPE这个信号是很常见的。当往一个写端关闭的管道或socket连接中连续写入数据时会引发SIGPIPE信号，引发SIGPIPE信号的写操作将设置errno为EPIPE。 在TCP通信中，当通信的双方中的一方close一个连接时，若另一方接着发数据，根据TCP协议的规定，会收到一个RST响应报文，若再往这个服务器发送数据时，系统会发出一个SIGPIPE信号给进程，告诉进程这个连接已经断开了，不能再写入数据。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/misc/":{"url":"note/misc/","title":"杂项","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/misc/how-to-ask-recruited-question.html":{"url":"note/misc/how-to-ask-recruited-question.html","title":"面试中如何提问","keywords":"","body":"如何面试别人 四步提问法 开放式提问。通过开放式问题，了解候选人真实想法 追问。通过追问技巧使 模糊抽象概念具体化 假设提问。通过假设问题，确认真实想法 对比。通过对比前后措辞查出矛盾表述 行为事件访谈法(Behavioral Event Interview，BEI)是由麦克里兰结合关键事件法和主题统觉测验而提出来的。虽然BEI是在进行胜任模型研究过程中提出来的，但是对于人才的招聘选拔有着非常重要的借鉴意义。一般来讲，行为事件访谈法有以下几个步骤： 访谈开始阶段的自我介绍和解释 了解被访谈人的工作学习经验 深入挖掘被访谈者的行为事件(一般采用STAR法) 求证被访谈者所需特质 结束语 STAR法则是情境(situation)、任务(task)、行动(action)、结果(result)四项的缩写。STAR法则是一种常常被面试官使用的工具，用来收集面试者与工作相关的具体信息和能力。STAR法则比起传统的面试手法来说，可以更精确地预测面试者未来的工作表现。 situation，代表情景或者是情形，意味着我们在怎么样的背景下去发生了这个行为事件 task，代表我们在这个情形，在这个事件当中我们要达成怎么样的目标，我们的任务是什么 action，我们做了怎样的行动，我们具体的行为展开是如何的 result，我们最终取得了怎样的结果，我们的结论是什么 例：能说一下需求分析的阶段您都做了哪些事儿，当时是什么样的背景？你的任务是什么，具体是怎么做的吗，最后结果如何？开发的阶段是什么背景，你的任务是什么？你是怎么做的？结果如何？ MSA法则是Most Significant Accomplishment三项的缩写。代表关键事件，典型事件，直接针对能力主题。每一项胜任力背后至少有一个过去的实际行为事例来支持。 选场景问事件——能力提问 问情绪及感受——个性提问 改进和提升——关注动机 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/misc/it-interview-questions.html":{"url":"note/misc/it-interview-questions.html","title":"技术面试题","keywords":"","body":"常见技术面试题 top、tail 命令该如何实现 文件目录结构的组织形式 智能指针如何实现 golang 的常用调优手段 golang里context的作用 常用网络调优手段 C10K都是怎么做的 TCP三次握手发生在那个阶段，如果不accept，connect会阻塞么？listen的参数 Redis过期数据的清理策略 B+树和B树有什么区别，mysql 数据库索引有哪些类型 mysql 常用的优化手段 zk 和 etcd 有哪些不同 thrift 主要提供了哪些功能？ 写寻找中位数的代码（快排） 写区间合并的代码 淘宝价格搜索如何实现 迅雷积分（积分只会增加）排序如何实现 流动的中位数 微服务的理解 服务治理 负载均衡有哪些手段 服务降级如何实现 服务性能优化 mysql、kafka、redis 实现原理 你擅长哪方面的技术 thrift 的线程模型 bind 深入理解 右值 数据结构&算法 hash，hash冲突，rehash的增长方式，一致性哈希 快排有哪些优化（三数取中，重复放中，STL中的排序手段）；数组TOPK，时间复杂度 B+树和B树的区别，数据库索引用哪一种，为什么？ 判断链表有环及入环地址 红黑树有哪些具体应用（答了map,epoll） 面向对象 面向对象编程有什么特点和原则，你认为哪个原则是面向对象编程的核心原则？ 写一个单例类 讲讲reactor模式（结合muduo来回答） 操作系统原理 linux多线程和多进程的区别，调用fork后父子进程共享哪些资源，fork之后父进程修改的内容子进程也会改变吗? 子进程修改的值父进程也会改变吗？聊一下写时复制技术？zero copy的原理Fork子进程时父进程一般需要做什么，如果不用wait进行回收会出现什么情况，init进程是自动回收孤儿进程吗？ linux这里主要考察进程调度和进程生命周期，特别是CFS调度算法，几乎是必问，进程部分还有进程间通信。还有文件系统，对VFS的结构很喜欢考，解释软链接和硬链接（从inode和dentry去解释），还有文件缓存，IO调度算法等等。Linux这里也喜欢问内存，slab，slub，伙伴算法，进程内存空间，线程内存空间等等。在系统编程层次主要考察各种IO系统调用、进程相关的系统调用、socket编程。然后把这些系统调用对应到进程生命周期和进程间通信的各个阶段去考。 进程IPC机制，共享内存中多进程是怎么做到多个进行对同一块内存的安全访问的。 pthread_exit会调用析构函数吗（不会） 线程局部变量需要注意什么，当时没有反应过来问的是thread_local，GG了 epoll和select的区别，epoll两种触发方式，踩过那些坑，epoll底层实现，项目中时间设置为多大，超时时间是否精确。红黑树的性质，元素插入和删除哪个更复杂,因为用到了epoll，让讲一下epoll的原理，epoll,select,poll的区别，什么是多路IO复用，epoll的边沿触发和水平触发，用边沿触发一般会遇到什么问题，该怎么解决？ 多线程和多进程的区别，进程间通信方式，无名管道和命名管道的区别，共享内存的实现方式，线程同步方式。进程和线程独有的是什么。 进程IPC机制，共享内存中多进程是怎么做到多个进行对同一块内存的安全访问的。 shell相关 makefile的作用，有什么不足？用过cmake、qmake没？.PHONY的作用：避免和同名文件冲突，改善性能。 你用gdb一般是怎么调试的？gdb里有那几种中断？软中断是怎么实现的？常用命令，多线程命令，怎么debug一个正在运行的进程 awk 设置分隔符，怎么传shell变量，grep的使用方法 网络 socket的编写方法 OSI七层模型，每一层的作用是什么，tcp和udp的区别，tcp如何保证可靠性，三次握手和四次挥手过程，SYN flood是什么？怎么出现的？Keepalive linux命令介绍，说了一下自己用过的命令，被问了netstat怎么查看超时重传的(gg),然后聊了一下我在项目中如何使用tcpdump，又被问了tcpdump要和哪些工具结合使用。 HTTP在第几层，长连接短连接？怎么保持状态的、 拥塞避免的理解 tcp的最大报文段长度（隐约记得65535字节），ip分片过程，如何实现把一个报文不分片一次性传输 讲一下CS模型一般用到那几个函数，每个函数都有哪些参数设置，客户端和服务器的bind是否必须？ 数据库 写一个平均分的sql mysql数据库优化方式,工作原理 杂项 看过那些技术书 有成就感的事情 传智播客视频：（C++基础，C++进阶，C和C++数据结构，六天带你玩转MySQL，linux服务器开发三-网络编程，Unix编程） 书籍：C++ primer，effective C++，STL源码剖析，现代操作系统，程序员代码面试指南，linux多线程服务端编程，tcpip详解1，mysql技术内幕：innodb存储引擎，高性能mysql，Unix环境高级编程，算法导论（这个啃不动，看了不到三分之一），深度探索C++对象模型，C++11新特性解析与应用（看了一点），鸟哥的私房菜，linux网络编程 Github:找了tinystl, tiny http,看完重写了一遍，受益很大，看了larbin源码，muduo源码,基于这两个实现了两个小项目。另外libevent看了一点。 博客：陈硕，陈皓，廖雪峰，陶辉。博客里面有一些工具，比如GDB，Makefile，git的使用很详细。 目前在学分布式，有懂这块的大佬可以私信我，带带我入门（目前在看Google三宝,raft,paxos, zookeeper,rpc） var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/misc/how-to-make-a-good-presentation.html":{"url":"note/misc/how-to-make-a-good-presentation.html","title":"如何做技术演讲","keywords":"","body":"我认为，按照“问题缘起 - 方案 - 优化方案 - 总结”这类“总分总”的结构来组织内容是比较安全的。 我们可以讲一下遇到了什么问题，问题产生的原因是什么，为了解决相应的问题，我们做了些什么，以及为什么要这么做。 我们就可以展开描述解决方案的迭代过程、遇到过的矛盾冲突点，针对这些矛盾，向大家介绍下有哪些传统的解决方案以及传统方案的优缺点，之后再介绍一下我们的递进方案和最佳实践。 最后做一个总结。 大家好，我是来自 58 到家的架构师沈剑（这一句点名了我的公司、职位和姓名）。 我在百度、58 同城有过多年的架构工作经验（这一句就是吹吹牛，增强信服力）。 接下来我会和大家介绍 58 到家订单中心的架构演进细节（这个就是内容介绍了）。 通过本次分享，希望大家能够了解到对于平台型的业务来说，订单中心究竟是合还是分，以及多种方案的优缺点和我们在实践中遇到过的坑（这句话是为了告诉听众我的演讲主题和他们有什么关系，同时进一步介绍内容）。 如同架构设计一样，了解需求永远是第一步的，任何脱离需求的架构设计都是耍流氓。参加技术大会的听众，主要是想学习知识，借鉴经验解决工作中的实际问题。 那么演讲嘉宾可以在 PPT 中针对性地准备这些内容：包括真实案例、碰到的问题、踩到的坑、尝试过的各种解决方案以及解决方案的优缺点、迭代演进和最佳实践等等。 总之，技术大会的演讲，尽量少一些放之四海皆准的原则理论，多一些血肉充实的生动案例。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/misc/improve-oneself.html":{"url":"note/misc/improve-oneself.html","title":"个人提升","keywords":"","body":"个人提升 高效能人士的7个习惯 依赖期：1积极主动 2以终为始 3要事第一 独立期：4双赢思维 5知彼解己 6 统合综效 7不断更新 操之在我 刺激和反应之间有回旋的余地 不要被感觉左右，要靠理智，自己的言行、选择不应该被外界左右 信守承诺 直接控制的问题：改变自己的习惯；间接控制的问题：施加自己的影响力；不能控制的问题：接受他，保持微笑 确立目标 有功夫的修行人，乐于助人，坚定，是大家可以依靠的人 在我的葬礼上，我想听到什么 人生的目标：我有慈悲心。我愿意牺牲。我以身作则。我有影响力。 人生的角色：作为丈夫。作为父亲。作为儿子。作为佛教徒。作为员工。 掌握重点 左脑管理，右脑领导 以第II类事情（重要不紧急）为重点 对事讲效率，对人讲效应 授权代表着成长 利人利己 出现问题是改进的契机 设身处地 先了解别人，然后被了解 集思广益 均衡发展 磨刀不误砍柴功 学习-实践-坚持 提升工作 回答下面的几个问题： 你领导在向上级汇报时，他的领导会重点关注哪几个指标？ 哪些工作对你的领导是重要的？ 尝试从他的角度去思考问题？ 在公司的利润构成，哪些收入渠道占比最高？ 你做的事情跟利润来源有多少关系？ 你的工作对公司有多少重要？ 做好哪些事情能对公司更重要？ 每隔段时间就做下总结，问问自己： 从工作中学到了什么新东西？ 都处理了哪些问题，这个问题是什么原因所导致的？ 下次遇到同样的问题，如何解决? 接下来做什么？哪些是可以直接行动的？ 怎样优化能缩短工作时间和提高工作效率？ 公司最好的员工是怎么做，有什么方式可以缩短跟这个人的距离。 怎么才能避免再次遇到问题？ 主动思考 我在做XX项目的时候，碰到XX问题，引入了开源的XX，后来发现在XX场景下会出现XX现象，研究了XX的源码，发现是XX环节出了问题，为此我系统的学了XX原理，后来自己解决了这个问题，经过X次优化后，我把代码提交给了XX项目，并总结了XX文章，我甚至尝试自己实现一个XX解决问题，并且将其推广到XX。 为什么要做，收益、付出都是什么? 分析问题：当前的状况，各个环节的性能、时间对比，瓶颈在哪里 行业调研：当前行业有哪些成熟、热门的解决方案，并有哪些优缺点 技术方案：确定实现的技术方案，并给出优缺点，方案预期效果 如何落地：如何以最小代价将方案实现，的减少开发、运维、配合方的工作，方案如何平滑上线 效果追踪：方案最终达到的效果，和预期的差别 后期维护：如何运维，快速定位问题的方案 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/misc/how-to-learn-cs-english.html":{"url":"note/misc/how-to-learn-cs-english.html","title":"如何学计算机专业英语","keywords":"","body":"如何学计算机专业英语 Highly recommend NOT to start with novels, unless you are interested in literacy anyway. You'll most likely be very frustrated and give up soon. Some non-fictions like Steve Jobs and In the Plex are very good, though. It needs a bit practice, but that's all. Go pick up an interesting CS book, read it, highlight it, take some notes, scribble a few words on the margins, etc. Just do it, 30min a day, for a few months. Remember, only read the best and the most interesting books. TCPL, SICP, CLRS, CAQA, CMATH, CC2, and even TAOCP are all incredibly interesting and well-written. Pick one and throw months in it. Write slides, like this and this. Writing technical slides is an amazing practice. With very limited space you have to use accurate words, concise sentences, and clear structures. Plus that you will find it an amazingly useful skill in future work. The other one is writing emails, by the way. Read The Elements of Style, at least twice a year. If you do not have time, skip everything else and read this 100-page book. It takes time, at best months and normally years. I saw no one successfully improved his/her language skills within a few weeks, including some very smart guys. The earlier you start, the earlier and more likely you will get there, and the more fun you will enjoy. That's it. Hope this helps. 来源： https://mail.google.com/mail/?shva=1#label/TL/13aee76e01076775 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"note/misc/markdown-grammar.html":{"url":"note/misc/markdown-grammar.html","title":"Markdown简明语法","keywords":"","body":"Cmd Markdown 简明语法手册 标签： Cmd-Markdown 1. 斜体和粗体 使用 和 * 表示斜体和粗体。 示例： 这是 斜体，这是 粗体。 2. 分级标题 使用 === 表示一级标题，使用 --- 表示二级标题。 示例： 这是一个一级标题 ============================ 这是一个二级标题 -------------------------------------------------- ### 这是一个三级标题 你也可以选择在行首加井号表示不同级别的标题 (H1-H6)，例如：# H1, ## H2, ### H3，#### H4。 3. 外链接 使用 [描述](链接地址) 为文字增加外链接。 示例： 这是去往 本人博客 的链接。 4. 无序列表 使用 *，+，- 表示无序列表。 示例： 无序列表项 一 无序列表项 二 无序列表项 三 5. 有序列表 使用数字和点表示有序列表。 示例： 有序列表项 一 有序列表项 二 有序列表项 三 6. 文字引用 使用 > 表示文字引用。 示例： 野火烧不尽，春风吹又生。 7. 行内代码块 使用 `代码` 表示行内代码块。 示例： 让我们聊聊 html。 8. 代码块 使用 四个缩进空格 表示代码块。 示例： 这是一个代码块，此行左侧有四个不可见的空格。 9. 插入图像 使用 ![描述](图片链接地址) 插入图像。 示例： Cmd Markdown 高阶语法手册 1. 内容目录 在段落中填写 [TOC] 以显示全文内容的目录结构。 [TOC] 2. 标签分类 在编辑区任意行的列首位置输入以下代码给文稿标签： 标签： 数学 英语 Markdown 或者 Tags： 数学 英语 Markdown 3. 删除线 使用 ~~ 表示删除线。 这是一段错误的文本。 4. 注脚 使用 keyword 表示注脚。 这是一个注脚footnote的样例。 这是第二个注脚footnote2的样例。 5. LaTeX 公式 $ 表示行内公式： 质能守恒方程可以用一个很简洁的方程式 $E=mc^2$ 来表达。 $$ 表示整行公式： $$\\sum_{i=1}^n a_i=0$$ $$f(x_1,x_x,\\ldots,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2 $$ $$\\sum^{j-1}{k=0}{\\widehat{\\gamma}{kj} z_k}$$ 访问 MathJax 参考更多使用方法。 6. 加强的代码块 支持四十一种编程语言的语法高亮的显示，行号显示。 非代码示例： $ sudo apt-get install vim-gnome Python 示例： @requires_authorization def somefunc(param1='', param2=0): '''A docstring''' if param1 > param2: # interesting print 'Greater' return (param2 - param1 + 1) or None class SomeClass: pass >>> message = '''interpreter ... prompt''' JavaScript 示例： /** * nth element in the fibonacci series. * @param n >= 0 * @return the nth element, >= 0. */ function fib(n) { var a = 1, b = 1; var tmp; while (--n >= 0) { tmp = a; a += b; b = tmp; } return a; } document.write(fib(10)); 7. 流程图 示例 st=>start: Start:>https://www.zybuluo.com io=>inputoutput: verification op=>operation: Your Operation cond=>condition: Yes or No? sub=>subroutine: Your Subroutine e=>end st->io->op->cond cond(yes)->e cond(no)->sub->io 更多语法参考：流程图语法参考 8. 序列图 示例 1 Alice->Bob: Hello Bob, how are you? Note right of Bob: Bob thinks Bob-->Alice: I am good thanks! 示例 2 Title: Here is a title A->B: Normal line B-->C: Dashed line C->>D: Open arrow D-->>A: Dashed open arrow 更多语法参考：序列图语法参考 9. 甘特图 甘特图内在思想简单。基本是一条线条图，横轴表示时间，纵轴表示活动（项目），线条表示在整个期间上计划和实际的活动完成情况。它直观地表明任务计划在什么时候进行，及实际进展与计划要求的对比。 title 项目开发流程 section 项目确定 需求分析 :a1, 2016-06-22, 3d 可行性报告 :after a1, 5d 概念验证 : 5d section 项目实施 概要设计 :2016-07-05 , 5d 详细设计 :2016-07-08, 10d 编码 :2016-07-15, 10d 测试 :2016-07-22, 5d section 发布验收 发布: 2d 验收: 3d 更多语法参考：甘特图语法参考 10. Mermaid 流程图 A[Hard edge] -->|Link text| B(Round edge) B --> C{Decision} C -->|One| D[Result one] C -->|Two| E[Result two] 更多语法参考：Mermaid 流程图语法参考 11. Mermaid 序列图 Alice->John: Hello John, how are you? loop every minute John-->Alice: Great! end 更多语法参考：Mermaid 序列图语法参考 12. 表格支持 项目 价格 数量 计算机 $1600 5 手机 $12 12 管线 $1 234 13. 定义型列表 名词 1 : 定义 1（左侧有一个可见的冒号和四个不可见的空格） 代码块 2 : 这是代码块的定义（左侧有一个可见的冒号和四个不可见的空格） 代码块（左侧有八个不可见的空格） 14. Html 标签 本站支持在 Markdown 语法中嵌套 Html 标签，譬如，你可以用 Html 写一个纵跨两行的表格： 值班人员 星期一 星期二 星期三 李强 张明 王平 值班人员 星期一 星期二 星期三 李强 张明 王平 15. 内嵌图标 本站的图标系统对外开放，在文档中输入 即显示微博的图标： 替换 上述 i 标签 内的 icon-weibo 以显示不同的图标，例如： 即显示人人的图标： 更多的图标和玩法可以参看 font-awesome 官方网站。 16. 待办事宜 Todo 列表 使用带有 [ ] 或 [x] （未完成或已完成）项的列表语法撰写一个待办事宜列表，并且支持子列表嵌套以及混用Markdown语法，例如： - [ ] **Cmd Markdown 开发** - [ ] 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率 - [ ] 支持以 PDF 格式导出文稿 - [x] 新增Todo列表功能 [语法参考](https://github.com/blog/1375-task-lists-in-gfm-issues-pulls-comments) - [x] 改进 LaTex 功能 - [x] 修复 LaTex 公式渲染问题 - [x] 新增 LaTex 公式编号功能 [语法参考](http://docs.mathjax.org/en/latest/tex.html#tex-eq-numbers) - [ ] **七月旅行准备** - [ ] 准备邮轮上需要携带的物品 - [ ] 浏览日本免税店的物品 - [x] 购买蓝宝石公主号七月一日的船票 对应显示如下待办事宜 Todo 列表： [ ] Cmd Markdown 开发 [ ] 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率 [ ] 支持以 PDF 格式导出文稿 [x] 新增Todo列表功能 语法参考 [x] 改进 LaTex 功能 [x] 修复 LaTex 公式渲染问题 [x] 新增 LaTex 公式编号功能 语法参考 [ ] 七月旅行准备 [ ] 准备邮轮上需要携带的物品 [ ] 浏览日本免税店的物品 [x] 购买蓝宝石公主号七月一日的船票 footnote. 这是一个 注脚 的 文本。 ↩ footnote2. 这是另一个 注脚 的 文本。 ↩ var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:39 "},"blog/cpp/":{"url":"blog/cpp/","title":"cpp","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"blog/cpp/note-on-c++0x-simplify-grammar.html":{"url":"blog/cpp/note-on-c++0x-simplify-grammar.html","title":"C++0x学习之简洁语法","keywords":"","body":"C++0x学习之简洁语法 模块尖括号 list> lvs;可以正确解析了，不用再这样写了：list > lvs;(注意> >之间的空格)。 循环迭代器 迭代器遍历更方便的写法，想到 foreach了吗？ void f(vector& v) { for (auto x : v) cout 初始化列表 初始化列表可以是任意长度，但必须是同质的（所有的元素必须属于某一模板类型T, 或可转化至T类型的)，内部使用了 initializer_list。仅具有一个 std::initializer_list 的单参数构造函数被称为初始化列表构造函数。 vector> languages = { {\"Nygaard\",\"Simula\"}, {\"Richards\",\"BCPL\"}, {\"Ritchie\",\"C\"} }; map,vector> years = { { {\"Maurice\",\"Vincent\", \"Wilkes\"},{1913, 1945, 1951, 1967, 2000} }, { {\"Martin\", \"Ritchards\"}, {1982, 2003, 2007} }, { {\"David\", \"John\", \"Wheeler\"}, {1927, 1947, 1951, 2004} } }; vector v1(7); // 正确: v1有7个元素 v1 = 9; // 错误: 无法将int转换为vector vector v2 = 9; // 错误: 无法将int转换为vector vector> vs = { vector(10), // 正确: 显式构造（10个元素，值为double的默认值） vector{10}, // 正确：显式构造（1个元素，值为10） 10 // 错误 ：vector的构造函数是显式的 }; nullptr：空指针标识 char* p = nullptr; int* q = nullptr; char* p2 = 0; // 这里 0 的赋值还是有效的，并且 p == p2 void g(int); g(nullptr); // 错误：nullptr 并不是一个整型常量 int i = nullptr; // 错误：nullptr 并不是一个整型常量 统一初始化的语法和语义 看下面的代码，是函数声明还是变量定义，你搞晕了吧！ int a(1); // 变量定义 int b(); // 函数声明 int b(foo); // 变量定义或函数声明都有可能 c++0x中统一可以通过 {} 初始化 X x1 = X{1,2}; X x2 = {1,2}; // the = is optional X x3{1,2}; X* p = new X{1,2}; 这样也可以： X x{a}; X* p = new X{a}; z = X{a}; // 使用了类型转换 f({a}); // 函数的实际参数（X类型的） return {a}; // 函数的返回值（函数返回类型为X） 原生字符串标识 为了转义字符，看了这个估计要崩溃了吧： \"('(?:[^\\\\\\\\']|\\\\\\\\.)*'|\\\"(?:[^\\\\\\\\\\\"]|\\\\\\\\.)*\\\")|\" // 这五个反斜杠是否正确? 现在可以这样写原生字符串了（R\"PATTERN(\" 和 \")PATTERN\" 之间为实际字符串， PATTERN 为自定义标识符，为什么不来 here document 呢？）： R\"(\"quoted string\")\" // 字符串为 \"quoted string\" // 字符串为 \"quoted string containing the usual terminator (\")\" R\"***(\"quoted string containing the usual terminator (\")\")***\" Lambdas vector [] 是一个“捕捉列表(capture list)”，即调用lambda所在函数的变量。不使用则为 []；使用引用则为[&]；传值则为[=]。下面例子： void f(vector& v) { vector 如果一个函数的行为既不一般也不简单，最好使用具名函数或函数对象。如： void f(vector& v) { vector& vr; Cmp_names(const vector& r) :vr(r) { } bool operator()(int a, int b) const { return vr[a].name var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"blog/cpp/note-on-c++0x-type-deduction.html":{"url":"blog/cpp/note-on-c++0x-type-deduction.html","title":"C++0x 学习之类、函数","keywords":"","body":"C++0x 学习之类、函数 控制默认函数：默认或者禁用 还记得如何禁止拷贝构造函数和赋值函数么？ C++98 中，你可能这样写: // A macro to disallow operator= // This should be used in the private: declarations for a class. #define GTEST_DISALLOW_ASSIGN_(type)\\ void operator=(type const &) // A macro to disallow copy constructor and operator= // This should be used in the private: declarations for a class. #define GTEST_DISALLOW_COPY_AND_ASSIGN_(type)\\ type(type const &);\\ GTEST_DISALLOW_ASSIGN_(type) c++0x 中可以明确指出来： class X { // ... X& operator=(const X&) = delete; // 禁用拷贝构造函数 X(const X&) = delete; }; class Y { // ... Y& operator=(const Y&) = default; // 使用默认赋值函数 Y(const Y&) = default; }; 控制默认函数:移动(move)或者复制(copy) 在默认情况下，一个类拥有 5 个默认函数或操作符： 拷贝赋值操作符（copy assignment） 拷贝构造函数（copy constructor） 移动赋值操作符（move assignment） 移动构造函数（move constructor） 析构函数（destructor） 如果显式地指明（声明，定义，=default，或者 =delete）了移动、复制或者析构函数，将不会产生默认的移动操作（移动赋值操作符和移动构造函数），同时未声明的复制操作（复制赋值操作符和复制构造函数）也会被默认生成。 如果声明了上述 5 个默认函数中的任何一个，强烈建议你显式地声明所有这 5 个默认函数。 template class Handle { T* p; public: // 构造函数 Handle(T* pp) : p{pp} { } // 用户定义析构函数，没有隐式的复制和移动操作 ~Handle() { delete p; } // 转移构造函数，传递所有权 Handle(Handle&& h) :p{h.p} { h.p=nullptr; }; // 转移赋值函数，传递所有权 Handle& operator=(Handle&& h) { delete p; p=h.p; h.p=nullptr; return *this; } // 拷贝构造函数 Handle(const Handle&) = delete; // 拷贝赋值函数 Handle& operator=(const Handle&) = delete; // ... }; 右值引用 左值（赋值操作符“=”的左侧，通常是一个变量）与右值（赋值操作符“=”的右侧，通常是一个常数、表达式、函数调用）。在 C++ 中，左值可被绑定到 const 或非 const 引用；右值只能绑定到 const 引用。是为了防止人们修改临时变量的值，这些临时变量在被赋予新的值之前，都会被销毁。&& 表示“右值引用”。右值引用可以绑定到右值（但不能绑定到左值）： X a; X f(); X& r1 = a; // 将r1绑定到a(一个左值) X& r2 = f(); // 错误：f()的返回值是右值，无法绑定 X&& rr1 = f(); // 正确：将rr1绑定到临时变量 X&& rr2 = a; // 错误：不能将右值引用rr2绑定到左值a move(x) 意味着“你可以把x当做一个右值” template void swap(T& a, T& b) // \"perfect swap\" (almost) { T tmp = move(a); // could invalidate a a = move(b); // could invalidate b b = move(tmp); // could invalidate tmp } 委托构造函数 c++0x中构造函数可以互相调用了，如： class X { int a; public: X(int x) { if (0(s)} { } // ... }; 类成员的内部初始化 现在也允许非静态（non-static）数据成员在其声明处（在其所属类内部）进行初始化。这样，在运行过程中，需要初始值时构造函数可以使用这个初始值。如果一个成员同时在类内部初始化时和构造函数内被初始化，则只有构造函数的初始化有效（这个初始化值“优先于”默认值），示例如下： class A { public: A() {} A(int a_val) : a(a_val) {} A(D d) : b(g(d)) {} int a = 7; int b = 5; private: HashingFunction hash_algorithm{\"MD5\"}; // Cryptographic hash to be applied to all A instances std::string s{\"Constructor run\"}; // String indicating state in object lifecycle }; 继承的构造函数 c++0x中可以直接继承基类的构造函数了。如下例所示： class Derived : public Base { public: // 提升Base类的f函数到Derived类的作用范围内 // 这一特性已存在于C++98标准内 using Base::f; void f(char); // 提供一个新的f函数 void f(int); // 与Base类的f(int)函数相比更常用到这个f函数 // 提升Base类的构造函数到Derived的作用范围内 // 这一特性只存在于C++11标准内 using Base::Base; Derived(char); // 提供一个新的构造函数 // 与Base类的构造函数Base(int)相比 // 更常用到这个构造函数 Derived(int); // ... }; 注意，如果子类有父类没有的变量，该如何初始化呢？可以借助“类成员的内部初始化” struct D1 : B1 { using B1::B1; // 隐式声明构造函数D1(int) int x{0}; // 注意：x变量已经被初始化 }; void test() { D1 d(6); // d.x的值是 0 } 重写(override)的控制 在 C++11 中，可以使用新的 override 关键字，来让程序员可以更加明显地表明他对于重写的设计意图，增加代码的可读性。 struct B { virtual void f(); virtual void g() const; virtual void h(char); void k(); // 非虚函数 }; struct D : B { void f() override; // 正确: 重写 B::f() void g() override; // 错误: 不同的函数声明，不能重写 virtual void h(char); // 重写 B::h(char); 可能会有警告 void k() override; // 错误: B::k() 不是虚函数 }; 有时候，可能想要阻止某个虚函数被重写，在这种情况下，他可以为虚函数加上final关键字来达到这个目的。例如： struct B { virtual void f() const final; // 不能重写 virtual void g(); // 没有final关键字，可以重写 }; struct D : B { void f() const; // 错误: D::f尝试重写final修饰的B::f会产生编译错误 void g(); // OK }; var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"blog/cpp/google-c++-note.html":{"url":"blog/cpp/google-c++-note.html","title":"google c++代码规范分享","keywords":"","body":"Google C++ 代码规范笔记 和同事分享的 google c++ 代码规范 ppt，不得不说，做 ppt 很耗费经历，beamer + xelatex 确实给力。 PPT传送门 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"blog/cpp/c++-vector.html":{"url":"blog/cpp/c++-vector.html","title":"一次 C++ vector 的误用","keywords":"","body":"一次 C++ vector 的误用 最近在项目中用到了很多这样的结构：有很多记录放在一个 vector 中，然后对这些记录建立了一些索引放在 map 中，大概结构如下： std::vector records; std::map index; 构建数据的时候，大概流程如下： Record record; while (getRecord(&record)) { records.push_back(record); Key key = makeKey(record); index[key] = &record; } 错了，最后一句应该取 vector 中最后一个元素的地址，而不是变量 record 的地址。修改程序如下： Record record; while (getRecord(&record)) { records.push_back(record); Key key = makeKey(record); index[key] = &(*records.rbegin()); } 结果运行的时候还是出错了。诡异的是，构建完索引后，打印索引里的 record 指针地址，竟然和原始的 vector 地址不一样，如果在循环中打印各个记录的地址，已经变了。 原因呢也很简单，但需要对 vector 的内部实现稍微有点了解—— vector 是如何分配内存的，当 vector push_back 新元素，但内部空间不够使用时， vector 会 realloc 新内存，然后将原有的元素拷贝过去，内存分配以 2 的次幂分配，第一次是 2^0 元素，第二次为 2^1 个，第三次为 2^2，这个可以通过调用 std::vector::capacity() 来验证。知道这些，有两个办法可以修复上述 bug。 1) 根据 records 最大数量，预先给 vector reserve 一段内存，确保 vector 不会重新分配内存。 records.reserve(MAX_RECORD_NUM); Record record; while (getRecord(&record)) { records.push_back(record); Key key = makeKey(record); index[key] = &(*records.rbegin()); } 2) 构建完 vector 之后，再构建索引，注意：如果之后 vector 还会插入新纪录，index 还会失效，幸运的是，我们的程序构建完 vector 后就不会新增加元素了。 Record record; while (getRecord(&record)) { records.push_back(record); } for (auto iter = records.begin(); iter != records.end(); ++iter) { Key key = makeKey(*iter); index[key] = &(*iter); } 附录 与 vector 的 size 相关的函数： size() 返回当前 vector 中的元素个数 capacity() 放回当前 vector 内存空间可以元素数量 reserve(size_type n) 分配至少可以存放 n 元素的空间 resize(size_type n, value_type val = value_type()) 将当前 vector 的元素数置为 n， 多删少补 shrink_to_fit() C++11 新增 将 vector 占用的内存数 降低到和 size 数一致 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"blog/cpp/gcc-inline-assembly.html":{"url":"blog/cpp/gcc-inline-assembly.html","title":"从CAS到内嵌汇编","keywords":"","body":"从CAS到内嵌汇编 引子 从博文《无锁队列的实现》里知道了 CAS（Compare & Set，或是 Compare & Swap)，Compare & Swap为例，用C语言描述如下： int compare_and_swap(int* reg, int oldval, int newval) { int old_reg_val = *reg; if (old_reg_val == oldval) *reg = newval; return old_reg_val; } compare_and_swap 看一看内存 *reg 里的值是不是 oldval，如果是的话，则对其赋值 newval，返回 *reg 的旧值。但该操作到底如何实现的，为什么是原子操作，就不得而知了，后来在 Preshing on Programming、Nginx等好几处又看到这个操作，于是有了“求甚解”的想法，大多数实现都用了嵌入式汇编，于是趁机学习了一下 gcc 的嵌入式汇编。特整理一下，所谓好记性不如烂笔头。 CAS 实现 先看 nginx 的 CAS 代码： static ngx_inline ngx_atomic_uint_t ngx_atomic_cmp_set(ngx_atomic_t *lock, ngx_atomic_uint_t old, ngx_atomic_uint_t set) { u_char res; __asm__ volatile ( // line 1 \" lock; \" // line 2 \" cmpxchgl %3, %1; \" // line 3 \" sete %0; \" // line 4 : \"=a\"(res) // line 5 : \"m\"(*lock), \"a\"(old), \"r\"(set) // line 6 : \"cc\", \"memory\"); // line 7 return res; } 首先说说两个汇编指令。第2行的 lock 指令，intel 手册上的解释是： Causes the processor's LOCK# signal to be asserted during execution of the accompanying instruction (turns the instruction into an atomic instruction). In a multiprocessor environment, the LOCK# signal insures that the processor has exclusive use of any shared memory while the signal is asserted. 意思是 lock 将其后续的指令变为一个原子指令，也就是将下面的指令 cmpxchgl 变为原子操作。而 cmpxchgl 所做动作大概是： /** * accumulator = AL, AX, or EAX, depending on whether * a byte, word, or doubleword comparison is being performed */ if(accumulator == Destination) { F = 1; Destination = Source; } else { ZF = 0; accumulator = Destination; } 第4行中 sete cl 是设置指令，根据 zf(zero flags) 标志位来设置 cl 的值。即是如果 zf=1，则 cl 等于 1，否则等于 0。 综合一下上述两条指令，如果 cmpxchgl 更新了 *reg 的值， ngx_atomic_cmp_set 返回1，否则返回 0。 到现在也只明白了几条汇编指令而已，到底参数是怎么传进去，结果又怎么传出来呢？ 嵌入汇编 下面简单介绍一下 gcc 嵌入汇编。 最基本的嵌入汇编是这样的 asm(\"assembly code\");（注意 AT&T 的汇编语法），如： asm(\"movl %ecx %eax\"); /* moves the contents of ecx to eax */ __asm__(\"movb %bh (%eax)\"); /*moves the byte from bh to the memory pointed by eax */ 其中， asm 和 __asm__ 都是有效的，后者是为了防止关键字冲突。如果我们需要使用一条以上的汇编指令, 每条指令占用一行, 用双引号括起，并加上\\n和\\t后缀. 这是因为gcc把用字符串的格式把汇编指令传给as(GAS), 利用换行符转换成正确的汇编格式。举例如下： __asm__ (\"movl %eax, %ebx\\n\\t\" \"movl $56, %esi\\n\\t\" \"movl %ecx, $label(%edx,%ebx,$4)\\n\\t\" \"movb %ah, (%ebx)\"); 对于复杂的，有输入、输出的嵌入汇编，需要使用扩展模式，刚才的CAS的嵌入式汇编就属于这种情况。扩展模式格式如下： asm(\"statement\" : output_reg(output_variable), /* optional */ : input_reg(intpu_variable), /* optional */ : colbbered_args); /* optional */ 回到最初的代码，从第6行的入参说起，\"m\"(*lock), \"a\"(old), \"r\"(set) 表示有三个输入参数，每一个入参都以这样的形式出现：\"constraint\"(variable)（限制 变量）。 m 表示 *lock是一个内存操作对象， a 表示 old 需要放到寄存机 eax 中， r 表示 gcc 可以自己决定使用哪个寄存器保存变量 set。限制 a，b，c，d，S，D，r 分别表示 eax，ebx，ecx，edx，esi，edi，Register(s)。 r 首先将操作数保存在寄存器内，然后在寄存器里进行数据操作，接着把数据写回内存区域。与 r 限制符不同，限制符 m 后的操作数放在内存中，任何对它们的操作都会直接更改内存值。 第5行中，\"=a\"(res) 是输出参数，即将 eax 的值保存到变量 res 中。=表示此操作数类型是只写，之前的值会被输出数据值替代。除了 = 限制符，还有 & 限制符，表示此操作数是一个很早更变的（earlyclobber）操作数。在汇编指令使用所有入参之前， & 修饰的操作数就会发生变化（详细见关于 & 的解释部分）。 回到第3、4行，操作数 %N，其中 N = 0,1,2,...，表示依次出现的输入、输出参数，本例中 %0 为 \"=a\"(res)， %1 为 \"m\"(*lock)， %3 为 \"r\"(set)。如果在汇编指令的操作数中使用寄存器，需要用两个%，如 movl %1, %%eax。 还有一种数字限制符，如： asm (\"incl %0\" :\"=a\"(var): \"0\"(var));, \"0\"(var)表示 var 将与第0个操作数使用相同的寄存器，这样输入输出使用了相同的寄存器 eax。更多的常用限制符可以参考这里。 第7行， cc 表示汇编代码将改变条件寄存器，memory 表示有内存被修改，我们需要将指令改变的寄存器放到 clobbered args 列表中，但不需要将输入、输出用到的寄存器放入其中。如果之前的汇编指令修改了 eax，而输入输出中没使用 eax， 则在 clobbered args 列表中加上 \"a\"。 第1行中的 volatile 表示每行汇编代码必须按给的次序执行。如果没有 volatile，编译器可能会对汇编代码做一些优化。对于常见的没有副作用的计算操作，不需要使用 volatile。 到这里，读懂 CAS 嵌入的汇编已经不成问题了。 关于 & 的解释 这是一个较常见用于输出的限定符，它告诉gcc输出操作数使用的寄存器不可再让输入操作数使用。对于 \"g\"，\"r\" 等限定符，为了有效利用为数不多的几个通用寄存器，gcc一般会让输入操作数和输出操作数选用同一个寄存器。但如果代码没编好，会引起 一些意想不到的错误。例如： asm(\"call fun;mov ebx,%1\":\"=a\"(foo):\"r\"(bar)); gcc 编译的结果是 foo 和 bar 同时使用 eax 寄存器： movl bar,eax #APP call fun movl ebx,eax #NO_APP movl eax,foo 本来这段代码的意图是将 fun() 函数的返回值放入 foo 变量，但半路杀出个程咬金，用 ebx 的值冲掉了返回值，所以这是一段错误的代码，解决的方法是输出操作数加上一个 \"&\" 限定符： asm(\"call fun;mov ebx,%1\":\"=&a\"(foo):\"r\"(bar)); 这样 gcc 就会让输入操作数另寻高就，不再使用 eax 寄存器了。 其他例子 两个数的加法 int main(void) { int foo = 10, bar = 15; __asm__ __volatile__(\"addl %%ebx,%%eax\" :\"=a\"(foo) :\"a\"(foo), \"b\"(bar)); printf(\"foo+bar=%d\\n\", foo); return 0; } 读取时间标签计数器 static __inline__ unsigned long long rdtsc(void) { unsigned hi, lo; __asm__ __volatile__ (\"rdtsc\" : \"=a\"(lo), \"=d\"(hi)); return ((unsigned long long)lo) | (((unsigned long long)hi) string copy static inline char* strcpy(char* dest, const char* src) { int d0, d1, d2; __asm__ __volatile__(\"1:\\tlodsb\\n\\t\" \"stosb\\n\\t\" \"testb %%al,%%al\\n\\t\" \"jne 1b\" : \"=&S\"(d0), \"=&D\"(d1), \"=&a\"(d2) : \"0\"(src), \"1\"(dest) : \"memory\"); return dest; } 参考资料 gcc 手册 gcc 嵌入汇编 gcc中的内嵌汇编语言 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"blog/cpp/tuxedo-tuning-with-gprof.html":{"url":"blog/cpp/tuxedo-tuning-with-gprof.html","title":"Tuxedo性能调优之使用gprof","keywords":"","body":"Tuxedo性能调优之使用gprof 一个 tuxedo 应用系统的整体性能往往是由很多方面决定的，操作系统、网络、数据库、以及应用系统的设计，程序的编写水平都会影响该 tuxedo 应用系统的性能。当性能不好时,主要表现在对客户段的请求响应很慢。这时，如果用 tmadmin 中的 pq 命令察看，会发现有较多的请求在排队。 如何确认应用程序的瓶颈是性能调优的关键，也是难点。对于一个程序，如果可以知道每个函数的调用次数，调用时间，无疑会指引系统调优的方向。本文将介绍如何使用gprof查看tuxedo服务进程的函数调用情况，包括调用次数、调用时间、函数调用关系图等等。 gprof 是 GNU profiler 工具。基本用法如下： 使用 -pg 选项编译和链接你的应用程序。 执行你的应用程序，使之运行完成后生成供 gprof 分析的数据文件（默认是gmon.out）。 使用 gprof 程序分析你的应用程序生成的数据，例如：gporf a.out gmon.out。 关于 gprof 的详细用法可以 google，有很多信息，这里不再赘述。 对于一个 tuxedo 程序，一般会编写很多 .cpp 文件，生成相应的 .o 文件，最后使用 buildserver 命令生成可执行文件。你会想在编译 .cpp 文件产生 .o 文件时，为编译器(系统为 linux 环境，编译器为 gcc)提供 -pg 选项，再使用 buildserver，但在 tmshutdown 服务进程之后，并没有发现 gmon.out 文件产生。为什么？ 原来 gprof 只能在程序正常结束退出之后才能生成程序测评报告，原因是 gprof 通过在 atexit() 里注册一个函数来产生结果信息，任何非正常退出都不会执行 atexit() 的动作，所以不会产生 gmon.out 文件。如果你的程序是一个不会退出的服务程序，那就只有修改代码来达到目的。如果不想改变程序的运行方式，可以添加一个信号处理函数解决问题（这样对代码修改最少），例如： #include #include static void catch_term(int sig_no) { exit(0); } int main() { signal(SIGTERM, catch_term); // 以下是原来的代码 } 当使用 kill -TERM pid 后，程序退出，生成 gmon.out 文件。 问题又来了，在 tuxedo 程序中，你只编写了应用服务的代码，并没有编写main函数，也就是说，buildserver 命令在编译时对你的代码做了一些手脚，查看 buildserver 帮助文档，可以看到使用 -v 选项可以详细显示 buildserver 的编译过程，使用这个选项可以容易看出 buildserver 实际上使用 gcc 来生成可执行文件，并添加了 tuxedo 相应的链接库，而且可以看到一个你没写过的 xxx.c，编译之后，这个 xxx.c 文件却消失了。 问题就在这，这个 xxx.c 文件中包含着 main 函数，buildserver 使用 -k 选项可以保留这个 xxx.c 文件而不被删除。在生成 xxx.c 后，按上面的方法注册一个 TERM 信号处理方法。此时不再用 buildserver 生成可执行文件，而是使用 buildserver -v 实际调用 gcc 的命令来生成可执行文件。 当你使用 tmshutdown –s server –k TERM (使用 TERM 信号结束程序)，还是没有产出 gmon.out，原因是在链接时 gcc 没有使用 -pg 选项；使用 -pg 选项重新编译链接程序，启动、结束服务程序后，终于看到久违的 gmon.out 文件了。 啊哈，现在可以查看运行的结果了。 参考资料： http://download.oracle.com/docs/cd/E13203_01/tuxedo/tux80/atmi/rfcmd8.htm http://forums.oracle.com/forums/thread.jspa?threadID=815390&tstart=2164 http://apps.hi.baidu.com/share/detail/2292841 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"blog/linux/":{"url":"blog/linux/","title":"linux","keywords":"","body":"var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"blog/linux/about_io.html":{"url":"blog/linux/about_io.html","title":"关于IO的基本概念","keywords":"","body":"关于IO的基本概念 同步、异步、阻塞、非阻塞 对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。当一个read操作发生时，它会经历两个阶段： 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) 基本概念 阻塞：调用者因期待的某些事件（如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等）未发生，会被挂起（投入到睡眠状态，直到数据可用时被唤醒），CPU会调度别的进程（线程）工作； 同步：发起IO请求的线程不从正在调用的IO操作函数返回（即被阻塞，第2步过程中肯定阻塞）； 异步：发起IO请求的线程不等IO操作完成，就继续执行随后的代码，IO结果用其他方式通知发起IO请求的程序； 如下图所示，对unix来讲：阻塞式I/O(默认)、非阻塞式I/O(nonblock)、I/O复用(select/poll/epoll)都属于同步I/O ，因为它们在数据由内核空间复制回进程缓冲区时都是阻塞的(不能干别的事)。只有异步I/O模型(AIO)是符合异步I/O操作的含义的，即在1数据准备完成、2由内核空间拷贝回缓冲区后通知进程，在等待通知的这段时间里可以干别的事。 多路复用I/O模型 由于非阻塞调用的过程中，论询占据了大部分的过程，所以论询会占据大量的CPU时间。如果论询不是进程的用户态，而是有人帮忙就好了。多路复用正好处理这样的问题。 I/O多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。 IO多路复用适用如下场合： 当客户处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用。 两种I/O多路复用模式：Reactor 和 Proactor，Reactor模式采用同步 IO，而Proactor采用异步 IO，异步情况下(Proactor)，当回调handler时，表示IO操作已经完成；同步情况下(Reactor)，回调handler时，表示IO设备可以进行某个操作(can read or can write)。 select int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。 select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。 select的缺点： 在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样也会造成效率的降低。 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低。当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。这会浪费很多CPU时间。 需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。 poll int poll (struct pollfd *fds, unsigned int nfds, int timeout); struct pollfd { int fd; /* file descriptor */ short events; /* requested events to watch */ short revents; /* returned events witnessed */ }; 不同与select使用三个位图来表示三个fdset的方式，poll使用一个pollfd的指针实现。pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制，原因是它是基于链表来存储的，但是数量过大后性能也是会下降。和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。 poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。 poll的缺点： 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。 poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。 epoll epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。epoll的优点： 没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）。 效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，epoll的效率就会远远高于select和poll。 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 epoll操作过程 epoll操作过程需要三个接口，分别如下： int epoll_create(int size); //创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); struct epoll_event { __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ }; int epoll_create(int size); 创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。 在linux 2.6.8之前的内核，epoll使用hash来组织fds集合，于是在创建epoll fd的时候，epoll需要初始化hash的大小。于是epoll_create(int size)有一个参数size，以便内核根据size的大小来分配hash的大小。在linux 2.6.8以后的内核中，epoll使用红黑树来组织监控的fds集合，所以参数size实际上已经没有意义了。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); 函数是对指定描述符fd执行op操作。 epfd：是epoll_create()的返回值。 op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。 fd：是需要监听的fd（文件描述符） epoll_event：是告诉内核需要监听什么事，events可以是以下几个宏的集合： EPOLLIN：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）； EPOLLOUT：表示对应的文件描述符可以写； EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）； EPOLLERR：表示对应的文件描述符发生错误； EPOLLHUP：表示对应的文件描述符被挂断； EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。 EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里 int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 等待epfd上的io事件，最多返回maxevents个事件。 events用来从内核得到事件的集合， maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size， timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞） 该函数返回需要处理的事件数目，如返回0表示已超时。 epoll工作模式 主要实现逻辑： epoll引入了一个中间层，一个双向链表ready_list，一个单独的睡眠队列single_epoll_wait_list。 Process（应用）只是插入到中间层的epoll的单独睡眠队列中（即single_epoll_wait_list），Process睡眠在epoll的单独队列上，等待事件的发生。 同时引入一个中间的wait_entry_sk，wait_entry_sk睡眠在socket的睡眠队列上，其callback函数逻辑是将当前socket排入到epoll的ready_list中，并唤醒epoll的single_epoll_wait_list。 single_epoll_wait_list上睡眠的Process的回调函数：遍历ready_list上的所有socket，挨个调用socket的poll函数收集事件，然后唤醒Process从epoll_wait返回。 epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下： LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。 ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。 LT模式 LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。 ET模式 ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once) ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 小结 表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。 select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善。 如果没有大量的idle-connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle-connection，就会发现epoll的效率大大高于select/poll。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"blog/linux/quote-marks-in-bash.html":{"url":"blog/linux/quote-marks-in-bash.html","title":"bash 里面的引号","keywords":"","body":"bash 里面的引号 单引号' ' 目的: 为了保护文字不被转换.除了他本身. 就是说除去单引号外, 在单引号内的所有文字都是原样输出. echo '$*>输出：$*> echo 'she is crying: \"help\"' 输出：she is crying: \"help\" echo '\\\\\\\\' 输出：\\\\ echo 'hah 'test'' 输出：hah test # 略去了所有' echo ' today is `date`' 输出：today is date # 反引号在此无法实现函数功能. 双引号\" \" 目的: 为了包含文字或者函数段. 除了本身,反引号内的函数,$开头的变量和\\开头反转换的字符外, 其余都是直接输出. echo \"today is `date`\" 输出：today is Fri Jul 4 08:03:34 GMT 2008 echo \"today is 'date'\" 输出：today is 'date'# 直接输出单引号 echo \"\\\\\\\\\" 输出：\\ echo \"test \"test\"\" 输出：test test 反引号 目的: 是为了在双引号内保持函数转换. 但单引号内其无作用. echo \"today is `date`\" 输出：today is Fri Jul 4 08:03:34 GMT 2008 echo ' today is `date` ' 输出：today is date # 在单引号内无作用. 附 如何输出 abc'abc echo 'abc'\\''abc' echo -e 'abc\\x27abc' echo $'abc\\'abc' # bash特有 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"blog/linux/delete-carriage-return.html":{"url":"blog/linux/delete-carriage-return.html","title":"删除 Linux 中的 ^M","keywords":"","body":"删除Linux中的^M 很久以前，老式的电传打字机使用两个字符来另起新行。一个字符把滑动架移回首位（称为回车 CR ），另一个字符把纸上移一行（称为换行 LF ）。当计算机问世以后，存储器曾经非常昂贵。有些人就认定没必要用两个字符来表示行尾。 UNIX 开发者决定他们可以用一个字符来表示行尾，Linux 沿袭 Unix，也是 =\\n= 。 Apple 开发者规定了用 =\\r= 开发 MS-DOS 以及 Windows 的那些家伙则决定沿用老式的。 三种行尾格式如下: 系统 名称 转义 ASCII mac 回车 =\\r= 0xa unix 换行 =\\n= 0xd dos 回车换行 =\\r\\n= 0xa0xd 这意味着，如果你试图把一个文件从一种系统移到另一种系统，那么你就有换行符方面的麻烦。 因为 MS-DOS 及 Windows 是回车＋换行来表示换行，因此在 Linux 下查看在 Windows 下写的代码， 行尾 ^M 符号，可用以下命令查看： cat -A filename , vi 中可以 :set list 在 Vim 中解决这个问题，很简单，在 Vim 中利用替换功能就可以将 ^M 都删掉， 键入如下替换命令 :%s/^M//g 或者 :%s/\\r//g 。 注意：上述命令行中的 ^M 由 C-v C-M 生成。 或者使用这个命令: dos2unix filename 或者 sed -i 's/^M//g' filename # 注意：^M的输入方式是 Ctrl + v ，然后Ctrl + M 或者 cat filename | tr -d '\\r' > newfile #^M 可用 \\r 代替 Emacs 中替换 C-x RET c undecided-unix RET C-x C-w RET y M-S 注意上面的 C-q C-m 就是换行符的生成方法，而不是简单的输入 ^M var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"blog/linux/linux-core.html":{"url":"blog/linux/linux-core.html","title":"Linux Core 基础","keywords":"","body":"Linux Core 基础 开启 ulimit -a 可以检查生成core文件的选项是否打开，该命令将显示所有的用户定制，其中选项 -a 代表 all 。也可以修改系统文件来调整 core 选项，在 /etc/profile 通常会有这样一句话来禁止产生 core 文件 ulimit -c 0 。 在开发过程中为了调试问题，需要在特定的用户环境下打开 core 文件产生的设置，可在用户的 ~/.bash_profile 里加上 ulimit -c unlimited 让特定的用户可以产生 core 文件；而 ulimit -c 1024 则限制产生的 core 文件的大小不能超过 1024kb。 命名 /proc/sys/kernel/core_uses_pid : 控制产生的 core 文件的文件名中是否添加 pid 作为扩展，如果添加则文件内容为 1 ，否则为 0 /proc/sys/kernel/core_pattern : 设置格式化的 core 文件保存位置或文件名 core 文件会存放到 /corefile 目录下，产生的文件名为\"core-命令名-pid-时间戳\"： echo \"/corefile/core-%u-%e-%p-%t\" > /proc/sys/kernel/core_pattern 参数列表： 参数 说明 %p insert pid into filename 添加pid %u insert current uid into filename 添加当前uid %g insert current gid into filename 添加当前gid %s insert signal that caused the coredump into the filename 信号 %t insert UNIX time that the coredump occurred into filename 时间 %h insert hostname where the coredump happened into filename 主机名 %e insert coredumping executable name into filename 命令名 使用 使用 gdb -c core 来调试 core 文件，会显示生成此 core 文件的程序名，中止此程序的信号等。如果已经知道是什么程序生成此 core 文件的，比如 MyServer 崩溃了生成 core.12345，那么用此指令调试: gdb -c core MyServer 。 测试 直接输入指令: kill -s SIGSEGV var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"blog/linux/crontab.html":{"url":"blog/linux/crontab.html","title":"Linux 计划任务 crontab","keywords":"","body":"linux计划任务crontab Cron is a time-based job scheduler in Unix-like computer operating systems. The name cron comes from the world chronograph(a time-piece). crontab 配置格式如下： .----------- minute (0 - 59) | .--------- hour (0 - 23) | | .------- day of month (1 - 31) | | | .----- month (1 - 12) OR jan,feb,mar,apr … | | | | .--- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat | | | | | * * * * * command to be executed 必须使用的一则技巧：每条 JOB 执行完毕之后，系统会自动将输出发送邮件给当前系统用户。日积月累，非常的多，甚至会撑爆整个系统。所以每条 JOB 命令后面进行重定向处理是非常必要的： >/dev/null 2>&1 。前提是对 Job 中的命令需要正常输出已经作了一定的处理, 比如追加到某个特定日志文件。 1.直接用 crontab 命令编辑 cron 服务提供 crontab 命令来设定 cron 服务的，以下是这个命令的一些参数与说明： crontab -u // 设定某个用户的cron 服务，一般 root 用户在执行这个命令的时候需要此参数 crontab -l // 列出某个用户 cron 服务的详细内容 crontab -r // 删除没个用户的 cron 服务 crontab -e // 编辑某个用户的 cron 服务 比如说root查看自己的cron设置： crontab -u root -l 再例如，root想删除fred的cron设置： crontab -u fred -r 在编辑cron服务时，编辑的内容有一些格式和约定，输入： crontab -u root -e 进入vi编辑模式，编辑的内容一定要符合下面的格式： */1 * * * * ls >> /tmp/ls.txt 这个格式的前一部分是对时间的设定，后面一部分是要执行的命令，如果要执行的命令太多，可以把这些命令写到一个脚本里面，然后在这里直接调用这个脚本就可以了，调用的时候记得写出命令的完整路径。时间的设定我们有一定的约定，前面五个*号代表五个数字，数字的取值范围和含义如下： 分钟　（0-59） 小時　（0-23） 日期　（1-31） 月份　（1-12） 星期　（0-6）//0代表星期天 除了数字还有几个个特殊的符号就是“*”、“/”和“-”、“,”，*代表所有的取值范围内的数字，“/”代表每的意思,“*/5”表示每5个单位，“-”代表从某个数字到某个数字,”,”分开几个离散的数字。以下举几个例子说明问题： 每天早上6点 0 6 * * * echo “Good morning.” >> /tmp/test.txt //注意单纯echo，从屏幕上看不到任何输出，因为 cron 把任何输出都 email 到 root 的信箱了。 每两个小时 0 */2 * * * echo “Have a break now.” >> /tmp/test.txt 晚上11点到早上8点之间每两个小时，早上八点 0 23-7/2，8 * * * echo “Have a good dream：）” >> /tmp/test.txt 每个月的4号和每个礼拜的礼拜一到礼拜三的早上11点 0 11 4 * 1-3 command line 1月1日早上4点 0 4 1 1 * command line 每次编辑完某个用户的 cron 设置后，cron 自动在 /var/spool/cron下生成一个与此用户同名的文件，此用户的 cron 信息都记录在这个文件中，这个文件是不可以直接编辑的，只可以用 crontab -e 来编辑。cron 启动后每过一份钟读一次这个文件，检查是否要执行里面的命令。因此此文件修改后不需要重新启动 cron 服务。 2.编辑 /etc/crontab 文件配置 cron cron 服务每分钟不仅要读一次 /var/spool/cron 内的所有文件，还需要读一次 /etc/crontab，因此我们配置这个文件也能运用 cron 服务做一些事情。用 crontab 配置是针对某个用户的，而编辑 /etc/crontab 是针对系统的任务。此文件的文件格式是： SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root //如果出现错误，或者有数据输出，数据作为邮件发给这个帐号 HOME=/ //使用者运行的路径,这里是根目录 # run-parts 01 * * * * root run-parts /etc/cron.hourly // 每小时执行/etc/cron.hourly内的脚本 02 4 * * * root run-parts /etc/cron.daily // 每天执行/etc/cron.daily内的脚本 22 4 * * 0 root run-parts /etc/cron.weekly // 每星期执行/etc/cron.weekly内的脚本 42 4 1 * * root run-parts /etc/cron.monthly // 每月去执行/etc/cron.monthly内的脚本 大家注意“run-parts”这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是文件夹名了。 怎样在 unix 系统下查看所有用户的 crontab 的定时任务？ grep -v \"^#\" /var/spool/cron/crontabs/* var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"blog/linux/fork-cow.html":{"url":"blog/linux/fork-cow.html","title":"如何证明fork用了COW","keywords":"","body":"如何证明fork用了COW？ 写时复制(COW，Copy on Write) 是一个众所周知的概念，古老又伟大的 unix 利用了这一个特性，在当时，内存非常昂贵，cpu 计算资源极其昂贵，因此有必要用这种懒惰的方式来节省时间和空间。但怎么证明fork时内核真的用了这种技术呢？如果对linux内核代码很熟悉的话，当然可以直接阅读代码，找到蛛丝马迹。但如果像我等小白对linux内核代码不熟悉，又该改怎么办呢？ 首先祭出我们的法宝 stap，借助它，我们可以看看在 fork 之后，父进程和子进程对内存的读写时，到底发生了哪些系统调用。由于我们用到该工具的东西很简单，这里不再详细介绍。 下面看我们的测试程序，该程序很简单，进程首先大块大块地申请内存，然后 fork 出一个子进程1，子进程1对刚才申请的空间做只读操作；父进程继续 fork 出一个子进程2，子进程2对刚才的空间做读写操作。里面的 sleep 函数只是为了延时，便于有时间我们操作。程序如下： #include #include #include #include #include #include int main() { int i = 0; char* ptr[1000]; for (i = 0; i 0) { int ret2 = fork(); if (ret2 == 0) { sleep(10); fprintf(stderr, \"I'm the 2nd child(%d). I begin to write now\\n\", getpid()); for (i = 0; i stap 的脚本更为简单，该脚本只是简单监控上述进程以及两个子进程在何时调用了内核函数 copy_page (或 do_wp_page )，为什么要监控这个函数，这里还是需要对内核代码有一定的了解，不过不了解也没多大关系，google 一下，胡乱看些介绍文章估计也会有大致了解（见参考资料）。然后脚本会在60s后自动退出。脚本如下： #!/usr/bin/stap probe kernel.function(\"copy_page\") { if(pid() == target() || ppid() == target()) { printf(\"copy_page(@%d):pid(%d)\\n\", gettimeofday_us(), pid()) } } probe timer.s(60) { exit(); } 运行脚本 sudo stap copy-page.stap -x 6300，运行结果如下： 父进程 pid = 6300，共有 13 次 copy_page 调用 子进程1 pid = 6308，共有 3 次 copy_page 调用 子进程2 pid = 6309，共有 312 次 copy_page 调用 细心的看官可能发现，示例代码中申请了内存之后，马上进行了 memset 操作，也就是对内存进行读写操作。如果没有这些操作，结果又是另外一个样子：父进程的 copy_page 调用次数基本没变，而子进程1 和子进程2的 copy_page 操作分别是1次和2次。 为什么变化这么大？内核发生了什么？看来内核对我们隐瞒了太多的东西，这个以后再验证了。猜测当 malloc 时，linux 只是分配了虚拟内存（地址），但没有真正分配内存，实际读写数据时才会真正触发缺页（pagefault），此时才会真正触发物理内存的分配，但这时候子进程只是分配新内存，而不需要复制主进程的内存。 参考资料 http://blog.chinaunix.net/uid-24774106-id-3361500.html http://blog.csdn.net/vanbreaker/article/details/7955713 http://proxy3.zju88.net/agent/thread.do?id=LinuxDev-48aa2848-065dd11ca3f0faee1115345308cfab11&page=0&bd=LinuxDev&bp=28&m=0 http://blog.csdn.net/yunsongice/article/details/5637671 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"blog/linux/splinlock.html":{"url":"blog/linux/splinlock.html","title":"Linux 自旋锁 spinlock 的使用","keywords":"","body":"Linux自旋锁spinlock的使用 在 Linux 中提供了一些机制用来避免竞争条件，最简单的一个种就是自旋锁，例如：当一个临界区的数据在多个函数之间被调用时，为了保护数据不被破坏，可以采用 spinlock 来保护临界区的数据。 定义和初始化spinlock 在 linux 中定义 spinlock 的方法很简单，与普通的结构体定义方式是一样的。其代码如下： spinlock_t spinlock = SPIN_LOCK_UNLOCKED; 一个自旋锁必须初始化才能被使用，可以通过在编译阶段通过宏定义来实现，比如上面的 SPIN_LOCK_UNLOCKED，这个表示一个没有锁定的自旋锁。同时在运行阶段可以使用 spin_lock_init() 函数动态地初始化一个自旋锁，其函数原型如下： spinlock_t spin_lock_init(spinlock_t lock); 锁定自旋锁 进入临界区之前，需要使用 spin_lock 宏定义来锁定自旋锁，spin_lock 宏定义的代码如下： #define spin_lock(lock) _spin_lock(lock) 这个宏用来获得 lock 的自旋锁，如果能够立即获得自旋锁，则宏立刻返回，否则，这个宏一直等待下去，直到被其它线程释放为止。 释放自旋锁 退出临界区之前，需要使用spin_unlock宏定义来释放自旋锁。spin_unlock宏定义的代码如下： #define spin_unlock(lock) _spin_unlock(lock) 这个宏用来释放 lock 的自旋锁，当调用该宏后，自旋锁立刻被释放。 使用自旋锁 在驱动程序中，有些设备只允许打开一次，那么就需要一个自旋锁保护表示设备打开或者关闭的状态的一个变量 status，此处的 status 为一个临界资源，如果不对 status 进行保护，当设备频繁的打开时，就有可能出现错误的 status 的状态，所以必须对 status 进行保护，其代码如下： int OpenCloseStatus; spinlock_t spinlock; int xxxx_init(void) { ... spin_lock_init(&spinlock); ... } int xxxx_open(struct inode *inode, struct file *filp) { ... spin_lock(&spinlock); if (OpenCloseStatus) { spin_unlock(&spinlock); return EBUSY; } status++; spin_unlock(&spinlock); ... } int xxxx_release(struct inode *inode, struct file *filp) { ... spin_lock(&spinlock); status--; spin_unlock(&spinlock); ... } 自旋锁使用注意事项 自旋锁一种忙等待，当条件不满足时，会一直不断的循环判断条件是否满足，如果满足就解锁，运行之后的代码。因此会对 linux 的系统的性能有些影响。所以在实际编程时，需要注意自旋锁不应该长时间的持有。它适合于短时间的的轻量级的加锁机制。 自旋锁不能递归使用，这是因为自旋锁，在设计之初就被设计成在不同进程或者函数之间同步。所以不能用于递归使用。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"blog/linux/who-stolen-ur-disk.html":{"url":"blog/linux/who-stolen-ur-disk.html","title":"谁偷了你的磁盘","keywords":"","body":"谁偷了你的磁盘 磁盘满了，但文件是空的，怎么办？ 使用df -hlT 查看磁盘剩余空间，所剩无几： [higkoo@TestServer ~]# df -hlT Filesystem Type Size Used Avail Use% Mounted on /dev/sda1 ext3 20G 6.6G 12G 36% / /dev/sda2 xfs 115G 103G 13G 89% /data tmpfs tmpfs 2.0G 0 2.0G 0% /dev/shm 而使用du -sh查看该分区磁盘占用量仅13G： [higkoo@TestServer ~]# du -sh /data/ 13G /data/ 产生这个问题的根本原因是：文件确实是从文件系统中删除了，但没有从磁盘上删除。由于进程正在操作磁盘，待进程退出后操作才能被更新。所以，在删除文件前先看一下有谁正在读写。若有进程在占用某个文件，而其他进程把这文件删掉，只会删除其在磁盘中的标记，而不会释放其占用的磁盘空间；直到所有访问该文件的进程退出为止。 df 是从内核中获取磁盘占用情况数据的，而du是统计当前磁盘文件大小的结果，由于磁盘标记已被删掉，因此du不会计算上述被删除文件的空间，导致df 与du的结果不一致。同理，ls -l显示文件的大小，du显示占用磁盘空间的大小。 如何跟踪这类问题呢？答案： lsof -n | grep deleted COMMAND PID USER FD TYPE DEVICE SIZE NODE NAME dd 31708 higkoo 1w REG 8,2 5523705856 429590 /data/filetest (deleted) 命令打lsof -n | grep deleted印出所有针对已删除文件的读写操作，这类操作是无效的，也正是磁盘空间莫名消失的根本原因！ 用清空的方式，把文件指针重置，该文件所占用的空间也会马上释放出来。所以，对于常发生类似问题的文件，如：日志记录文件等。以改名、清空、删除的顺序操作也可避免问题。 文件空洞 文件读写时，如果先文件指针偏移很大一段，然后写入1byte；这样这个文件实际占用1byte空间，但是stat查看文件大小，或者读写时，都会发现文件很大；所有没有写内容的都返回0，且不占用空间，这样的文件叫 'sparse file'，即文件空洞 复制输出的文件将使空洞全填为字符0，文件实际大小和原空洞文件大小一致，但是空洞部分化为字符0占用磁盘空间： cat file > file_copy 复制输出的文件不填平空洞，文件实际大小和原空洞文件大小一致，空洞部分仍是空洞，不占用磁盘空间： cp file file_copy var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:01:37 "},"./":{"url":"./","title":"说明","keywords":"","body":"Spark24ben's TechBook 个人技术资料整理，包括文章，读书笔记，常用工具等等。 var className='atoc'; Copyright © 9sheng all right reserved，powered by Gitbook文件修订时间： 2021-03-10 09:05:58 "}}